<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Liquibase小知识]]></title>
    <url>%2F2018%2F06%2FLiquibase%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[liquibase相关 不依赖于特定的数据库，目前支持包括Oracle/Sql Server/DB2/MySql/Sybase/PostgreSQL/Caché等12种数据库，这样在数据库的部署和升级环节可帮助应用系统支持多数据库 提供数据库比较功能，比较结果保存在XML中，基于该XML你可用Liquibase轻松部署或升级数据库 以XML存储数据库变化，其中以作者和ID唯一标识一个变化（ChangSet），支持数据库变化的合并，因此支持多开发人员同时工作 在数据库中保存数据库修改历史（DatabaseChangeHistory），在数据库升级时自动跳过已应用的变化（ChangSet）提供变化应用的回滚功能，可按时间、数量或标签（tag）回滚已应用的变化。通过这种方式，开发人员可轻易的还原数据库在任何时间点的状态 可生成数据库修改文档（HTML格式） 提供数据重构的独立的IDE和Eclipse插件 目录以及文件解释 data 存放初始化数据文件 schemas存放数据结构变动脚本 changelog.xml主要执行文件，引入相关数据变动脚本 liquibase.properties数据库配置文件 pom.xml引入数据库依赖以及liquibase插件 liquibase常用命令changelogSync : 將changelog中未套用至db的change logs标识成已同步changelogSyncSQL : 同changelogSync，但只產生sql，而不執行同步到dbgenerateChangeLog : 將目前数据库的结构(默认不包含数据)生成 xmldbDoc : 產生像java doc的文件diff : 比對兩個数据库間的差異status : 顯示目前change set有那些change log會被套用到dbrollbackSql:根据回滚版本生成回滚sqlrollback:根据回滚版本生成回滚sql，并在数据库中执行update : 将changeLog.xml中的数据变动changeset脚本转化为sql语句，直接在数据库中执行updateSQL : 将changeLog.xml中的数据变动changeset脚本转化为sql语句，并输出到对应的文件中 Flyway VS Liquibase Flyway简单，直接写sql保存文件不支持回滚数据库迁移问题(SQL语句并不是一个广泛兼容的语言，有些关键字是独有的，如果flyway就需要兼容写两套sql脚本) Liquibase支持多种格式（xml/json/yaml/sql）支持多种数据库迁移可读性强支持回滚 传送门]]></content>
      <categories>
        <category>liquibase</category>
      </categories>
      <tags>
        <tag>liquibase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis常见数据类型操作命令]]></title>
    <url>%2F2018%2F05%2FRedis%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Key keys *—查询所有key exists key—判断key是否存在 move key db—移除当前库的key值 expire key 秒钟—设定过期时间 ttl key —查看多少秒后过期，-1永不过期，-2已过期 type key —查看key类型 FLUSHALL—清空所有数据库String set/get/del/append（追加）/strlen（获取key长度） incr（递增1）/decr（递减1）/incrby（指定递增多少）/decrby（指定递减多少）—数字才行 getrange（区间范围内取值）/setrange（区间范围内覆盖设值） setex（set with expire）设值以及过期时间/setnx（set if not exist 不存在则写入） mset（多值设置）/mget（多值获取）/msetnx（全部不存在才进行插入） getset 先获取再设值Hash hset/hget/hmset/hmget/hgetall/hdel hlen获取键值个数 hexist key keyname 判断keyname是否在key中 hkeys（获取所有key）/hvals（获取所有values） hincrby/hincrbyfloat（指定递增） hsetnx（键值不存在则进行设值）List lpush（添加左边元素）/rpush（添加右边元素）/lrange（LRANGE key start stop 获取列表片段，0 -1 返回整个列表） lindex （返回索引的元素值，-1表示从最右边的第一位） llen（获取list长度） lrem（LREM key count value，返回被删除的个数）count&gt;0，从左边开始删除前count个值为value的元素count&lt;0，从右边开始删除前|count|个值为value的元素count=0，删除所有值为value的元素 ltrim （根据传入索引截取保留对应列表片段） rpoplpush（一个列表右移除转移另一个列表左插入） lset（设值元素值） linsert key before/after val01 val02 （在val01之前或者之后插入val02）Set sadd（新增set元素，去重）/smembers（获取set集合）/sismember（判断是否set里的值） scard（返回集合元素个数） srem（ 删除集合中一个或多个元素，返回成功删除的个数） srandmember（SRANDMEMBER key [count]）根据count不同有不同结果，count大于元素总数时返回全部元素count&gt;0 ，返回集合中count不重复的元素count&lt;0，返回集合中count的绝对值个元素，但元素可能会重复 spop（随机出栈） smove（smove k1 k2 val -&gt;将k1的val剪切到k2上） sdiff【差集】（sdiff A B —-&gt;集合A和集合B，差集表示A-B，在A里有的元素B里没有，返回差集合；多个集合(A-B)-C） sinter【交集】 sunion【并集】ZSet zadd（不存在添加，存在更新） zscore（获取元素分数） zrange（元素从小到大:加上withscores 返回带元素，即元素，分数，当分数一样时，按元素排序） zrevrange（元素从大到小） zrangebyscore（指定分数范围元素）返回从小到大的在min和max之间的元素，( 左括号表示不包含，例如：80-100—&gt;(80 100withscore返回带分数limit offest count 向左偏移offest个元素，并获取前count个元素 zrevrangebyscore（从大到小排序） zrem（删除元素） zcard（计算集合内个数） zcount（计算对应范围内个数）eg：ZCOUNT salary 2000 5000 —-&gt;计算薪水在 2000-5000 之间的人数 zrank（获取下标值） zrevrank（逆序获取下标值） zscore（获取对应的分数）]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程之synchronized、Lock、volatile]]></title>
    <url>%2F2018%2F05%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8Bsynchronized%E3%80%81Lock%E3%80%81volatile%2F</url>
    <content type="text"><![CDATA[synchronized Java的关键字，是Java的内置特性，在JVM层面实现了对临界资源的同步互斥访问，通过对对象的头文件来操作，从而达到加锁和释放锁的目的 synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生 不能响应中断 同一时刻不管是读还是写都只能有一个线程对共享资源操作，其他线程只能等待，性能不高 synchronized是Java中的关键字，是一种同步锁： 无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁对应的是类，该类所有的对象同一把锁。 每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码。 实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制 lock Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现 Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁 Lock可以让等待锁的线程响应中断，synchronized不可以 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到 Lock可以提高多个线程进行读操作的效率1234567891011121314151617181920212223242526272829303132333435363738394041public interface Lock &#123; /** * 获取锁，如果锁被其他线程获取，则进行等待 */ void lock(); /** * 当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断， * 即中断线程的等待状态。也就是说， * 当两个线程同时通过lock.lockInterruptibly()想获取某个锁时， * 假若此时线程A获取到了锁，而线程B只有在等待， * 那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 * * @throws InterruptedException */ void lockInterruptibly() throws InterruptedException; /** * tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成 * 功，则返回true，如果获取失败（即锁已被其他线程获取），则返回 * false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 */ boolean tryLock(); /** * tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的， * 只不过区别在于这个方法在拿不到锁时会等待一定的时间， * 在时间期限之内如果还拿不到锁，就返回false。 * 如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 * * @param time * @param unit * @return * @throws InterruptedException */ boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); //释放锁 Condition newCondition();&#125; volatile 可见性：保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的 有序性：禁止进行指令重排序 加入volatile关键字时，会多出一个lock前缀指令，lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成 它会强制将对缓存的修改操作立即写入主存 如果是写操作，它会导致其他CPU中对应的缓存行无效 lock和synchronized的区别 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 Lock可以提高多个线程进行读操作的效率。在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized volatile和synchronized区别 volatile本质是在告诉jvm当前变量在寄存器中的值是不确定的,需要从主存中读取,synchronized则是锁定当前变量,只有当前线程可以访问该变量,其他线程被阻塞住. volatile仅能使用在变量级别,synchronized则可以使用在变量,方法. volatile仅能实现变量的修改可见性,而synchronized则可以保证变量的修改可见性和原子性. 《Java编程思想》上说，定义long或double变量时，如果使用volatile关键字，就会获得（简单的赋值与返回操作）原子性。 volatile不会造成线程的阻塞,而synchronized可能会造成线程的阻塞. 当一个域的值依赖于它之前的值时，volatile就无法工作了，如n=n+1,n++等。如果某个域的值受到其他域的值的限制，那么volatile也无法工作，如Range类的lower和upper边界，必须遵循lower&lt;=upper的限制。 使用volatile而不是synchronized的唯一安全的情况是类中只有一个可变的域 锁可重入锁如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock（唯一实现了Lock接口的类）都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2 可中断锁在Java中，synchronized就不是可中断锁，而Lock是可中断锁如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁 公平锁公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁 参考：java中volatile、synchronized和lock解析、Java并发编程：Lock]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot学习之禁用数据库自动配置]]></title>
    <url>%2F2018%2F05%2FSpringboot%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A6%81%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[SpringBoot默认会自动配置数据库，如果业务不需要，就要手动禁用数据库自动配置,在Application的SpringBootApplication注解里加上12345@SpringBootApplication(exclude = &#123; DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class, HibernateJpaAutoConfiguration.class&#125;)]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA集合总结]]></title>
    <url>%2F2018%2F05%2FJAVA%E9%9B%86%E5%90%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Collection接口是集合类的根接口，Java中没有提供这个接口的直接的实现类。但是却让其被继承产生了两个接口，就是Set和List。Set中不能包含重复的元素。List是一个有序的集合，可以包含重复的元素，提供了按索引访问的方式 Map是Java.util包中的另一个接口，它和Collection接口没有关系，是相互独立的，但是都属于集合类的一部分。Map包含了key-value对。Map不能包含重复的key，但是可以包含相同的value Iterator，所有的集合类，都实现了Iterator接口，这是一个用于遍历集合中元素的接口，主要包含以下三种方法： hasNext()是否还有下一个元素。 next()返回下一个元素。 remove()删除当前元素 List List里存放的对象是有序的，同时也是可以重复的，List关注的是索引，拥有一系列和索引相关的方法，查询速度快。因为往list集合里插入或删除数据时，会伴随着后面数据的移动，所有插入删除数据速度慢。 说明 ArrayList在内存不够时默认是扩展50% + 1个，Vector是默认扩展1倍。 Vector属于线程安全级别的，但是大多数情况下不使用Vector，因为线程安全需要更大的系统开销。 一般使用ArrayList和LinkedList比较多，LinkedList不存在get()的操作，不能单个定位，ArrayList是顺序存储结构，LinkedList是链表存储结构 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据 ArrayList（常用、数组实现，对元素快速随机访问）ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要讲已经有数组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除 Vector（数组实现、线程同步、需高花费）Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢 LinkedList（链表结构、Queue）LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用 ArrayList和LinkedList在用法上没有区别，但是在功能上还是有区别的。LinkedList经常用在增删操作较多而查询操作很少的情况下，ArrayList则相反 Set Set集合不允许出现重复数据允许包含值为null的元素，但最多只能有一个null元素。 HashSet HashSet中不能有重复的元素 HashSet是无序的 HashSet也是基于HashMap实现 TreeSet TreeSet中不能有重复的元素； TreeSet具有排序功能，缺省是按照自然排序进行排列 TreeSet中的元素必须实现Comparable接口并重写compareTo()方法，TreeSet判断元素是否重复 、以及确定元素的顺序靠的都是这个方法 基于TreeMap实现 Map Map集合中存储的是键值对，键不能重复，值可以重复。根据键得到值，对map集合遍历时先得到键的set集合，对set集合进行遍历，得到相应的值 Map遍历：KeySet()、entrySet()keySet其实是遍历了2次，一次是转为iterator，一次就是从HashMap中取出key所对于的value。而entryset只是遍历了第一次，它把key和value都放到了entry中，所以entrySet效率较高 HashMapHashMap是最常用的Map，它根据键的HashCode值存储数据，根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。因为键对象不可以重复，所以HashMap最多只允许一条记录的键为Null，允许多条记录的值为Null，是非同步的 HashMap是无序的散列映射表； HashMap通过Hash 算法来决定存储位置 底层实现是哈希表 HashtableHashtable与HashMap类似，是HashMap的线程安全版，它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了Hashtale在写入时会比较慢，它继承自Dictionary类，不同的是它不允许记录的键或者值为null，同时效率较低 TreeMapTreeMap实现SortMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序（自然顺序），也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。不允许key值为空，非同步的 适用于按自然顺序或自定义顺序遍历键(key)。 底层是二叉树 提供compareTo，可以定义排序方法 LinkedHashMapLinkedHashMap保存了记录的插入顺序，在用Iteraor遍历LinkedHashMap时，先得到的记录肯定是先插入的，在遍历的时候会比HashMap慢，有HashMap的全部特性。 ConcurrentHashMap 线程安全 JDK1.7分析：ConcurrentHashMap采用 分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构 JDK1.8分析：1.8的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构 CAS的思想：三个参数，一个当前内存值V、旧的预期值A、即将更新的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。 主要实现类区别Vector VS ArrayList vector是线程同步的，所以它也是线程安全的，而arraylist是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用arraylist效率比较高。 如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%，而arraylist增长率为目前数组长度的50%。如果在集合中使用数据量比较大的数据，用vector有一定的优势。 如果查找一个指定位置的数据，vector和arraylist使用的时间是相同的，如果频繁的访问数据，这个时候使用vector和arraylist都可以。而如果移动一个指定位置会导致后面的元素都发生移动，这个时候就应该考虑到使用linklist,因为它移动一个指定位置的数据时其它元素不移动。 ArrayList 和Vector是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，都允许直接序号索引元素，但是插入数据要涉及到数组元素移动等内存操作，所以索引数据快，插入数据慢，Vector由于使用了synchronized方法（线程安全）所以性能上比ArrayList要差，LinkedList使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快 ArrayList VS LinkedList ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 这一点要看实际情况的。若只对单条数据插入或删除，ArrayList的速度反而优于LinkedList。但若是批量随机的插入删除数据，LinkedList的速度大大优于ArrayList. 因为ArrayList每插入一条数据，要移动插入点及之后的所有数据 HashMap VS TreeMap HashMap通过hashcode对其内容进行快速查找，而TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。 在Map 中插入、删除和定位元素，HashMap是最好的选择。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现。两个map中的元素一样，但顺序不一样，导致hashCode()不一样。同样做测试：123在HashMap中，同样的值的map,顺序不同，equals时，false;而在treeMap中，同样的值的map,顺序不同,equals时，true，说明treeMap在equals()时是整理了顺序了的 HashTable VS HashMap 同步性:Hashtable是线程安全的，也就是说是同步的，而HashMap是线程序不安全的，不是同步的。 HashMap允许存在一个为null的key，多个为null的value 。 hashtable的key和value都不允许为null 参考：JAVA集合类汇总、深入理解Java集合]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL两种引擎的区别]]></title>
    <url>%2F2018%2F05%2FMySQL%E4%B8%A4%E7%A7%8D%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Innodb引擎Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。 MyISAM引擎MyISAM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。不过和Innodb不同，MyISAM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyISAM也是很好的选择。 区别 MyISAM是非事务安全的，而InnoDB是事务安全的 MyISAM锁的粒度是表级的，而InnoDB支持行级锁 MyISAM支持全文类型索引，而InnoDB不支持全文索引 MyISAM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyISAM MyISAM表保存成文件形式，跨平台使用更加方便 应用场景 MyIASM管理非事务表，提供高速存储和检索以及全文搜索能力，如果再应用中执行大量select操作，应该选择MyIASM InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB 摘抄：MySQL两种引擎的区别]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis主从复制]]></title>
    <url>%2F2018%2F05%2FRedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[配置从库，不配主库从库配置：slaveof 主库ip 主库端口每次与master断开后，都需要重新连接，除非配置redis.conf文件 修改配置文件常用3招 一主二仆 薪火相传 反客为主（slaveof no one） 复制原理salve 启动成功连接到master后会发送一个sync命令，master接到命令后启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，进程执行完毕后，master将传送整个数据文件到slave，以完成一次完全同步，也就是全量复制，而slave服务在接收到数据后，存盘到内存中；master将新的修改命令依次传给slave，完成同步，此时为增量复制 只要重新连接master，一次完全同步（全量复制）将被自动执行 哨兵模式 反客为主的自动版本，监控主机是否故障，当主库挂了，根据投票数重新选定master 新建sentinel.conf 配置文件内容 1sentinel monitor 自定义名称 监控库ip 监控库端口 1 启动哨兵 1redis-sentinel /usr/local/redis/sentinel.conf 自动监控，选好新master后，原master恢复后会变成slave 一组sentinel可以同时监控多个master 复制的缺点由于所有的写操作都在master上，然后同步更新到slave上，所以从master同步到slave 机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave机器数量的增加也会使得这个问题更加严重]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化存储]]></title>
    <url>%2F2018%2F05%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[Redis中数据存储模式 cache-onlypersistence 1234cache-only：只做为“缓存”服务，不持久数据，数据在服务终止后将消失，此模式下也将不存在“数据恢复”的手段，是一种安全性低/效率高/容易扩展的方式；persistence：为内存中的数据持久备份到磁盘文件，在服务重启后可以恢复，此模式下数据相对安全。 对于persistence持久化存储，Redis提供了两种持久化方法12Redis DataBase(简称RDB)Append-only file (简称AOF) 如果同时开启两种持久化，会优先加载AOF进行恢复 RDB持久化：默认开启 指定时间间隔进行快照存储 优点：使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能缺点：RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候 save：服务器进程进行快照存储（阻塞） bgsave：进行异步快照存储（派生子进程处理，非阻塞） 异常恢复：redis-check-rdb1234567891011121314151617181920#dbfilename：持久化数据存储在本地的文件dbfilename dump.rdb#dir：持久化数据存储在本地的路径，如果是在/redis/redis-3.0.6/src下启动的redis-cli，则数据会存储在当前src目录下dir ./##snapshot触发的时机，save &lt;seconds&gt; &lt;changes&gt; ##如下为900秒后，至少有一个变更操作，才会snapshot ##对于此值的设置，需要谨慎，评估系统的变更操作密集程度 ##可以通过save “”来关闭snapshot功能 #持久化(以快照的方式) 策略（默认）save 900 1 （15分钟变更一次）save 300 10 （5分钟变更10次）save 60 10000 （1分钟变更1万次）##当snapshot时出现错误无法继续时，是否阻塞客户端“变更操作”，“错误”可能因为磁盘已满/磁盘故障/OS级别异常等 stop-writes-on-bgsave-error yes ##是否启用rdb文件压缩，默认为“yes”，压缩往往意味着“额外的cpu消耗”，同时也意味这较小的文件尺寸以及较短的网络传输时间 rdbcompression yes AOF持久化：默认不开启 以日志的形式来记录每个写操作，将redis执行过的所有写指令记录下来（读操作不记录），只许追加但不可以改写文件，redis启动之初会读取改文件进行重新构建数据 AOF通过保存所有修改数据库的写命令请求来记录服务器的数据库状态 AOF文件中的所有命令都会以Redis命令请求协议的格式保存优点：可以保持更高的数据完整性，如果设置追加file的时间是1s，如果redis发生故障，最多会丢失1s的数据（appendfsync—&gt;everysec）；且如果日志写入不完整支持redis-check-aof来进行日志修复；AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）。缺点：AOF文件比RDB文件大，且恢复速度慢，运行效率也比rdb慢。 重写机制 当超过阈值，则启动内容压缩，只保留最小指令集，可使用命令：bgrewriteaof 定义：AOF采用文件追加的方式持久化数据，所以文件会越来越大，为了避免这种情况发生，增加了重写机制当AOF文件的大小超过了配置所设置的阙值时，Redis就会启动AOF文件压缩，只保留可以恢复数据的最小指令集，可以使用命令bgrewriteaof 原理：当AOF增长过大时，会fork出一条新的进程将文件重写(也是先写临时文件最后rename)，遍历新进程的内存数据，每条记录有一条set语句。重写AOF文件并没有操作旧的AOF文件，而是将整个内存中的数据内容用命令的方式重写了一个新的aof文件（有点类似快照） 触发机制：Redis会记录上次重写时的AOF文件大小，默认配置时当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发12auto-aof-rewrite-percentage 100 （一倍）auto-aof-rewrite-min-size 64mb 持久化策略 appendfsync always (同步持久化，每次发生数据变更会被立即记录到磁盘，性能差但数据完整性比较好) appendfsync everysec (异步操作，每秒记录，如果一秒钟内宕机，有数据丢失) appendfsync no （将缓存回写的策略交给系统，linux 默认是30秒将缓冲区的数据回写硬盘的）12345678910111213141516171819##此选项为aof功能的开关，默认为“no”，可以通过“yes”来开启aof功能 ##只有在“yes”下，aof重写/文件同步等特性才会生效 appendonly yes ##指定aof文件名称 appendfilename appendonly.aof ##指定aof操作中文件同步策略，有三个合法值：always(记录立即同步，性能较差) everysec(每秒同步，官方推荐) no(将缓存回写的策略交给系统，linux 默认是30秒将缓冲区的数据回写硬盘的)，默认为everysec appendfsync everysec ##在aof-rewrite期间，appendfsync是否暂缓文件同步，&quot;no&quot;表示“不暂缓”，“yes”表示“暂缓”，默认为“no” no-appendfsync-on-rewrite no ##aof文件rewrite触发的最小文件尺寸(mb,gb),只有大于此aof文件大于此尺寸是才会触发rewrite，默认“64mb” auto-aof-rewrite-min-size 64mb ##相对于“上一次”rewrite，本次rewrite触发时aof文件应该增长的百分比。 ##每一次rewrite之后，redis都会记录下此时“新aof”文件的大小(例如A)，那么当aof文件增长到A*(1 + p)之后 ##触发下一次rewrite，每一次aof记录的添加，都会检测当前aof文件的尺寸。 auto-aof-rewrite-percentage 100 比较 RDB与AOF同时开启 默认先加载AOF的配置文件 相同数据集，AOF文件要远大于RDB文件，恢复速度慢于RDB AOF运行效率慢于RDB,但是同步策略效率好，不同步效率和RDB相同]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java常见设计模式]]></title>
    <url>%2F2018%2F04%2FJava%E5%B8%B8%E8%A7%81%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式 保证一个类仅有一个实例，并提供一个访问它的全局访问点 懒汉式123456789101112131415public class Singleton &#123; /* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */ private static Singleton instance = null; /* 私有构造方法，防止被实例化 */ private Singleton() &#123;&#125; /* 1:懒汉式，静态工程方法，创建实例 */ public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 调用：Singleton.getInstance().method();优点：延迟加载（需要的时候才去加载）,适合单线程操作缺点： 线程不安全，在多线程中很容易出现不同步的情况，如在数据库对象进行的频繁读写操作时。 饿汉模式 在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快 1234567891011121314public class EagerSingleton &#123; //饿汉单例模式 //在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快 private static EagerSingleton instance = new EagerSingleton();//静态私有成员，已初始化 private EagerSingleton() &#123; //私有构造函数 &#125; public static EagerSingleton getInstance() //静态，不用同步（类加载时已初始化，不会有多线程的问题） &#123; return instance; &#125;&#125; 双重线程检查模式12345678910111213141516171819202122232425public class SingletonInner &#123; private static volatile SingletonInner sInst = null; // &lt;&lt;&lt; 这里添加了 volatile /** * 私有的构造函数 */ private SingletonInner() &#123;&#125; public static SingletonInner getInstance() &#123; SingletonInner inst = sInst; // &lt;&lt;&lt; 在这里创建临时变量 if (inst == null) &#123; synchronized (SingletonInner.class) &#123; inst = sInst; if (inst == null) &#123; inst = new SingletonInner(); sInst = inst; &#125; &#125; &#125; return inst; // &lt;&lt;&lt; 注意这里返回的是临时变量 &#125; protected void method() &#123; System.out.println(&quot;SingletonInner&quot;); &#125; &#125; volatile：可见性（volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新）防止指令重排序（赋值后多执行了一个“load addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障）调用：Singleton.getInstance().method();优点：延迟加载，线程安全缺点：写法复杂，不简洁 内部类模式12345678910111213141516171819202122public class SingletonInner &#123; /** * 内部类实现单例模式 * 延迟加载，减少内存开销 */ private static class SingletonHolder &#123; private static SingletonInner instance = new SingletonInner(); &#125; /** * 私有的构造函数 */ private SingletonInner() &#123;&#125; public static SingletonInner getInstance() &#123; return SingletonHolder.instance; &#125; protected void method() &#123; System.out.println(&quot;SingletonInner&quot;); &#125; &#125; 调用：Singleton.getInstance().method();优点：延迟加载，线程安全（java中class加载时互斥的），也减少了内存消耗，推荐使用内部类方式。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中的代码优化]]></title>
    <url>%2F2018%2F04%2F%E5%B7%A5%E4%BD%9C%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[函数式接口改造123456789101112131415161718192021222324252627private TopModel generateTopDetailModel(TopModel topModel, List&lt;PlayerWithData&gt; playerWithDataList) &#123; List&lt;TopDetailModel&gt; shotsTopDetail = playerWithDataList.stream() .filter(p -&gt; p.getShots() != null &amp;&amp; p.getShots() != 0)//要过滤掉空值再比较,且要过滤掉0值 .sorted(Comparator.comparing(PlayerWithData::getShots).reversed() .thenComparing(PlayerWithData::getName)). limit(3).map(StatsPlayer -&gt; &#123; TopDetailModel model = new TopDetailModel(); BeanUtils.copyProperties(StatsPlayer, model); model.setDataCount(StatsPlayer.getShots()); return model; &#125;).collect(Collectors.toList()); topModel.setShots(shotsTopDetail); List&lt;TopDetailModel&gt; maxDribbSpTopDetail = playerWithDataList.stream(). filter(p -&gt; p.getMaxDribbSp() != null &amp;&amp; p.getMaxDribbSp() != 0.0) .sorted(Comparator.comparing(PlayerWithData::getMaxDribbSp).reversed() .thenComparing(PlayerWithData::getName)). limit(3).map(StatsPlayer -&gt; &#123; TopDetailModel model = new TopDetailModel(); BeanUtils.copyProperties(StatsPlayer, model); model.setDataCount(StatsPlayer.getMaxDribbSp()); return model; &#125;).collect(Collectors.toList()); topModel.setMaxDribbSp(maxDribbSpTopDetail); //省略N个字段的获取设值... return topModel; &#125; 123456789101112131415private List&lt;TopDetailModel&gt; setIntegerTopModel(List&lt;PlayerWithData&gt; playerWithDataList, Function&lt;PlayerWithData, Integer&gt; function, Integer count) &#123; return playerWithDataList.stream() .filter(p -&gt; function.apply(p) != null &amp;&amp; function.apply(p) != 0) .sorted(Comparator.comparing(function).reversed() .thenComparing(PlayerWithData::getName)). limit(count).map(stasPlayer -&gt; &#123; TopDetailModel model = new TopDetailModel(); BeanUtils.copyProperties(stasPlayer, model); model.setDataCount(function); return model; &#125;).collect(Collectors.toList()); &#125; 之后每个参数传入函数方法调用设值即可： topModel.setShots(setIntegerTopModel(playerWithDataList, PlayerWithData::getShots, count)); 字符串操作12345678910for (PenaltyModel penaltyModel : penaltyModels) &#123; String eventType = &quot;PENALTY.&quot;; if (penaltyModel.getIsGoal()) &#123; eventType = eventType + &quot;TRUE&quot;; &#125; else &#123; eventType = eventType + &quot;FALSE&quot;; &#125; ...... 每次循环都会创建新对象，造成内存资源浪费 &#125; 12345String为字符串常量，而StringBuilder和StringBuffer均为字符串变量，即String对象一旦创建之后该对象是不可更改的，但后两者的对象是变量，是可以更改的String：适用于少量的字符串操作的情况StringBuilder：适用于单线程下在字符缓冲区进行大量操作的情况StringBuffer：适用多线程下在字符缓冲区进行大量操作的情况 枚举命名建议带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开正例：BallEnum 反例：BallType 避免在循环中进行数据库操作12345678910private void uploadTeamConfig(List&lt;TeamConfig&gt; teamConfigList, String matchId) &#123; if (!CollectionUtils.isEmpty(teamConfigList)) &#123; for (TeamConfig teamConfig : teamConfigList) &#123; PerMatchTeamConfig perMatchTeamConfig = new PerMatchTeamConfig(); BeanUtils.copyProperties(teamConfig, perMatchTeamConfig); perMatchTeamConfig.setMatchId(matchId); perMatchTeamConfigService.saveOrUpdateByMatchIdAndTeamId(perMatchTeamConfig); &#125; &#125; &#125;]]></content>
      <categories>
        <category>优化</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习之actuator]]></title>
    <url>%2F2018%2F04%2FSpringBoot%E5%AD%A6%E4%B9%A0%E4%B9%8Bactuator%2F</url>
    <content type="text"><![CDATA[应用配置类/autoconfig用来获取应用的自动化配置报告，其中包括所有自动化配置的候选项。该端点可以帮助我们方便找到一些自动化配置为什么没有生效的具体原因。 positiveMatches：返回条件匹配成功的自动化配置 negativeMatches：返回条件匹配不成功的自动化配置 /beans获取应用上下文创建的所有Bean /configprops获取应用中配置的属性信息报告。prefix属性代表了属性的配置前缀，properties代表了各个属性的名称和值。如果要关闭该端点，通过使用endpoints.configprops.enabled=false来完成设置 /env该端点主要是用来获取应用中所有可用的环境属性报告。包括环境变量、JVM属性、应用的配置属性、命令行的参数。该端点会进行隐私保护，对于password、serect、key等关键词会使用*来替代实际的属性值 /mappings返回所有SpringMVC的控制器映射关系报告 /info返回自定义的配置信息，该自定义配置信息需要以info为前缀进行配置，例如：12info.app.name=spring-helloinfo.app.version=v0.0.1 度量指标类/metrics返回当前应用的各类重要度量指标，比如内存信息、线程信息、垃圾回收信息等。 系统信息：包括处理器数量processors、运行时间uptime和instance.uptime、系统平均负载systemload.average mem.* ：内存概要情况 heap.* ：堆内存使用情况 noheap.* ： 非堆内存使用情况 threads.*：线程使用情况，包括线程数、守护线程数（daemon）、线程峰值（peak）等 classes.*：应用加载和卸载的类统计 gc.*：垃圾收集器的详细信息，包括垃圾回收次数gc.ps_scavenge.count、垃圾回收消耗时间gc.ps_scavenge.time、标记-清楚算法的次数gc.ps_marksweep.count、标记-清楚算法的消耗时间gc.ps_marksweep.time httpsessions.*：Tomcat容器的会话使用情况，包括最大会话数httpsessions.max和活跃会话数httpsessions.active，该度量指标仅在引入嵌入式Tomcat作为应用容器才会提供 gauge.* ：HTTP请求的性能指标之一，主要用来反映一个绝对数值，比如gauge.response.hello:5，表示上一次hello请求的延迟时间为5毫秒 counter.*：HTTP请求的性能指标之一，主要作为计数器使用，记录了增加量和减少量，counter.status.200.hello:11，表示hello请求返回200状态的次数为11 可以通过/metrics/{name}接口来获取更细粒度的度量信息，比如通过/metrics/mem.free来获取当前可用内存数量 /health获取应用的各类健康指标信息 /dump用来暴露程序运行中的线程信息 /trace返回基本的HTTP跟踪信息，始终保留最近的100条请求记录 操作控制类在原生端点中，只提供了一个用来关闭应用的端点：/shutdown，通过如下配置开启1endpoints.shutdown.enabled=true 配置好了之后，只要访问该端点，就能实现关闭该应用的远程操作，后续Eureka中还会有许多控制端点…]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《书单》]]></title>
    <url>%2F2018%2F04%2F%E3%80%8A%E4%B9%A6%E5%8D%95%E3%80%8B%2F</url>
    <content type="text"><![CDATA[一 锋利的Jquery JavaScript高级程序设计 Maven Spring实战 第四版 二 Java8实战 Redis设计与实现 SpringBoot实战 深入理解Java虚拟机 Spring Cloud与Docker微服务架构实战 SpringCloud微服务实战 鸟哥的linux私房菜-服务器架设（待定）]]></content>
      <categories>
        <category>书单</category>
      </categories>
      <tags>
        <tag>书单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Stream结合RabbitMQ简单实例]]></title>
    <url>%2F2018%2F03%2FSpring-Cloud-Stream%E7%BB%93%E5%90%88RabbitMQ%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[了解Spring Cloud Stream了解RabbitMQ各项目中引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 生产者AA项目中新建一个接口作为通道 NotifyChannelConstant为自定义常量@Output注解代表这是一个输出通道 123456@Componentpublic interface PdfNotifyChannel &#123; @Output(NotifyChannelConstant.PDF_NOTIFY_CHANNEL) MessageChannel output();&#125; 绑定接口@EnableBinding 进行消息通知的类，需要添加@EnableBinding(PdfNotifyChannel.class)，指定绑定的接口通道 在类中进行初始化 12@Autowiredprivate PdfNotifyChannel pdfNotifyChannel; 业务方法中进行调用 1pdfNotifyChannel.output().send(MessageBuilder.withPayload(msg).build()); 消费者BB项目中新建一个接口作为通道 NotifyChannelConstant为自定义常量，此处引用的是A项目中的常量@Input注解代表这是一个输入通道，通道名需要与生产者对应才能接收消息12345@Componentpublic interface PdfNotifyChannel &#123; @Input(NotifyChannelConstant.PDF_NOTIFY_CHANNEL) MessageChannel input();&#125; 绑定接口@EnableBinding 进行消息接收的类，需要添加@EnableBinding(PdfNotifyChannel.class)，指定绑定的接口通道 监听使用@StreamListener进行监听该通道中的信息123456789/** * 监听推送信息 * @param message */ @StreamListener(NotifyChannelConstant.PDF_NOTIFY_CHANNEL) public void receiverPdfNotify(Message&lt;String&gt; message) &#123; LOGGER.info(&quot;频道[&#123;&#125;]监听信息为:[&#123;&#125;]&quot;, NotifyChannelConstant.PDF_NOTIFY_CHANNEL, message.getPayload()); &#125; 配置RabbitMQ 需要AB配置一致1234567spring.rabbitmq.host=localhostspring.rabbitmq.username=guestspring.rabbitmq.password=guest#默认5672spring.rabbitmq.port=5673#默认/spring.rabbitmq.virtual-host=/ RabbitMQ相关命令1234567891011121314151617181920# 查看当前所有用户$ sudo rabbitmqctl list_users# 查看默认guest用户的权限$ sudo rabbitmqctl list_user_permissions guest# 由于RabbitMQ默认的账号用户名和密码都是guest。为了安全起见, 先删掉默认用户$ sudo rabbitmqctl delete_user guest# 添加新用户$ sudo rabbitmqctl add_user username password# 设置用户tag$ sudo rabbitmqctl set_user_tags username administrator# 赋予用户默认vhost的全部操作权限$ sudo rabbitmqctl set_permissions -p / username &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;# 查看用户的权限$ sudo rabbitmqctl list_user_permissions username]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九浅一深之RabbitMQ]]></title>
    <url>%2F2018%2F03%2F%E4%B9%9D%E6%B5%85%E4%B8%80%E6%B7%B1%E4%B9%8BRabbitMQ%2F</url>
    <content type="text"><![CDATA[RabbitMQ是一个开源的AMQP实现：AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。 AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 ConnectionFactory、Connection、Channel都是RabbitMQ对外提供的API中最基本的对象。Connection是RabbitMQ的socket链接，它封装了socket协议相关部分逻辑。ConnectionFactory为Connection的制造工厂。 Channel是我们与RabbitMQ打交道的最重要的一个接口，我们大部分的业务操作是在Channel这个接口中完成的，包括定义Queue、定义Exchange、绑定Queue与Exchange、发布消息等。 RabbitMQMessage消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher消息的生产者，也是一个向交换器发布消息的客户端应用程序。 Exchange交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。 Binding绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 Connection网络连接，比如一个TCP连接。 Channel信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。 Virtual Host虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。 Broker表示消息队列服务器实体。 AMQP 中的消息路由 AMQP 中消息的路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发送到那个队列。 Exchange 类型Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了 direct消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。 fanout每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。 topic routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit” binding key与routing key一样也是句点号“. ”分隔的字符串 binding key中可以存在两种特殊字符’*’与“#”，用于做模糊匹配，其中“**”用于匹配一个单词，“#”用于匹配多个单词（可以是零个） headerheaders类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。 RPCMQ本身是基于异步的消息处理，前面的示例中所有的生产者（P）将消息发送到RabbitMQ后不会知道消费者（C）处理成功或者失败（甚至连有没有消费者来处理这条消息都不知道）。 但实际的应用场景中，我们很可能需要一些同步处理，需要同步等待服务端将我的消息处理完成后再进行下一步处理。这相当于RPC（Remote Procedure Call，远程过程调用）。在RabbitMQ中也支持RPC。 RabbitMQ 中实现RPC 的机制是： 客户端发送请求（消息）时，在消息的属性（MessageProperties ，在AMQP 协议中定义了14中properties ，这些属性会随着消息一起发送）中设置两个值replyTo （一个Queue 名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue 中）和correlationId （此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败） 服务器端收到消息并处理 服务器端处理完消息后，将生成一条应答消息到replyTo 指定的Queue ，同时带上correlationId 属性 客户端之前已订阅replyTo 指定的Queue ，从中收到服务器的应答消息后，根据其中的correlationId 属性分析哪条请求被执行了，根据执行结果进行后续业务处理 RabbitMQ 选型和对比 从社区活跃度按照目前网络上的资料，RabbitMQ 、activeM 、ZeroMQ 三者中，综合来看，RabbitMQ 是首选。 持久化消息比较ZeroMq 不支持，ActiveMq 和RabbitMq 都支持。持久化消息主要是指我们机器在不可抗力因素等情况下挂掉了，消息不会丢失的机制。 综合技术实现可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等等。RabbitMq / Kafka 最好，ActiveMq 次之，ZeroMq 最差。当然ZeroMq 也可以做到，不过自己必须手动写代码实现，代码量不小。尤其是可靠性中的：持久性、投递确认、发布者证实和高可用性。 高并发毋庸置疑，RabbitMQ 最高，原因是它的实现语言是天生具备高并发高可用的erlang 语言。 比较关注的比较， RabbitMQ 和 KafkaRabbitMq 比Kafka 成熟，在可用性上，稳定性上，可靠性上， RabbitMq 胜于 Kafka （理论上）。 另外，Kafka 的定位主要在日志等方面， 因为Kafka 设计的初衷就是处理日志的，可以看做是一个日志（消息）系统一个重要组件，针对性很强，所以 如果业务方面还是建议选择 RabbitMq 。还有就是，Kafka 的性能（吞吐量、TPS ）比RabbitMq 要高出来很多。 原文：消息队列之 RabbitMQ 、 我为什么要选择RabbitMQ]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务管理@Transactional]]></title>
    <url>%2F2018%2F03%2F%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86-Transactional%2F</url>
    <content type="text"><![CDATA[传播行为（生命周期）-Propagation 所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为（org.springframework.transaction.annotation.Propagation） REQUIRED（默认）方法A调用时没有事务新建一个事务，当在方法A调用另一个方法B的时候，方法B将使用同一个事务；如果方法B发生异常需要数据回滚的时候，整个事务回滚 REQUIRED_NEW对于方法A与B，在方法调用的时候无论是否有事务，都要开启一个新的事；如果这样方法B有异常不会导致方法A的数据回滚 NESTED和REQUIRED_NEW类似，但支持JDBC，不支持JPA或者Hibernate SUPPORTS方法调用时有事务就用事务，没有就不用 NOT_SUPPORTS强制方法不在事务中执行，若有事务，在方法调用到结束阶段事务都将会被挂起 NEVER强制方法不在事务中执行，若有事务则抛出异常 MANDATORY强制方法在事务中执行，若无事务则抛出异常指定方法：通过使用propagation属性设置1@Transactional(propagation = Propagation.REQUIRED) 隔离级别-Isolation 隔离级别是指若干个并发的事务之间的隔离程度，与我们开发时候主要相关的场景包括：脏读取、重复读、幻读；Isolation（隔离）决定了事务的完整性，处理在多事务对相同数据下的处理机制 READ_UNCOMMITED对于在A事务里修改了一条记录但没有提交事务，在B事务可以读取到修改后的记录。可导致脏读，不可重复读以及幻读 READ_COMMITED只有当在A事务里修改了一条记录且提交记录之后，B事务才可以读取到提交后的记录；阻止脏读，但可能导致不可重复读和幻读 REPEATABLE_READ不仅能实现READ_COMMITED的功能，而且还能阻止当A事务读取了一条记录，B事务将不允许修改这条记录；阻止脏读和不可重复读，但可出现幻读 SERIALIZABLE此级别下事务是顺序执行的，可以避免上述级别的缺陷，但开销较大 DEFAULT（默认）使用当前数据库的默认隔离界级别，如Oracle、SqlServer是READ_COMMITED；Mysql是REPEATABLE_READ指定方法：通过使用isolation属性设置1@Transactional(isolation = Isolation.DEFAULT) timeout（默认TIMEOUT_DEFAULT）timeout指定事务过期时间，默认为当前数据库的事务过期时间 readonly（默认false）指定当前事务是否是只读事务 rollbackFor（默认Throwable的子类）指定哪个或者哪些异常可以引起事务回滚 noRollBackFor（默认Throwable的子类）指定哪个或者哪些异常不可以引起事务回滚 12345678@Transactional(propagation=Propagation.REQUIRED) //控制事务传播。默认是Propagation.REQUIRED@Transactional(isolation=Isolation.DEFAULT) //控制事务隔离级别。默认跟数据库的默认隔离级别相同@Transactional(readOnly=false) //控制事务可读写还是只可读。默认可读写@Transactional(timeout=30) //控制事务的超时时间，单位秒。默认跟数据库的事务控制系统相同，又说是30秒@Transactional(rollbackFor=RuntimeException.class) //控制事务遇到哪些异常才会回滚。默认是RuntimeException@Transactional(rollbackForClassName=RuntimeException) //同上@Transactional(noRollbackFor=NullPointerException.class) //控制事务遇到哪些异常不会回滚。默认遇到非RuntimeException不会回滚@Transactional(noRollbackForClassName=NullPointerException)//同上]]></content>
      <categories>
        <category>事务</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java元注解]]></title>
    <url>%2F2018%2F03%2FJava%E5%85%83%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[@Retention: 定义注解的保留策略@Retention(RetentionPolicy.SOURCE) // 注解仅存在于源码中，在 class 字节码文件中不包含@Retention(RetentionPolicy.CLASS) // 默认的保留策略，注解会在 class 字节码文件中存在，但运行时无法获得，@Retention(RetentionPolicy.RUNTIME) // 注解会在 class 字节码文件中存在，在运行时可以通过反射获取到首 先要明确生命周期长度 SOURCE &lt; CLASS &lt; RUNTIME ，所以前者能作用的地方后者一定也能作用。一般如果需要在运行时去动态获取注解信息，那只能用 RUNTIME 注解；如果要在编译时进行一些预处理操作，比如生成一些辅助代码（如 ButterKnife），就用 CLASS 注解；如果只是做一些检查性的操作，比如 @Override 和 @SuppressWarnings，则可选用 SOURCE 注解。 @Target：定义注解的作用目标源码为：@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Target {ElementType[] value();}@Target(ElementType.TYPE) // 接口、类、枚举、注解@Target(ElementType.FIELD) // 字段、枚举的常量@Target(ElementType.METHOD) // 方法@Target(ElementType.PARAMETER) // 方法参数@Target(ElementType.CONSTRUCTOR) // 构造函数@Target(ElementType.LOCAL_VARIABLE)// 局部变量@Target(ElementType.ANNOTATION_TYPE)// 注解@Target(ElementType.PACKAGE) /// 包 @Document：说明该注解将被包含在 javadoc 中@Inherited：说明子类可以继承父类中的该注解作者：JavaIsRubbish链接：http://pipe.b3log.org/blogs/JavaIsRubbish/articles/2018/03/16/1521171085983]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系列：垃圾收集器与内存分配策略]]></title>
    <url>%2F2018%2F03%2FJVM%E7%B3%BB%E5%88%97%EF%BC%9A%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[判断对象是否存活引用计数算法 实现简单，判定效率高 Java虚拟机没有使用，主要原因是此算法很难解决对象之间相互循环引用的问题 可达性分析算法 通过一系列的称为”GC Roots”的对象作为起始点，从这些节点向下搜索，搜索走过的路径称为引用链；当一个对象跟”GC Roots”没有任何引用链的关系，则证明此对象不可达。 在进行可达性分析后发现此对象没有与”GC Roots”相连的引用链，则会被第一次标记并且进行一次筛选，条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者说finalize()方法已被虚拟机调用过，则没有必要执行如果该对象判定有必要执行，则会放到F-Quene队列，并在稍后由一个虚拟机自动建立、低优先级的Finalize线程去执行（会触发，但并不一定会等这个方法执行结束，以避免该方法执行缓慢或者死循环）finalize方法是对象逃脱死亡的最后一次机会，GC会对F-Quene中的对象进行第二次小规模标记，只有重新与引用链上的任何一个对象建立关联， 那么第二次标记，将会被移出”即将回收”集合，否则，就进行回收。一个对象的finalize方法只会被虚拟机调用一次 在Java中，可作为”GC Roots”的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（一般说的是Native方法）引用的对象 引用又分为：强、软、弱、虚 回收方法区 永久代的垃圾收集主要是：废弃常量和无用的类 无用的类： 该类所有的实例都已经被回收 加载该类的ClassLoader已经被回收 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法满足以上3个条件，可以进行回收，而不是必然回收。 垃圾收集算法标记-清除—-&gt;老年代 效率不高，产生大量不连续内存碎片 复制—-&gt;新生代 实现简单，运行高效，但是将内存缩小了一半 将可用内存划分为（A，B）2块，每次只用A块，将A块存活对象复制到B块，然后将A块一次清理，每次都对半区进行回收 标记-整理—-&gt;老年代垃圾收集器Serial收集器单线程：进行垃圾收集时，必须暂停其他所有的工作线程，直到收集结束。在Client模式下，简单高效，没有线程交互的开销 ParNew收集器Serial收集器的多线程版本 Parallel Scavenge收集器使用复制算法，达到可控制的吞吐量 Serial Old收集器使用标记-整理算法 Parallel Old收集器使用标记整理算法 CMS收集器 以获取最短回收停顿时间为目标的收集器 步骤： 初始标记（stop the world） 并发标记（stop the world） 重新标记 并发清除缺点： 对CPU资源非常敏感 无法处理浮动垃圾，可能导致Full GC产生 标记-清除算法，会导致大量内存碎片，从而引起Full GC G1收集器 面向服务器应用的垃圾收集器 特点： 并行与并发 分代收集 空间整合（标记-整理算法） 可预测的停顿：明确指定在一个长度为M毫秒的时间片段里，消耗在垃圾收集上的时间不得超过N毫秒 将Java堆划分为多个大小相等的独立区域Region，G1跟踪各个Region里面的价值大小（回收获得的空间大小以及需要花费的时间的经验值），在后台维护一个优先列表，每一次根据允许的收集时间（可预测的停顿）优先回收价值最大的Region（每个Region都有Remembered Set 避免全堆扫描） 步骤： 初始标记 并发标记 最终标记 筛选回收 内存分配与回收策略 对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配少数情况下分配到老年代 对象优先在Eden区分配当Eden区没有足够的空间分配时，虚拟机将会发起一次Minor GC（新生代GC，速度较快） 大对象直接进入老年代长期存活对象将进入老年代年龄计数器：在Survivor没熬过一次Minor GC，年龄加1，当达到阈值，则进入老年代；阈值设置（-XX:MaxTenuringThreshold） 动态对象年龄判定如果Survivor 中相同年龄所有对象的大小总和大于Survivor空间的一半，年龄大于或者等于该年龄的对象都直接进入老年代 空间分配担保在Minor GC，虚拟机会检查老年代中最大可用的连续空间是否大于新生代所有对象总空间。如果成立，则Minor GC安全；不成立，查看HandlePromotionFailure是否允许担保失败；如果允许，则检查老年代可用连续空间是否大于之前每次晋升老年代的平均值大小，如果大于，则冒险进行Minor GC，如果小于或者设置不允许担保失败的话，则进行Full GC。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系列：Java内存区域与内存溢出异常]]></title>
    <url>%2F2018%2F03%2FJVM%E7%B3%BB%E5%88%97%EF%BC%9AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[运行时数据区域 程序计数器 作用记录当前线程所执行到的字节码的行号。字节码解释器工作的时候就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。 意义JVM的多线程是通过线程轮流切换并分配处理器来实现的，对于我们来说的并行事实上一个处理器也只会执行一条线程中的指令。所以，为了保证各线程指令的安全顺利执行，每条线程都有独立的私有的程序计数器。 存储内容当线程中执行的是一个Java方法时，程序计数器中记录的是正在执行的线程的虚拟机字节码指令的地址。当线程中执行的是一个本地方法时，程序计数器中的值为空。 可能出现的异常此内存区域是唯一一个在JVM上不会发生内存溢出异常（OutOfMemoryError）的区域。 Java虚拟机栈 Java内存区常被分为堆内存（Heap）和栈内存（Stack），其中栈内存其实指的就是虚拟机栈，或者说是虚拟机栈中的局部变量表部分 作用描述Java方法执行的内存模型。每个方法在执行的同时都会开辟一段内存区域用于存放方法运行时所需的数据，成为栈帧，一个栈帧包含如：局部变量表、操作数栈、动态链接、方法出口等信息。 意义JVM是基于栈的，所以每个方法从调用到执行结束，就对应着一个栈帧在虚拟机栈中入栈和出栈的整个过程。 存储内容局部变量表（编译期可知的各种基本数据类型、引用类型和指向一条字节码指令的returnAddress类型）、操作数栈、动态链接、方法出口等信息。值得注意的是：局部变量表所需的内存空间在编译期间完成分配。在方法运行的阶段是不会改变局部变量表的大小的 可能出现的异常如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。如果在动态扩展内存的时候无法申请到足够的内存，就会抛出OutOfMemoryError异常。本地方法栈与虚拟机栈类似，区别在于虚拟机栈为虚拟机执行java方法（字节码）服务，而本地方法则为虚拟机所使用的Native方法服务Java堆 Java堆是垃圾收集器管理的主要区域（GC堆），可细分为：新生代，老年代，按空间可细分为：Eden空间，From Survivor空间，To Survivor空间 作用所有线程共享一块内存区域，在虚拟机开启的时候创建 意义存储对象实例，更好地分配内存。垃圾回收（GC）。堆是垃圾收集器管理的主要区域。更好地回收内存 存储内容存放对象实例，几乎所有的对象实例都在这里进行分配。堆可以处于物理上不连续的内存空间，只要逻辑上是连续的就可以。值得注意的是：在JIT编译器等技术的发展下，所有对象都在堆上进行分配已变得不那么绝对。有些对象实例也可以分配在栈中 可能出现的异常实现堆可以是固定大小的，也可以通过设置配置文件设置该为可扩展的。如果堆上没有内存进行分配，并无法进行扩展时，将会抛出OutOfMemoryError异常方法区 作用用于存储运行时常量池、已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 意义对运行时常量池、常量、静态变量等数据做出了规定。 存储内容运行时常量池（具有动态性）、已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 可能出现的异常当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。运行时常量池 运行时常量池对于Class文件常量池的另一个特征是具备动态性，在运行期间也可能将新的常量放入池中，例如String类的intern() 直接内存 JDK1.4中新加入NIO类，引入一种基于通道与缓冲的IO方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffeer对象作为这块内存的引用进行操作。（在一些场景中显著提高性能，因为避免了Java堆和Native堆中来回复制数据） 如果服务器管理员在配置虚拟机参数时，忽略了直接内存，就有可能导致动态扩展时，出现OutOfMemoryError异常 HotSpot虚拟机对象对象创建 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程，类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。 内存分配的2种方式： 选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定 指针碰撞Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离 空闲列表Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值 对象的内存布局 在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding） HotSpot虚拟机的对象头包括两部分信息： Mark Word第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit。 类型指针对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身对象的访问定位 建立对象是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的具体对象 目前主流的访问方式有使用句柄和直接指针两种： 句柄访问 直接指针访问对比优势： 使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。 使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。Sun HotSpot虚拟机是使用第二种方式进行对象虚拟机访问的。OutOfMemoryError 异常 除了程序计数器，其他运行时区域都有可能抛出OutOfMemoryError异常 Java堆溢出 内存泄露查看泄露对象到GC Roots的引用链，定位泄露代码位置。 内存溢出如果不存在泄露，即内存中的对象确实都还必须活着，检查JVM堆参数（-Xmx与-Xms），调大参数，检查代码是否存在某些对象生命周期过长，持有状态过长的情况，减少程序运行期的内存消耗。虚拟机栈、本地方法栈溢出HotSpot不区分虚拟机栈和本地方法栈，栈容量只能由-Xss参数设定。 StackOverFlow：线程申请的栈深度超过允许的最大深度 OutOfMemoryError： 虚拟机扩展时无法申请到足够的内存空间StackOverFlow的情况：递归调用方法，定义大量的本地变量，增大此方法帧中本地变量表的长度。OutOfMemoryError：多线程下的内存溢出，与栈空间是否足够大并不存在任何联系。为每个线程的栈分配的内存越大（参数-Xss），那么可以建立的线程数量就越少，建立线程时就越容易把剩下的内存耗尽，越容易内存溢出。在这种情况下，如果不能减少线程数目或者更换64位虚拟机时，减少最大堆和减少栈容量能够换区更多的线程。方法区和运行时常量池溢出 运行时常量池String.intern()是一个Native方法，它的作用是：如果运行时常量池中已经包含一个等于此String对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此String内容相同的字符串，并返回常量池中创建的字符串的引用。JDK7的intern()方法的实现有所不同，当常量池中没有该字符串时，不再是在常量池中创建与此String内容相同的字符串，而改为在常量池中记录堆中首次出现的该字符串的引用，并返回该引用 方法区方法区用于存放Class的相关信息，如果运行时产生大量的类去填满方法区，就可能发生方法区的内存溢出。 例如主流框架Spring、Hibernate对大量的类进行增强时，利用CGLib字节码生成动态类；大量JSP或动态JSP(JSP第一次运行时需要编译为Java类）。本机直接内存溢出Java虚拟机可以通过参数-XX:MaxDirectMemorySize设定本机直接内存可用大小，如果不指定，则默认与java堆内存大小相同。JDK中可以通过反射获取Unsafe类(Unsafe的getUnsafe()方法只有启动类加载器Bootstrap才能返回实例)直接操作本机直接内存。通过使用-XX:MaxDirectMemorySize=10M，限制最大可使用的本机直接内存大小为10MB。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cache声名式缓存注解]]></title>
    <url>%2F2018%2F03%2FCache%E5%A3%B0%E5%90%8D%E5%BC%8F%E7%BC%93%E5%AD%98%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[@Cacheable在方法执行前Spring先查看缓存中是否有数据，如果有，则直接返回缓存数据；若没有，调用方法并将方法返回值放入缓存 value：缓存的名称，在 spring 配置文件中定义，必须指定至少一个 例如：@Cacheable(value=”mycache”) 或者@Cacheable(value={”cache1”,”cache2”} key：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 例如：@Cacheable(value=”testcache”,key=”#userName”) condition：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 例如：@Cacheable(value=”testcache”,condition=”#userName.length()&gt;2”) @CachePut无论怎么样，都会把方法的返回值放进缓存中，属性与@Cacheable一致 @CacheEvict将一条或者多条数据从缓存中删除 value：缓存的名称，在 spring 配置文件中定义，必须指定至少一个 例如：@CachEvict(value=”mycache”) 或者@CachEvict(value={”cache1”,”cache2”} key：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 例如：@CachEvict(value=”testcache”,key=”#userName”) condition：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才清空缓存 例如：@CachEvict(value=”testcache”, condition=”#userName.length()&gt;2”) allEntrie：是否清空所有缓存内容，缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存 例如：@CachEvict(value=”testcache”,allEntries=true) beforeInvocation：是否在方法执行前就清空，缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存 例如：@CachEvict(value=”testcache”，beforeInvocation=true) @Caching可以通过@Caching注解将多个注解策略组合到一个方法上@Caching注解可以让我们在一个方法或者类上同时指定多个Spring Cache相关的注解。其拥有三个属性：cacheable、put和evict，分别用于指定@Cacheable、@CachePut和@CacheEvict。12345@Caching(cacheable = @Cacheable(&quot;users&quot;), evict = &#123; @CacheEvict(&quot;cache2&quot;), @CacheEvict(value = &quot;cache3&quot;, allEntries = true) &#125;) public User find(Integer id) &#123; return null; &#125;]]></content>
      <categories>
        <category>cache</category>
      </categories>
      <tags>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC内存回收]]></title>
    <url>%2F2018%2F02%2FGC%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[Java在内存中的状态 可达状态：在一个对象创建后，有一个以上的引用变量引用它 可恢复状态：如果程序中某个对象不再有任何的引用变量引用它，它将先进入可恢复状态。在这个状态下，系统的垃圾回收机制准备回收该对象的所占用的内存，在回收之前，系统会调用finalize()方法进行资源清理，如果资源整理后重新让一个以上引用变量引用该对象，则这个对象会再次变为可达状态；否则就会进入不可达状态 不可达状态：当对象的所有关联都被切断，且系统调用finalize()方法进行资源清理后依旧没有使该对象变为可达状态，则这个对象将永久性失去引用并且变成不可达状态，系统才会真正的去回收该对象所占用的资源 Java对对象的4种引用 强引用 ：创建一个对象并把这个对象直接赋给一个变量，eg ：Person person = new Person(“sunny”); 不管系统资源有么的紧张，强引用的对象都绝对不会被回收，即使以后不会再用到 软引用 ：通过SoftReference类实现，eg : SoftReference p = new SoftReference(new Person(“Rain”));,内存非常紧张的时候会被回收，其他时候不会被回收，所以在使用之前要判断是否为null从而判断他是否已经被回收了 弱引用 ：通过WeakReference类实现，eg : WeakReference p = new WeakReference(new Person(“Rain”));不管内存是否足够，系统垃圾回收时必定会回收 虚引用 ：不能单独使用，主要是用于追踪对象被垃圾回收的状态。通过PhantomReference类和引用队列ReferenceQueue类联合使用实现 JAVA辣鸡回收机制 内存回收 / 碎片整理 辣鸡回收算法 串行回收（单个CPU）/ 并行回收（多个CPU才有用） 1并行回收的执行效率很高，但复杂度增加，另外也有一些副作用，如内存碎片增加 并发执行和应用程序停止 1234***应用程序停止，这种方式会导致应用程序的暂停***并发执行虽然不会导致应用程序暂停，但是需要解决和应用程序的执行冲突（应用程序可能在回收阶段修改对象等等），所以并发执行这种方式的系统开销比应用程序停止更高，而且执行起来需要更多的堆内栈 压缩/不压缩/复制 支持压缩的垃圾回收器（标记-压缩 = 标记清除+压缩）会把所有的可达对象搬迁到一端，然后直接清理掉端边界以外的内存，减少了内存碎片。 不压缩的垃圾回收器（标记-清除）要遍历两次，第一次先从跟开始访问所有可达对象，并将他们标记为可达状态，第二次便利整个内存区域，对未标记可达状态的对象进行回收处理。这种回收方式不压缩，不需要额外内存，但要两次遍历，会产生碎片 复制式的垃圾回收器：将堆内存分成两个相同空间，从根（类似于前面的有向图起始顶点）开始访问每一个关联的可达对象，将空间A的全部可达对象复制到空间B，然后一次性回收空间A。对于该算法而言，因为只需访问所有的可达对象，将所有的可达对象复制走之后就直接回收整个空间，完全不用理会不可达对象，所以遍历空间的成本较小，但需要巨大的复制成本和较多的内存。 堆内存的分代回收分代回收的依据 对象生存时间的长短：大部分对象在Young期间就被回收 不同代采取不同的垃圾回收策略：新（生存时间短）老（生存时间长）对象之间很少存在引用 堆内存的分代 Young代 回收机制 ：因为对象数量少，所以采用复制回收 回收频率：Young代对象大部分很快进入不可达状态，回收频率高且回收速度快 对象来源：绝大多数对象先分配到Eden区，一些大的对象会直接被分配到Old代中 Old代 回收机制：采用标记压缩算法回收 对象来源：对象大直接进入老年代 / Young代中生存时间长的可达对象 回收频率 ：因为很少对象会死掉，所以执行频率不高，而且需要较长时间来完成 Permanent代 用途 ：用来装载Class，方法等信息，默认为64M，不会被回收 对象来源 ：eg：对于像Hibernate，Spring这类喜欢AOP动态生成类的框架，往往会生成大量的动态代理类，因此需要更多的Permanent代内存。所以我们经常在调试Hibernate，Spring的时候经常遇到java.lang.OutOfMemoryError:PermGen space的错误，这就是Permanent代内存耗尽所导致的错误。 回收频率 ：不会被回收 常见的垃圾回收器串行回收器（只使用一个CPU） Young代采用串行复制算法；Old代使用串行标记压缩算法（三个阶段：标记mark—清除sweep—压缩compact），回收期间程序会产生暂停 并行回收器 对Young代采用的算法和串行回收器一样，只是增加了多CPU并行处理； 对Old代的处理和串行回收器完全一样，依旧是单线程 并行压缩回收器 对Young代处理采用与并行回收器完全一样的算法；只是对Old代采用了不同的算法，其实就是划分不同的区域，然后进行标记压缩算法：① 将Old代划分成几个固定区域；② mark阶段（多线程并行），标记可达对象；③ summary阶段（串行执行），从最左边开始检验知道找到某个达到数值（可达对象密度小）的区域时，此区域及其右边区域进行压缩回收，其左端为密集区域④ compact阶段（多线程并行），识别出需要装填的区域，多线程并行的把数据复制到这些区域中。经此过程后，Old代一端密集存在大量活动对象，另一端则存在大块空间 并发标识—清理回收（CMS） 对Young代处理采用与并行回收器完全一样的算法；只是对Old代采用了不同的算法，但归根待地还是标记清理算法：① 初始标识（程序暂停）：标记被直接引用的对象(一级对象)；② 并发标识（程序运行）：通过一级对象寻找其他可达对象；③ 再标记（程序暂停）：多线程并行的重新标记之前可能因为并发而漏掉的对象（简单的说就是防遗漏）④ 并发清理（程序运行） 内存管理小技巧 尽量使用直接量，eg：String javaStr = “内存回收” 使用StringBuilder和StringBuffer进行字符串连接等操作 尽早释放无用对象 尽量少使用静态变量 缓存常用的对象:可以使用开源的开源缓存实现，eg：OSCache，Ehcache 尽量不使用finalize()方法 在必要的时候可以考虑使用软引用SoftReference]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>GC</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis安装以及配置]]></title>
    <url>%2F2018%2F01%2FRedis%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[下载http://redis.io/download 解压tar zxvf redis-2.8.17.tar.gz 编译并安装1234cd redis-2.8.17make cd srcmake install PREFIX=/usr/local/redis make编译如果失败，因为没有安装gcc服务12yum install gcc---安装gccrpm -qa |grep gcc---查看安装是否成功 将配置文件移动到redis安装目录下进入redis目录，创建etc文件夹mv redis.conf /usr/local/redis/etc 启动服务、配置123/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf第一个是启动redis服务器第二个是启动服务器所需的配置 设置后台运行vim /usr/local/redis/etc/redis.conf将daemonize的值改为yes 设置开机自启vim /etc/rc.local加入/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis-conf 客户端链接/usr/local/redis/bin/redis-cli 停止服务/usr/local/redis/bin/redis-cli shutdown或者pkill redis-server]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx小知识]]></title>
    <url>%2F2017%2F12%2FNginx%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Nginx 禁止IP访问 为了避免别人把未备案的域名解析到自己的服务器IP而导致服务器被断网 在配置文件nginx.conf中新建一个server 12345server &#123; listen 80 default; server_name _; return 500; &#125; 原先的server中，server_name可以设置多个域名 Nginx 代理，http识别不到js，但是https可以识别到？ 由于在https的server中没有对js/css进行操作，但是在http的server中，发现了下面这一段： 1234location ~ .*\.(js|css)?$ &#123; expires 15d; &#125; 将需要识别的文件所在的端口的地址放进去 12345location ~ .*\.(js|css)?$ &#123; # expires 15d; proxy_pass http://127.0.0.1:8088; &#125; 或者直接将这一段删除即可 nginx 出现413 Request Entity Too Large问题的解决方法 nginx默认上传文件的大小是1M，可nginx的设置中修改 打开nginx配置文件 nginx.conf 在http{}段中加入 client_max_body_size 20m; 20m为允许最大上传的大小 保存后重启nginx]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛文件操作]]></title>
    <url>%2F2017%2F12%2F%E4%B8%83%E7%89%9B%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[七牛资源管理]]></content>
      <categories>
        <category>七牛</category>
      </categories>
      <tags>
        <tag>七牛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis小知识]]></title>
    <url>%2F2017%2F12%2FRedis%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[更改Redis报序列化错误，ClassNotFind 问题描述： 更改环境上线，由于依赖的A项目更改为旧的redis，因此B项目也改为旧的redis，发送短信时，系统报错，报错信息是：序列化错误，找不到对应的模型 检查发现，涉及到对应的逻辑代码已经几个月没有更新过 重启Tomcat，清除Tomcat缓存，无效 还原redis配置，短信发送成功 原因： 由于更改为旧的redis配置，登录redis客户端，发现对应的消息队列中还有一些没有被消费掉的消息，这些消息是之前旧的模型序列化进来，现在第一条序列化出去就找不到对应的模型，因此报错 更改旧版redis配置 &rArr; 旧消息队列没有被消费 &rArr; 重新连接总是读取第一条进行序列化 &rArr; 如果代码更改或者模型变更 &rArr; 导致序列化错误，找不到对应的模型 &rArr; redis需要设置过期时间进行自动清除 解决：设置缓存过期时间一天，且redis错误提示信息应当更加友好！redisTemplate.expire(“testKey”,1l,TimeUnit.DAYS);]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx安装以及配置]]></title>
    <url>%2F2017%2F11%2FNginx%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装编译工具及库文件1yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装 PCRE下载 PCRE 安装包1[root@bogon src]# wget http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz 解压安装包1[root@bogon src]# tar zxvf pcre-8.35.tar.gz 进入安装包目录1[root@bogon src]# cd pcre-8.35 编译安装12[root@bogon pcre-8.35]# ./configure[root@bogon pcre-8.35]# make &amp;&amp; make install 查看pcre版本1[root@bogon pcre-8.35]# pcre-config --version 安装 Nginx下载Nginx1[root@bogon src]# wget http://nginx.org/download/nginx-1.6.2.tar.gz 解压安装包1[root@bogon src]# tar zxvf nginx-1.6.2.tar.gz 进入安装目录1[root@bogon src]# cd nginx-1.6.2 编译安装123[root@bogon nginx-1.6.2]# ./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.35[root@bogon nginx-1.6.2]# make[root@bogon nginx-1.6.2]# make install 查看Nginx版本1[root@bogon nginx-1.6.2]# /usr/local/webserver/nginx/sbin/nginx -v Nginx 配置创建 Nginx 运行使用的用户 www12[root@bogon conf]# /usr/sbin/groupadd www [root@bogon conf]# /usr/sbin/useradd -g www www 配置nginx.conf 将/usr/local/webserver/nginx/conf/nginx.conf替换为以下内容配置nginx.conf ，将/usr/local/webserver/nginx/conf/nginx.conf替换为以下内容: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105user www www;worker_processes 2; #设置值和CPU核心数一致error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别pid /usr/local/webserver/nginx/nginx.pid;#Specifies the value for maximum file descriptors that can be opened by this process.worker_rlimit_nofile 65535;events&#123; use epoll; worker_connections 65535;&#125;http&#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;; #charset gb2312; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 8m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #下面是server虚拟主机的配置 server &#123; listen 80;#监听端口 server_name localhost;#域名 index index.html index.htm index.php; root /usr/local/webserver/nginx/html;#站点目录 location /aaa &#123; proxy_pass http://127.0.0.1:8080/aaa; &#125; location /abcd &#123; proxy_pass http://127.0.0.1:8081/abcd; &#125; location /yiwu &#123; proxy_pass http://127.0.0.1:8081/yiwu; &#125; location ~ .*\.(php|php5)?$ &#123; #fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|ico)$ &#123; expires 30d; # access_log off; &#125; location ~ .*\.(js|css)?$ &#123; expires 15d; # access_log off; &#125; access_log off; &#125; server &#123; listen 443 ssl; server_name localhost; ssl on; root html; index index.html index.htm; ssl_certificate cert/214335641040602.pem; ssl_certificate_key cert/214335641040602.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125; location /aaa &#123; proxy_pass http://127.0.0.1:8080/aaa; &#125; location /abcd &#123; proxy_pass http://127.0.0.1:8081/abcd; &#125; &#125;&#125; 在conf目录新建cert文件夹，将证书文件（阿里云免费证书：pem，key）放置cert，并且加入一个配置server：（这个server是https的配置，原先的server是对于http的配置） 1234567891011121314151617181920212223server &#123; listen 443 ssl; server_name localhost; ssl on; root html; index index.html index.htm; ssl_certificate cert/214335641040602.pem; ssl_certificate_key cert/214335641040602.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125; location /bjjc &#123; proxy_pass http://127.0.0.1:8080/bjjc; &#125; location /yiwu &#123; proxy_pass http://127.0.0.1:8081/yiwu; &#125; &#125; 检查配置文件ngnix.conf的正确性命令1[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx -t 启动 Nginx1[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx 启动后可以根据ip访问成功！ Nginx其他命令123/usr/local/webserver/nginx/sbin/nginx -s reload # 重新载入配置文件/usr/local/webserver/nginx/sbin/nginx -s reopen # 重启 Nginx/usr/local/webserver/nginx/sbin/nginx -s stop # 停止 Nginx 安装后启动报错，原因是tomcat80端口冲突]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux ActiveMQ安装启动]]></title>
    <url>%2F2017%2F11%2FLinux-ActiveMQ%E5%AE%89%E8%A3%85%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[下载 ActiveMQ官网：http://activemq.apache.org ， 下载apache-activemq-5.14.4-bin.tar.gz 安装jdk，配置环境变量 安装 上传apache-activemq-5.12.1-bin.tar.gz到linux服务器，并解压 部分目录说明：1234567bin目录：(windows下面的bat和unix/linux下面的sh) 启动ActiveMQ的启动服务就在这里conf目录： activeMQ配置目录，包含最基本的activeMQ配置文件data目录：activeMQ的日志文件目录webapps目录：系统管理员web控制界面文件 启动 进入bin目录，执行命令：1./activemq start 访问 启动成功就可以以 http://ip地址:8161 方式访问WEB管理界面，默认用户名和密码admin/admin ActiveMQ启动后，默认会启用8161和61616两个端口 8161端口为ActiveMQ的web管理控制端口， 61616为ActiveMQ的通讯端口 配置 web管理界面默认的用户名为admin/admin，其配置文件位于./conf/jetty-realm.properties 通信端口的定义在ActiveMQ的主配置文件，./conf/activemq.xml 12345678 &lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;!-- &lt;transportConnector name=&quot;amqp&quot; uri=&quot;amqp://0.0.0.0:5672?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;--&gt;&lt;!-- &lt;transportConnector name=&quot;stomp&quot; uri=&quot;stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;--&gt; &lt;transportConnector name=&quot;mqtt&quot; uri=&quot;mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;!-- &lt;transportConnector name=&quot;ws&quot; uri=&quot;ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;--&gt; &lt;/transportConnectors&gt; web管理端口的修改，activemq使用了jetty服务器来进行管理， 我们可以在conf/jetty.xml文件中对其配置，web管理端口默认为8161，定义在jetty.xml文件 12345&lt;bean id=&quot;jettyPort&quot; class=&quot;org.apache.activemq.web.WebConsolePort&quot; init-method=&quot;start&quot;&gt; &lt;!-- the default port number for the web console --&gt; &lt;property name=&quot;host&quot; value=&quot;0.0.0.0&quot;/&gt; &lt;property name=&quot;port&quot; value=&quot;8161&quot;/&gt;&lt;/bean&gt; 自動清空沒在使用的 topic 12345------broker 元素加上 schedulePeriodForDestinationPurge 的屬性 (10秒):------&lt;broker xmlns=&quot;http://activemq.apache.org/schema/core&quot; brokerName=&quot;localhost&quot; dataDirectory=&quot;$&#123;activemq.data&#125;&quot; schedulePeriodForDestinationPurge=&quot;10000&quot;&gt;------policyEntry 元素加上 gcInactiveDestinations 跟 inactiveTimoutBeforeGC 的屬性 (分別是開啟, 跟 20秒):------&lt;policyEntry topic=&quot;&gt;&quot; gcInactiveDestinations=&quot;true&quot; inactiveTimoutBeforeGC=&quot;20000&quot; &gt; 关闭服务 进入bin目录，执行命令：1./activemq stop]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7(firewall)开放端口和关闭防火墙]]></title>
    <url>%2F2017%2F11%2FCentOS7-firewall-%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3%E5%92%8C%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[开放端口永久的开放需要的端口12sudo firewall-cmd --zone=public --add-port=8080/tcp --permanentsudo firewall-cmd --reload 之后检查新的防火墙规则1firewall-cmd --list-all 关闭防火墙12345678910111213//临时关闭防火墙,重启后会重新自动打开systemctl restart firewalld//检查防火墙状态firewall-cmd --statefirewall-cmd --list-all//Disable firewallsystemctl disable firewalldsystemctl stop firewalldsystemctl status firewalld//Enable firewallsystemctl enable firewalldsystemctl start firewalldsystemctl status firewallad]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux小知识]]></title>
    <url>%2F2017%2F10%2FLinux%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[linux 执行jar nohup java -jar dlz-0.0.1-SNAPSHOT.jar –server.port=8899 &gt;&gt; background.log 2&gt;&amp;1 &amp; linux命令 查看是否存在相关进程(Back)： ps ax | grep Back 添加用户1234567首先用adduser命令添加一个普通用户，命令如下：#adduser tommy //添加一个名为tommy的用户#passwd tommy //修改密码Changing password for user tommy.New UNIX password: //在这里输入新密码Retype new UNIX password: //再次输入新密码passwd: all authentication tokens updated successfully. 赋予root权限 方法一 123456修改 /etc/sudoers 文件，找到下面一行，把前面的注释（#）去掉## Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL然后修改用户，使其属于root组（wheel），命令如下：#usermod -g root tommy修改完毕，现在可以用tommy帐号登录，然后用命令 su - ，即可获得root权限进行操作。 方法二 12345修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示：## Allow root to run any commands anywhereroot ALL=(ALL) ALLtommy ALL=(ALL) ALL修改完毕，现在可以用tommy帐号登录，然后用命令 su - ，即可获得root权限进行操作。 通常查找出错误日志 cat error.log | grep ‘错误error’ , 这时候我们还有个需求就是输出当前这个日志的前后几行：123cat error.log | grep -C 5 &apos;错误error&apos; 显示error.log文件里匹配&quot;错误error&quot;字符串那行以及上下5行cat error.log | grep -B 5 &apos;错误error&apos; 显示&quot;错误error&quot;及前5行cat error.log | grep -A 5 &apos;错误error&apos; 显示&quot;错误error&quot;及后5行 批量删除某字符串开头的文件12删除“tomcat-开头的文件”find . -name &quot;tomcat-*&quot; | xargs rm -rf 查看文件最后N行的命令12tail -n 20 filename说明：显示filename最后20行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>小知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven小知识]]></title>
    <url>%2F2017%2F10%2FMaven%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Maven 的classifier的作用 maven中要引入json包 12345&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; 当执行mvn install 命令时，却抛出一个错误，说找不到net.sf.json-lib:json-lib:2.2.2这个包，到仓库中看一下http://repo2.maven.org/maven2/net/sf/json-lib/json-lib/2.2.2/ jar的名称中多了一个跟JDK相关的名称，例如jdk15，按照上面的配置，明显是找不到这个jar的，于是classifier就有它的用武之地了，它表示在相同版本下针对不同的环境或者jdk使用的jar,如果配置了这个元素，则会将这个元素名在加在最后来查找相应的jar，例如： 123456&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; 这样配置即可找到json-lib-2.2.2-jdk15.jar maven 快照 更新策略 为什么会有快照？ 没有快照之前： A项目依赖于项目B，B每次改动就赋予一个新版本号，然后告诉A我改版本好了啊，每次改动都得告诉，有时忘了就麻烦了。 可以看出没有快照会带来“浪费版本号”、沟通成大加大的问题。 有了快照之后： A项目依赖于项目B，B每次改动都会打上时间戳，A编译时会检查B的时间戳，如果晚于本地仓库B的时间戳，那么就会进行更新，否则不予更新。 可以看出快照省去了沟通成本、版本号成本。 快照更新策略 注意，快照并不是每次install就会更新，这取决于更新策略；快照更新策略，有每日更新、永远检查更新、从不检查更新和自定义时间间隔更新，默认是每日更新也就是说一日更新一次，如果想总是更新，那么可以在settings.xml中配置。比如:12345678910111213141516&lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; updatePolicy更新snapshot包的频率，属性有四个值always(实时更新) daily（每天更新） interval:xxx（隔xxx分钟更新一次） never（从不更新） 默认为daily 也可以通过命令强制更新，mvn clean install-U参考博文 maven打包本地jar包，在plugin中设置includeSystemScope为true1234567&lt;dependency&gt; &lt;groupId&gt;llw-base-rpc&lt;/groupId&gt; &lt;artifactId&gt;llw-base-rpc&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/lib/llw-base-rpc.jar&lt;/systemPath&gt;&lt;/dependency&gt; 1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习之配置文件的加载顺序]]></title>
    <url>%2F2017%2F10%2FSpringBoot%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[spring boot通过jar包启动时，配置文件的加载顺序 @TestPropertySource 注解 命令行参数 Java系统属性（System.getProperties()） 操作系统环境变量 只有在random.*里包含的属性会产生一个RandomValuePropertySource 在打包的jar外的应用程序配置文件（通过 java -jar demo.jar –spring.config.location=/path/test_evn.properties ） 在打包的jar内的应用程序配置文件（application.properties，包含YAML和profile变量） 在@Configuration类上的@PropertySource注解 默认属性（使用SpringApplication.setDefaultProperties指定）所以，针对6和7的情况，我们一般在应用程序外部放置配置yml文件，防止每次发布时被篡改！参考]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git命令]]></title>
    <url>%2F2017%2F10%2FGit%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586git init # 初始化本地git仓库（创建新仓库）git config --global user.name &quot;xxx&quot; # 配置用户名git config --global user.email &quot;xxx@xxx.com&quot; # 配置邮件git config --global color.ui true # git status等命令自动着色git config --global color.status autogit config --global color.diff autogit config --global color.branch autogit config --global color.interactive autogit config --global --unset http.proxy # remove proxy configuration on gitgit clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库git status # 查看当前版本状态（是否修改）git add xyz # 添加xyz文件至indexgit add . # 增加当前子目录下所有更改过的文件至indexgit commit -m &apos;xxx&apos; # 提交git commit --amend -m &apos;xxx&apos; # 合并上一次提交（用于反复修改）git commit -am &apos;xxx&apos; # 将add和commit合为一步git rm xxx # 删除index中的文件git rm -r * # 递归删除git log # 显示提交日志git log -1 # 显示1行日志 -n为n行git log -5git log --stat # 显示提交日志及相关变动文件git log -p -mgit show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交的详细内容git show dfb02 # 可只用commitid的前几位git show HEAD # 显示HEAD提交日志git show HEAD^ # 显示HEAD的父（上一个版本）的提交日志 ^^为上两个版本 ^5为上5个版本git tag # 显示已存在的taggit tag -a v2.0 -m &apos;xxx&apos; # 增加v2.0的taggit show v2.0 # 显示v2.0的日志及详细内容git log v2.0 # 显示v2.0的日志git diff # 显示所有未添加至index的变更git diff --cached # 显示所有已添加index但还未commit的变更git diff HEAD^ # 比较与上一个版本的差异git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异git diff origin/master..master # 比较远程分支master上有本地分支master上没有的git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程定义（用于push/pull/fetch）git branch # 显示本地分支git branch --contains 50089 # 显示包含提交50089的分支git branch -a # 显示所有分支git branch -r # 显示所有原创分支git branch --merged # 显示所有已合并到当前分支的分支git branch --no-merged # 显示所有未合并到当前分支的分支git branch -m master master_copy # 本地分支改名git checkout -b master_copy # 从当前分支创建新分支master_copy并检出git checkout -b master master_copy # 上面的完整版git checkout features/performance # 检出已存在的features/performance分支git checkout --track hotfixes/BJVEP933 # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支git checkout v2.0 # 检出版本v2.0git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出git checkout -- README # 检出head版本的README文件（可用于修改错误回退）git merge origin/master # 合并远程master分支至当前分支git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改git push origin master # 将当前分支push到远程master分支git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支git push --tags # 把所有tag推送到远程仓库git fetch # 获取所有远程分支（不更新本地分支，另需merge）git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支git pull origin master # 获取远程分支master并merge到当前分支git mv README README2 # 重命名文件README为README2git reset --hard HEAD # 将当前版本重置为HEAD（通常用于merge失败回退）git rebasegit branch -d hotfixes/BJVEP933 # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支）git branch -D hotfixes/BJVEP933 # 强制删除分支hotfixes/BJVEP933git ls-files # 列出git index包含的文件git show-branch # 图示当前分支历史git show-branch --all # 图示所有分支历史git whatchanged # 显示提交历史对应的文件修改git revert dfb02e6e4f2f7b573337763e5c0013802e392818 # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818git ls-tree HEAD # 内部命令：显示某个git对象git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASHgit reflog # 显示所有提交，包括孤立节点git show HEAD@&#123;5&#125;git show master@&#123;yesterday&#125; # 显示master分支昨天的状态git log --pretty=format:&apos;%h %s&apos; --graph # 图示提交日志git show HEAD~3git show -s --pretty=raw 2be7fcb476git stash # 暂存当前修改，将所有至为HEAD状态git stash list # 查看所有暂存git stash show -p stash@&#123;0&#125; # 参考第一次暂存git stash apply stash@&#123;0&#125; # 应用第一次暂存git grep &quot;delete from&quot; # 文件中搜索文本“delete from”git grep -e &apos;#define&apos; --and -e SORT_DIRENTgit gcgit fsck]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ与Spring整合]]></title>
    <url>%2F2017%2F09%2FActiveMQ%E4%B8%8ESpring%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[配置文件中引入ActiveMQ.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:amq=&quot;http://activemq.apache.org/schema/core&quot; xmlns:jms=&quot;http://www.springframework.org/schema/jms&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms-4.0.xsd http://activemq.apache.org/schema/core http://activemq.apache.org/schema/core/activemq-core-5.8.0.xsd&quot;&gt; &lt;context:property-placeholder location=&quot;classpath:app*.properties&quot; local-override=&quot;true&quot; file-encoding=&quot;UTF-8&quot;/&gt; &lt;!-- ActiveMQ 连接工厂 --&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;!-- 如果连接网络：tcp://ip:61616；未连接网络：tcp://localhost:61616 以及用户名，密码--&gt; &lt;amq:connectionFactory id=&quot;amqConnectionFactory&quot; brokerURL=&quot;$&#123;jms.broker-url&#125;&quot; userName=&quot;admin&quot; password=&quot;admin&quot;/&gt; &lt;!-- Spring Caching连接工厂 --&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.CachingConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;amqConnectionFactory&quot;/&gt; &lt;!-- 同上，同理 --&gt; &lt;!-- &lt;constructor-arg ref=&quot;amqConnectionFactory&quot; /&gt; --&gt; &lt;!-- Session缓存数量 --&gt; &lt;property name=&quot;sessionCacheSize&quot; value=&quot;100&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring JmsTemplate 的消息生产者 start--&gt; &lt;!-- 定义JmsTemplate的Topic类型 --&gt; &lt;bean id=&quot;jmsTopicTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;constructor-arg ref=&quot;connectionFactory&quot;/&gt; &lt;!-- pub/sub模型（发布/订阅） --&gt; &lt;property name=&quot;pubSubDomain&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; &lt;!-- 定义JmsTemplate的Queue类型 --&gt; &lt;bean id=&quot;jmsQueueTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;constructor-arg ref=&quot;connectionFactory&quot;/&gt; &lt;!-- 非pub/sub模型（发布/订阅），即队列模式 --&gt; &lt;property name=&quot;pubSubDomain&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;!--Spring JmsTemplate 的消息生产者 end--&gt; &lt;!-- 消息消费者 start--&gt; &lt;!-- 定义Queue监听器 --&gt; &lt;jms:listener-container destination-type=&quot;queue&quot; container-type=&quot;default&quot; connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;auto&quot;&gt; &lt;jms:listener destination=&quot;test.queue&quot; ref=&quot;queueReceiver1&quot;/&gt; &lt;jms:listener destination=&quot;test.queue&quot; ref=&quot;queueReceiver2&quot;/&gt; &lt;/jms:listener-container&gt; &lt;!-- 定义Topic监听器 --&gt; &lt;jms:listener-container destination-type=&quot;topic&quot; container-type=&quot;default&quot; connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;auto&quot;&gt; &lt;jms:listener destination=&quot;test.topic&quot; ref=&quot;topicReceiver1&quot;/&gt; &lt;jms:listener destination=&quot;test.topic&quot; ref=&quot;topicReceiver2&quot;/&gt; &lt;/jms:listener-container&gt; &lt;!-- 消息消费者 end --&gt;&lt;/beans&gt; Queue生产者123456789101112131415161718192021/** * @description 队列消息生产者，发送消息到队列 */@Component(&quot;queueSender&quot;)public class QueueSender &#123; @Autowired @Qualifier(&quot;jmsQueueTemplate&quot;) private JmsTemplate jmsQueueTemplate;//通过@Qualifier修饰符来注入对应的bean /** * 发送一条消息到指定的队列（目标） * * @param queueName 队列名称 * @param message 消息内容 */ public void send(String queueName, final String message) &#123; jmsQueueTemplate.convertAndSend(queueName, message); &#125;&#125; Topic生产者123456789101112131415161718@Component(&quot;topicSender&quot;)public class TopicSender &#123; @Autowired @Qualifier(&quot;jmsTopicTemplate&quot;) private JmsTemplate jmsTemplate; /** * 发送一条消息到指定的队列（目标） * * @param topicName 队列名称 * @param message 消息内容 */ public void send(String topicName, final String message) &#123; jmsTemplate.convertAndSend(topicName, message); &#125;&#125; 接口测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Controller@RequestMapping(&quot;/activemq&quot;)public class ActivemqController &#123; @Resource private QueueSender queueSender; @Resource private TopicSender topicSender; /** * todo 开启activeMQ服务 * 发送消息到队列 * Queue队列：仅有一个订阅者会收到消息，消息一旦被处理就不会存在队列中 * @param message * @return String */ @ResponseBody @PostMapping(&quot;/queueSender&quot;) public String queueSender(@RequestParam(&quot;message&quot;) String message) &#123; String opt = &quot;&quot;; try &#123; queueSender.send(&quot;test.queue&quot;, message); opt = &quot;success&quot;; &#125; catch (Exception e) &#123; opt = e.getCause().toString(); &#125; return opt; &#125; /** * 发送消息到主题 * Topic主题 ：放入一个消息，所有订阅者都会收到 * 这个是主题目的地是一对多的 * * @param message * @return String */ @ResponseBody @PostMapping(&quot;/topicSender&quot;) public String topicSender(@RequestParam(&quot;message&quot;) String message) &#123; String opt = &quot;&quot;; try &#123; topicSender.send(&quot;test.topic&quot;, message); opt = &quot;success&quot;; &#125; catch (Exception e) &#123; opt = e.getCause().toString(); &#125; return opt; &#125;&#125;]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九浅一深之ActiveMQ]]></title>
    <url>%2F2017%2F09%2F%E4%B9%9D%E6%B5%85%E4%B8%80%E6%B7%B1%E4%B9%8BActiveMQ%2F</url>
    <content type="text"><![CDATA[下载ActiceMQ : http://activemq.apache.org/运行ActiveMQ服务 双击bin目录下的activemq.bat脚本文件 ActiveMQ默认使用的TCP连接端口是61616, 通过查看该端口的信息可以测试ActiveMQ是否成功启动 netstat -an|find “61616” ActiveMQ默认启动时，启动了内置的jetty服务器，提供一个用于监控ActiveMQ的admin应用。admin：http://127.0.0.1:8161/admin/，账号密码默认admin Ctrl+Shift+C 停止服务HelloWorld 生产者 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class JMSProducer &#123; //默认连接用户名 private static final String USERNAME = ActiveMQConnection.DEFAULT_USER; //默认连接密码 private static final String PASSWORD = ActiveMQConnection.DEFAULT_PASSWORD; //默认连接地址 private static final String BROKEURL = ActiveMQConnection.DEFAULT_BROKER_URL; //发送的消息数量 private static final int SENDNUM = 10; public static void main(String[] args) &#123; //连接工厂 ConnectionFactory connectionFactory; //连接 Connection connection = null; //会话 接受或者发送消息的线程 Session session; //消息的目的地 Destination destination; //消息生产者 MessageProducer messageProducer; //实例化连接工厂 connectionFactory = new ActiveMQConnectionFactory(JMSProducer.USERNAME, JMSProducer.PASSWORD, JMSProducer.BROKEURL); try &#123; //通过连接工厂获取连接 connection = connectionFactory.createConnection(); //启动连接 connection.start(); //创建session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); //创建一个名称为HelloWorld的消息队列 destination = session.createQueue(&quot;HelloWorld&quot;); //创建消息生产者 messageProducer = session.createProducer(destination); //发送消息 sendMessage(session, messageProducer); session.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; if(connection != null)&#123; try &#123; connection.close(); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 发送消息 * @param session * @param messageProducer 消息生产者 * @throws Exception */ public static void sendMessage(Session session,MessageProducer messageProducer) throws Exception&#123; for (int i = 0; i &lt; JMSProducer.SENDNUM; i++) &#123; //创建一条文本消息 TextMessage message = session.createTextMessage(&quot;ActiveMQ 发送消息&quot; +i); System.out.println(&quot;发送消息：Activemq 发送消息&quot; + i); //通过消息生产者发出消息 messageProducer.send(message); &#125; &#125;&#125; 消费者 1234567891011121314151617181920212223242526272829303132333435363738394041public class JMSConsumer &#123; private static final String USERNAME = ActiveMQConnection.DEFAULT_USER;//默认连接用户名 private static final String PASSWORD = ActiveMQConnection.DEFAULT_PASSWORD;//默认连接密码 private static final String BROKEURL = ActiveMQConnection.DEFAULT_BROKER_URL;//默认连接地址 public static void main(String[] args) &#123; ConnectionFactory connectionFactory;//连接工厂 Connection connection = null;//连接 Session session;//会话 接受或者发送消息的线程 Destination destination;//消息的目的地 MessageConsumer messageConsumer;//消息的消费者 //实例化连接工厂 connectionFactory = new ActiveMQConnectionFactory(JMSConsumer.USERNAME, JMSConsumer.PASSWORD, JMSConsumer.BROKEURL); try &#123; //通过连接工厂获取连接 connection = connectionFactory.createConnection(); //启动连接 connection.start(); //创建session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建一个连接HelloWorld的消息队列 destination = session.createQueue(&quot;HelloWorld&quot;); //创建消息消费者 messageConsumer = session.createConsumer(destination); while (true) &#123; TextMessage textMessage = (TextMessage) messageConsumer.receive(100000); if(textMessage != null)&#123; System.out.println(&quot;收到的消息:&quot; + textMessage.getText()); &#125;else &#123; break; &#125; &#125; &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 开启ActiveMQ服务，启动生产者，发送消息，此时在http://localhost:8161/admin/ 可查看相应的Queues内容 启动消费者，消费队列中的消息，此时在http://localhost:8161/admin/ 相应的Queues内容已被消费]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九浅一深之JMS]]></title>
    <url>%2F2017%2F09%2F%E4%B9%9D%E6%B5%85%E4%B8%80%E6%B7%B1%E4%B9%8BJMS%2F</url>
    <content type="text"><![CDATA[消息模型点对点模型概念 消息队列（Queue） 发送者(Sender) 接收者(Receiver) 每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。 特点 每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中) 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列 接收者在成功接收消息之后需向队列应答成功 如果你希望发送的每个消息都应该被成功处理的话，那么你需要P2P模式。 发布订阅模型概念 主题（Topic） 发布者（Publisher） 订阅者（Subscriber） 客户端将消息发送到主题。多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。 特点 每个消息可以有多个消费者 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。 为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。 如果你希望发送的消息可以不被做任何处理、或者被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型 消息的消费 在JMS中，消息的产生和消息是异步的。对于消费来说，JMS的消息者可以通过两种方式来消费消息。 同步订阅者或接收者调用receive方法来接收消息，receive方法在能够接收到消息之前（或超时之前）将一直阻塞 异步订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的onMessage方法。JMS编程模型 ConnectionFactory创建Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。 DestinationDestination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的Destination是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的Destination也是某个队列或主题（即消息来源）。 所以，Destination实际上就是两种类型的对象：Queue、Topic可以通过JNDI来查找Destination。 ConnectionConnection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。 SessionSession是我们操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当我们需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。 消息的生产者消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。 消息消费者消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。 MessageListener消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。 优点 提供消息灵活性 松散耦合 异步性]]></content>
      <categories>
        <category>JMS</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bug小知识]]></title>
    <url>%2F2017%2F09%2FBug%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[数据库字段类型与模型类型要一一对应 空指针验证anytime 会变动的配置数据，不应当存到数据库当中。例如，一个比赛发布地址（http://127.0.0.1/schedule/address/{scheduleId}），地址前缀是配置项，在数据库只需在比赛表设定一个状态，验证是否发布，调用时候再进行拼接即可。]]></content>
      <categories>
        <category>Bug</category>
      </categories>
      <tags>
        <tag>Bug</tag>
        <tag>小知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的5个常见使用场景]]></title>
    <url>%2F2017%2F09%2FRedis%E7%9A%845%E4%B8%AA%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。 全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。 发布/订阅]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis发布订阅]]></title>
    <url>%2F2017%2F09%2FRedis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%2F</url>
    <content type="text"><![CDATA[发布订阅(pub/sub)是一种消息通信模式，主要的目的是解耦消息发布者和消息订阅者之间的耦合，这点和设计模式中的观察者模式比较相似。pub /sub不仅仅解决发布者和订阅者直接代码级别耦合也解决两者在物理部署上的耦合。redis作为一个pub/sub server，在订阅者和发布者之间起到了消息路由的功能。订阅者可以通过subscribe和psubscribe命令向redis server订阅自己感兴趣的消息类型，redis将消息类型称为通道(channel)。当发布者通过publish命令向redis server发送特定类型的消息时。订阅该消息类型的全部client都会收到此消息。这里消息的传递是多对多的。一个client可以订阅多个 channel,也可以向多个channel发送消息。 配置文件12345678910111213141516171819202122232425262728&lt;bean id=&quot;jedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt; &lt;constructor-arg name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot;/&gt; &lt;property name=&quot;hostName&quot; value=&quot;$&#123;redis.host&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;redis.password&#125;&quot;/&gt; &lt;property name=&quot;port&quot; value=&quot;$&#123;redis.port&#125;&quot;/&gt; &lt;property name=&quot;database&quot; value=&quot;$&#123;redis.database&#125;&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;$&#123;redis.maxIdle&#125;&quot;/&gt; &lt;property name=&quot;maxTotal&quot; value=&quot;$&#123;redis.maxActive&#125;&quot;/&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;redis.testOnBorrow&#125;&quot;/&gt; &lt;property name=&quot;maxWaitMillis&quot; value=&quot;$&#123;redis.timeout&#125;&quot;/&gt; &lt;/bean&gt; &lt;bean scope=&quot;prototype&quot; id=&quot;redisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;/&gt; &lt;property name=&quot;keySerializer&quot; ref=&quot;stringRedisSerializer&quot;/&gt; &lt;property name=&quot;hashKeySerializer&quot; ref=&quot;stringRedisSerializer&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;stringRedisSerializer&quot; class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot;/&gt; &lt;bean id=&quot;redisMessageListener&quot; class=&quot;com.gengee.gsm.util.RedisMessageListener&quot;/&gt; &lt;redis:listener-container connection-factory=&quot;jedisConnectionFactory&quot;&gt; &lt;redis:listener ref=&quot;redisMessageListener&quot; topic=&quot;redisChannel&quot; /&gt; &lt;/redis:listener-container&gt; RedisMessageListener 消息监听 12345678910111213public class RedisMessageListener implements MessageListener &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RedisMessageListener.class); @Autowired private ScheduleLogMapper scheduleLogMapper; @Override public void onMessage(Message message, byte[] bytes) &#123; if (message != null &amp;&amp; !message.toString().equals(&quot;&quot;)) &#123; LOGGER.info(message.toString()); //do you job &#125; &#125;&#125; redis发布 123Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);jedis.auth(&quot;redisPassword&quot;);jedis.publish(&quot;redisChannel&quot;, &quot;publishMessage&quot;); 参考文档：http://www.cnblogs.com/yitudake/p/6747995.htmlhttp://blog.csdn.net/valenon/article/details/46414455]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA小知识]]></title>
    <url>%2F2017%2F09%2FJAVA%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[&amp;和&amp;&amp;的区别 &amp;和^,&lt;&lt;,&lt;&lt;&lt;,|同属于位运算符,其中&amp;是按位与,例如,1&amp;1=1，1&amp;0=0 &amp;&amp;是逻辑运算符,处理真假值，例如,true&amp;&amp;true=true。 mybatis中的CDATA标签的用法 在mapper文件中写sql语句时，遇到特殊字符时，如：&lt; 等，建议使用&lt;![CDATA[ sql 语句 ]]&gt;标记，将sql语句包裹住，不被解析器解析 Http跨域OPTIONS请求跨域资源共享标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站有权限访问哪些资源。另外，规范要求，对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。 OPTIONS请求报错由于预检请求（OPTIONS请求）不会包含Cookie信息（浏览器本身的实现决定其是否发送Cookie，前端无法控制，并且Chrome是不发送的），因此被权限拦截器提前结束，没有输出包含指定头部信息的响应。而一个被浏览器认为合格的预检请求响应必须包含如下的Http头部。(预检请求Options的执行顺序在拦截器之后，因此预检请求被拦截，导致出错,) 方法一：在拦截器中加响应头 1234567891011public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (request.getHeader(HttpHeaders.ORIGIN) != null) &#123; response.addHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); response.addHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;); response.addHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;POST, GET, OPTIONS, DELETE, PUT, HEAD&quot;); response.addHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type,token&quot;); response.addHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;); return true; &#125; &#125; 方法二：在mvcConfig中添加跨域设置：—–无效！待验证！12345678910111213//请求跨域@Overridepublic void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/**&quot;) .allowedOrigins(CorsConfiguration.ALL) .allowCredentials(true)//表示是否允许发送Cookie。 默认情况下，Cookie不包括在CORS请求之中。 设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。 这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可 .allowedHeaders(&quot;Content-Type&quot;, &quot;token&quot;) .allowedMethods(&quot;GET&quot;, &quot;HEAD&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;); super.addCorsMappings(registry);&#125; Tomcat报错： Note: further occurrences of HTTP header parsing errors will be logged at DEBUG level.网上是说在tomcat的server.xml文件里面的&lt;Connector&gt; 里面设定maxHttpHeaderSize属性，但是并没有效果，最后的原因是：用了https请求了本地接口，GG。。。 java作用域public ,private ,protected 及不写时的区别 对于继承自己的class，base class可以认为他们都是自己的子女，而对于和自己一个目录下的classes，认为都是自己的朋友 public：public表明该数据成员、成员函数是对所有用户开放的，所有用户都可以直接进行调用 private：private表示私有，私有的意思就是除了class自己之外，任何人都不可以直接使用，私有财产神圣不可侵犯嘛，即便是子女，朋友，都不可以使用 protected：protected对于子女、朋友来说，就是public的，可以自由使用，没有任何限制，而对于其他的外部class，protected就变成private 1234567891011作用域 当前类 同一package 子孙类 其他package public √ √ √ √ protected √ √ √ × friendly √ √ × × private √ × × × 不写时默认为friendly 图片上传耗时太久 问题描述：页面上传图片，提交后耗时8s才上传 成功，debug页面发现TTFB是主要原因，等待服务器返回的时间过长。 首先将服务器对应的ip端口开放，直接用postman调用接口，发现耗时一样很长，排除服务器nginx代理以及路由导致的原因 发现服务器带宽只有2M，下载理论峰值256k左右，上传只有128左右，1024/128=8s ，原因就是因为服务器带宽不足，导致上传时间消耗比较多 Switch能否用string做参数 在jdk 7 之前，switch 只能支持 byte、short、char、int 这几个基本数据类型和其对应的封装类型 jdk1.7后，整形，枚举类型，boolean，字符串都可以 其实jdk1.7并没有新的指令来处理switch string，而是通过调用switch中string.hashCode,将string转换为int从而进行判断 全局异常处理 使用 @ControllerAdvice + @ExceptionHandler 进行全局的 Controller 层异常处理，只要设计得当，就再也不用在 Controller 层进行 try-catch 了！而且，@Validated 校验器注解的异常，也可以一起处理，无需手动判断绑定校验结果 BindingResult/Errors 优点：将 Controller 层的异常和数据校验的异常进行统一处理，减少模板代码，减少编码量，提升扩展性和可维护性。 缺点：只能处理 Controller 层未捕获（往外抛）的异常，对于 Interceptor（拦截器）层的异常，Spring 框架层的异常，就无能为力了。 Integer 装箱 拆箱 比较 Integer与int类型的赋值 把Integer类型的赋值给int类型，调用intValue()方法进行拆箱赋值。 把int类型赋值给Integer，会调用valueOf()方法对int进行装箱赋值。 Integer与int类型的比较 先对Integer调用intValue()进行拆箱，然后进行值比较]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql小知识]]></title>
    <url>%2F2017%2F09%2FMysql%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Count(null) = 0 Sum(null) = null null + 1 = null 根据得分进行排名，分数为0 不进行排名1234567891011121314SELECT t.competition_id, t.player_id, ( SELECT CASE WHEN t.score &lt;= 0 THEN NULL ELSE COUNT(DISTINCT score) END # 当score小于等于0时，设定排名为null，否则根据where条件（t1.score &gt; t.score）count不同的score值来获取排名 FROM v_player_total_data t1 WHERE t1.competition_id = t.competition_id AND t1.score &gt; t.score ) + 1 scoreFROM v_player_total_data t ORDER BY competition_id]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql随机函数]]></title>
    <url>%2F2017%2F09%2FMySql%E9%9A%8F%E6%9C%BA%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[rand（）函数只能生成0到1之间的随机小数，如果想要生成0到10,0到100就rand（）相应的值。如果想得到整数就要用到round（x），floor（x）和ceiling（x）。round（x）是四舍五入 ； floor（x）是去小于等于x的整数； ceiling（x）是取大于等于x的整数；得到指定范围的随机数 round（rand（）（max-min）+min）即可 ROUND ROUND(X) – 表示将值 X 四舍五入为整数，无小数位 ROUND(X,D) – 表示将值 X 四舍五入为小数点后 D 位的数值，D为小数点后小数位数。若要保留 X 值小数点左边的 D 位，可将 D 设为负值。123456789101112SELECT ROUND(&apos;123.456&apos;)-----------------------------123SELECT ROUND(&apos;123.654&apos;)-----------------------------124SELECT ROUND(&apos;123.456&apos;,2)-----------------------------123.46SELECT ROUND(&apos;123.654&apos;,2)-----------------------------123.65 FLOOR FLOOR(X)表示向下取整，只返回值X的整数部分，小数部分舍弃。123456SELECT FLOOR(&apos;123.456&apos;)-----------------------------123SELECT FLOOR(&apos;123.654&apos;)-----------------------------123 CEILING CEILING(X) 表示向上取整，只返回值X的整数部分，小数部分舍弃。1234567SELECT CEILING(&apos;123.456&apos;)-----------------------------124SELECT CEILING(&apos;123.654&apos;)-----------------------------124]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[外面好吵]]></title>
    <url>%2F2017%2F09%2F%E5%A4%96%E9%9D%A2%E5%A5%BD%E5%90%B5%2F</url>
    <content type="text"><![CDATA[今天很阴。早晨模糊醒来，是阴冷的空调风。书桌上的瓶罐，一晃一晃没了重心。整个房间，没了生气。 外面好吵。轰隆隆的飞机声，掠过梦境。冷气一直吹，冰冷冷。棱角分明，生硬的拽我。摆了摆手，给我安静。]]></content>
      <categories>
        <category>大白话</category>
      </categories>
      <tags>
        <tag>大白话</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux安装多个tomcat]]></title>
    <url>%2F2017%2F09%2Flinux%E5%AE%89%E8%A3%85%E5%A4%9A%E4%B8%AAtomcat%2F</url>
    <content type="text"><![CDATA[编辑环境变量：vi /etc/profile 加入以下代码(tomcat路径要配置自己实际的tomcat安装目录) 123456789101112##########first tomcat###########CATALINA_BASE=/usr/local/tomcatCATALINA_HOME=/usr/local/tomcatTOMCAT_HOME=/usr/local/tomcatexport CATALINA_BASE CATALINA_HOME TOMCAT_HOME##########first tomcat######################second tomcat##########CATALINA_2_BASE=/usr/local/tomcat_2CATALINA_2_HOME=/usr/local/tomcat_2TOMCAT_2_HOME=/usr/local/tomcat_2export CATALINA_2_BASE CATALINA_2_HOME TOMCAT_2_HOME##########second tomcat########## 保存退出（:wq） source /etc/profile 生效 修改tomcat配置文件 第一个tomcat，保持解压后的原状不用修改, 来到第二个tomcat的bin目录下，打开catalina.sh ，找到下面红字： 1# OS specific support. $var _must_ be set to either true or false. 在下面增加如下代码 12export CATALINA_BASE=$CATALINA_2_BASEexport CATALINA_HOME=$CATALINA_2_HOME 来到第二个tomcat的conf目录下打开server.xml更改端口： 修改server.xml配置和第一个不同的启动、关闭监听端口。 修改后示例如下：123456789 &lt;Server port=&quot;9005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; 端口：8005-&gt;9005&lt;!-- Define a non-SSL HTTP/1.1 Connector on port 8080 --&gt; &lt;Connector port=&quot;8081&quot; maxHttpHeaderSize=&quot;8192&quot; 端口：8080-&gt;8081maxThreads=&quot;150&quot; minSpareThreads=&quot;25&quot; maxSpareThreads=&quot;75&quot; enableLookups=&quot;false&quot; redirectPort=&quot;8443&quot; acceptCount=&quot;100&quot; connectionTimeout=&quot;20000&quot; disableUploadTimeout=&quot;true&quot; /&gt;&lt;!-- Define an AJP 1.3 Connector on port 8009 --&gt; &lt;Connector port=&quot;9009&quot; 端口：8009-&gt;9009 enableLookups=&quot;false&quot; redirectPort=&quot;8443&quot; protocol=&quot;AJP/1.3&quot; /&gt; 分别进入两个tomcat的bin目录，启动tomcat–./startup.sh 然后访问http://localhost:8080 和 http://localhost:8081 都可以看到熟悉的tomcat欢迎界面。 如果想启动多个可以依此法类推……]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 80端口映射到8080]]></title>
    <url>%2F2017%2F08%2Flinux-80%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E5%88%B08080%2F</url>
    <content type="text"><![CDATA[有时我们在服务Linux服务器上安装了tomcat（端口号为8080），而要求是输入网址后不添加端口号就能访问，这就意味着浏览器得通过80端口访问到你的tomcat（端口为8080），为此有两种解决方式： 基于linux系统禁止1024一下的端口让非root用户使用，那么就必须是用root用户登录才能去启动修改为80端口的tomcat（注意： 直接在tomcat server.xml中更改为80，用sudo命令是启动不了的，必须要root用户登录启动！！） 基于root密码不是随随便便能得到的，所以一般采用第二种方法（即端口映射）来达到你的目的：具体命令为： 1iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080 1234-t nat : 指出我要操作什么表.(不写就表示filter.默认是filter) -A PREROUTING : A 添加的意思.表示我要在PREROUTING 中添加一个规则 --dport 80 : 如果请求80端口. --to-port 8080 : 那么就转到8080端口.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swagger文档linux部署]]></title>
    <url>%2F2017%2F08%2FSwagger%E6%96%87%E6%A1%A3linux%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[安装httpd配置httpd.conf文件 vim /etc/httpd/conf/httpd.conf 添加监听端口：Listen 6080 12345&lt;VirtualHost *:6080&gt; DocumentRoot /swagger Header set Access-Control-Allow-Origin * ServerName *.*.*.*:6080&lt;/VirtualHost&gt; 修改后需要重启httpd服务：/etc/init.d/httpd restart 放置文档文件夹 /swagger由于SELinux开启造成的Apache 2 Test Page powered by CentOS 把SELinux的状态改一下就可以：执行setenforce 0]]></content>
      <categories>
        <category>Swagger</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小知识系列：第二集]]></title>
    <url>%2F2017%2F08%2F%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97%EF%BC%9A%E7%AC%AC%E4%BA%8C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Shiro Redis JMS ActiveMQ/RabbitMQ 高并发 Maven WebSocket SpringBoot SpringCloud Docker JFinal]]></content>
      <categories>
        <category>杂烩</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>杂烩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小知识系列：第一集]]></title>
    <url>%2F2017%2F08%2F%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97%EF%BC%9A%E7%AC%AC%E4%B8%80%E9%9B%86%2F</url>
    <content type="text"><![CDATA[贫血模型—领域模型（区分）泛型JSR 303验证Lombok 去掉Setter和Getter bean的链式风格 构造静态方法 builder 代理模式理解OAuth 2.0学习列表 JAVA8 Git Maven MongoDB Shiro Redis Spring Mybatis Linux Liquibase Restful RMI Spring BootRemember Coding要考虑语义的操作，提高代码可读性 保证任何数据的入参到方法体内都合法，对于脏数据的产生一定是致命的 多回头看自己的代码 勤于重构 多看成熟的框架源码 排列组合 排列AA(n,m) = n! / (n-m)! 组合CC(n,m) = A(n,m) / m! 三角函数 远程调用(魔法隧道) 注册魔法隧道 新建一个隧道，设置本地ip以及发布端口 获取token以及隧道域名 本地下载魔法隧道exe，在命令行根据token开启隧道 网络调用本地接口]]></content>
      <categories>
        <category>杂烩</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>杂烩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 协作]]></title>
    <url>%2F2017%2F08%2FGit-%E5%8D%8F%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Fork项目到个人的仓库Clone项目到本地SSH （命令行操作） 复制ssh url在git命令行执行 git clone git@github.com:XXXXXX/你要fork的项目名12git branch -a ------查看所有分支git checkout -b dev-local origin/dev ----------创建一个dev-local分支（-b），并把远程dev分支（origin/dev）的内容放在该分支内。接着切换到该分支（checkout） HTTPS（idea等工具操作） https: //github.com/XXXXXX/你要fork的项目名.git VCS-&gt;checkout from Version controller-&gt;git-&gt;clone 后期直接idea操作， 不需要进行以下操作 push修改到自己的项目上 git add –all git fetch git commit -m ‘提交的注释’ git push 请求合并到团队项目上 点击Pull request 添加标题跟描述信息，确认提交内容 点击Create pull request进行发送合并请求]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小问题]]></title>
    <url>%2F2017%2F08%2F%E5%B0%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[bindException 1234567891011&lt;bean id=&quot;sessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:/mybatis.xml&quot;/&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.gengee.insait.c1.bean&quot;/&gt; # 引入mapper.xml文件 &lt;property name=&quot;mapperLocations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:/mapper/*.xml&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 抛出AuthenticationException，状态仍为200 1234567891011121314151617181920212223Filter应当重新实现onLoginFailure方法@Override protected boolean onLoginFailure(AuthenticationToken token, AuthenticationException e, ServletRequest request, ServletResponse response) &#123; HashMap&lt;String, String&gt; errMap = new HashMap&lt;&gt;(); errMap.put(&quot;description&quot;, e.getMessage()); errMap.put(&quot;error&quot;, &quot;invalid_equipId&quot;); try &#123; ObjectMapper objectMapper = new ObjectMapper(); String errorJson = objectMapper.writeValueAsString(errMap); HttpServletResponse httpResponse = WebUtils.toHttp(response); httpResponse.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); httpResponse.setHeader(&quot;Access-Control-Request-Method&quot;, &quot;*&quot;); httpResponse.setHeader(&quot;Access-Control-Request-Headers&quot;, &quot;*&quot;); httpResponse.setStatus(401); httpResponse.setContentType(&quot;application/json;charset=UTF-8&quot;); httpResponse.getWriter().write(errorJson); return false; &#125; catch (IOException var9) &#123; LOGGER.error(&quot;Build JSON message error&quot;, var9); throw new IllegalStateException(var9); &#125; &#125; one or more listener failed to startapp-shiro.xml应当在Spring Application配置文件中引入，而不是在Spring Mvc配置文件中引入]]></content>
      <categories>
        <category>小问题</category>
      </categories>
      <tags>
        <tag>Exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我想要说]]></title>
    <url>%2F2017%2F08%2F%E6%88%91%E6%83%B3%E8%A6%81%E8%AF%B4%2F</url>
    <content type="text"><![CDATA[小时候，你带着我虽然吃的不好，过的不好但总是没有饿着尽管你有缺点，也有不好可是我理解，我也有啊现在长大了，每次陪你聊天其实是听你叨叨我很满足，也开心的虽然每次讲的大体都一样可我知道你能记住的不多对老人还要苛求什么？老人只想要陪伴只想要心里舒坦点时间真的变了很多人但我记得你的好，也会对你好。]]></content>
      <categories>
        <category>大白话</category>
      </categories>
      <tags>
        <tag>大白话</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天晴的透透]]></title>
    <url>%2F2017%2F08%2F%E5%A4%A9%E6%99%B4%E7%9A%84%E9%80%8F%E9%80%8F%2F</url>
    <content type="text"><![CDATA[太阳不辣，天晴的透透漂了天蓝色，抹淡淡的妆幼稚的小松鼠探出头瞧了瞧，咽了口水跐溜一下，爬上龙眼树定是嘴馋了，像我一样盈满的木瓜树，缀着青翠一旁的枇杷，大半年也不结个果子妒忌着，眼羡极了别怕，再等等努努力，总会有结果的像我们一样]]></content>
      <categories>
        <category>大白话</category>
      </categories>
      <tags>
        <tag>大白话</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ajax 跨域请求]]></title>
    <url>%2F2017%2F08%2FAjax-%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[错误信息12345jquery-3.1.1.min.js:4 XMLHttpRequest cannot load http://127.0.0.1:8080/user/login.action. No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://localhost:8080&apos; is therefore not allowed access. 解决办法服务端设置支持跨域@CrossOrigin注解 即在Controller控制器中，在Controller注解上方添加@CrossOrigin注解。 12@CrossOrigin(origins = &#123;&quot;*&quot;&#125;, maxAge = 3600)public classUserController&#123;&#125; 官网：www.fhadmin.org也可以在Controller控制器中的每个方法中分别添加@CrossOrigin注解。 12@CrossOrigin(origins = &#123;&quot;*&quot;&#125;, maxAge = 3600)public String login(String username, String password)throws Exception &#123;&#125; 假如添加之后还是出现了跨域问题，需要给映射路径中配置请求方法（method） 123@RequestMapping(value = &quot;user&quot;, method = &#123;RequestMethod.POST&#125;)@CrossOrigin(origins = &#123;&quot;*&quot;&#125;, maxAge = 3600)public class UserController &#123;&#125; CORS全局配置 基于xml的配置，在springmvc.xml中配置 1234&lt;!-- 跨域请求 --&gt;&lt;mvc:cors&gt; &lt;mvc:mappingpath=&quot;/user/*&quot;/&gt;&lt;/mvc:cors&gt; 官网：www.fhadmin.org 可以进行详细的配置 12345678&lt;mvc:cors&gt; &lt;mvc:mappingpath=&quot;/api/**&quot;allowed-origins=&quot;http://domain1.com, http://domain2.com&quot;allowed-methods=&quot;GET, PUT &quot;allowed-headers=&quot;header1, header2, header3&quot; exposed-headers=&quot;header1, header2&quot; allow-credentials=&quot;false&quot;max-age=&quot;123&quot; /&gt; &lt;mvc:mappingpath=&quot;/resources/**&quot;allowed-origins=&quot;http://domain1.com&quot; /&gt;&lt;/mvc:cors&gt; 假如出现”通配符的匹配很全面, 但无法找到元素 ‘mvc:cors’ 的声明。”这样的错误解决办法： 查看文件上边beans中xsd文件引入的版本是不是不对。如下所示： http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd引入的xsd版本为3.0，而mvc:cors是4.2版本的功能。因此，只需要将xsd版本更新就行。或者设置成4.2以上的。 http://www.springframework.org/schema/mvc/spring-mvc.xsd PHP 1header(&quot;Access-Control-Allow-Origin:*&quot;); //*号表示所有域名都可以访问 JSONP实现跨域 常用的jquery实现跨域调用12345678$.ajax(&#123; url: &quot;&quot;, dataType: &quot;jsonp&quot;, jsonp: &quot;callback&quot;, success: function(data) &#123; console.log(data); &#125;&#125;); 这个调用实际上的实现原理是：在网页中构造一个script标签，将src设置为对应的url，并增加上相应的callback参数，形如如下格式：1&lt;script src=&quot;http://127.0.0.1/index?callback=jQuery211018970995225637144_1465350372062&amp;_=1465350372063&quot;&gt;&lt;/script&gt; 请求的服务端代码：12String jsoncallback=request.getParameter(&quot;callback&quot;);//指定接受参数为callbackreturn jsoncallback+&quot;([&#123;name:&apos;jsonp&apos;,age:&apos;30&apos;&#125;,&#123;name:&apos;jack&apos;,age:&apos;90&apos;&#125;])&quot;; jsonp实现的缺点jsonp实现的跨域方式不支持post请求，只能支持get请求]]></content>
      <categories>
        <category>Ajax</category>
      </categories>
      <tags>
        <tag>ajax</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro 简介]]></title>
    <url>%2F2017%2F08%2FShiro-%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[基本功能点 Authentication：身份认证/登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web支持，可以非常容易的集成到Web环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率； Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 记住一点，Shiro不会去维护用户、维护权限；这些需要我们自己去设计/提供；然后通过相应的接口注入给Shiro即可。接下来我们分别从外部和内部来看看Shiro的架构，对于一个好的框架，从外部来看应该具有非常简单易于使用的API，且API契约明确；从内部来看的话，其应该有一个可扩展的架构，即非常容易插入用户自定义实现，因为任何框架都不能满足所有需求。 外部视角 首先，我们从外部来看Shiro吧，即从应用程序角度的来观察如何使用Shiro完成工作。如下图： 可以看到：应用代码直接交互的对象是Subject，也就是说Shiro的对外API核心就是Subject；其每个API的含义： Subject：主体，代表了当前“用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是Subject，如网络爬虫，机器人等；即一个抽象概念；所有Subject都绑定到SecurityManager，与Subject的所有交互都会委托给SecurityManager；可以把Subject认为是一个门面；SecurityManager才是实际的执行者； SecurityManager：安全管理器；即所有与安全有关的操作都会与SecurityManager交互；且它管理着所有Subject；可以看出它是Shiro的核心，它负责与后边介绍的其他组件进行交互，如果学习过SpringMVC，你可以把它看成DispatcherServlet前端控制器； Realm：域，Shiro从从Realm获取安全数据（如用户、角色、权限），就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法；也需要从Realm得到用户相应的角色/权限进行验证用户是否能进行操作；可以把Realm看成DataSource，即安全数据源。 也就是说对于我们而言，最简单的一个Shiro应用： 应用代码通过Subject来进行认证和授权，而Subject又委托给SecurityManager； 我们需要给Shiro的SecurityManager注入Realm，从而让SecurityManager能得到合法的用户及其权限进行判断。 从以上也可以看出，Shiro不提供维护用户/权限，而是通过Realm让开发人员自己注入。 内部视角接下来我们来从Shiro内部来看下Shiro的架构，如下图所示： s Subject：主体，可以看到主体可以是任何可以与应用交互的“用户”； SecurityManager：相当于SpringMVC中的DispatcherServlet或者Struts2中的FilterDispatcher；是Shiro的心脏；所有具体的交互都通过SecurityManager进行控制；它管理着所有Subject、且负责进行认证和授权、及会话、缓存的管理。 Authenticator：认证器，负责主体认证的，这是一个扩展点，如果用户觉得Shiro默认的不好，可以自定义实现；其需要认证策略（Authentication Strategy），即什么情况下算用户认证通过了； Authrizer：授权器，或者访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能； Realm：可以有1个或多个Realm，可以认为是安全实体数据源，即用于获取安全实体的；可以是JDBC实现，也可以是LDAP实现，或者内存实现等等；由用户提供；注意：Shiro不知道你的用户/权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的Realm； SessionManager：如果写过Servlet就应该知道Session的概念，Session呢需要有人去管理它的生命周期，这个组件就是SessionManager；而Shiro并不仅仅可以用在Web环境，也可以用在如普通的JavaSE环境、EJB等环境；所有呢，Shiro就抽象了一个自己的Session来管理主体与应用之间交互的数据；这样的话，比如我们在Web环境用，刚开始是一台Web服务器；接着又上了台EJB服务器；这时想把两台服务器的会话数据放到一个地方，这个时候就可以实现自己的分布式会话（如把数据放到Memcached服务器）； SessionDAO：DAO大家都用过，数据访问对象，用于会话的CRUD，比如我们想把Session保存到数据库，那么可以实现自己的SessionDAO，通过如JDBC写到数据库；比如想把Session放到Memcached中，可以实现自己的Memcached SessionDAO；另外SessionDAO中可以使用Cache进行缓存，以提高性能； CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据基本上很少去改变，放到缓存中后可以提高访问的性能 Cryptography：密码模块，Shiro提高了一些常见的加密组件用于如密码加密/解密的。]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RMI框架搭建]]></title>
    <url>%2F2017%2F08%2FRMI%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[创建子模块一个作为公有接口模块（Common），一个作为接口实现模块（Component），一个作为引用接口模块（ApiCenter）Component 引入Common 去实现接口方法ApiCenter 引入Common 去调用接口方法 公有模块123&lt;artifactId&gt;Common&lt;/artifactId&gt;&lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 只需要创建接口文件即可，配置文件resource以及webapp都可以删除 接口实现模块12&lt;artifactId&gt;Component&lt;/artifactId&gt;&lt;packaging&gt;war&lt;/packaging&gt; 在接口实现模块的pom.xml，需要引入对接口模块的依赖12345&lt;dependency&gt; &lt;groupId&gt;**********&lt;/groupId&gt; &lt;artifactId&gt;Common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 新建接口实现类BaseService（自动扫描）1234567@Servicepublic class BaseService implements CommonInterface &#123; public String getName() &#123; return &quot;success&quot;; &#125;&#125; Spring Mvc配置文件中引入rmi配置文件（新建rmi配置文件）1234567891011 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; # 此时这个/baseService即为之后调用接口的方法 &lt;bean name=&quot;/baseService&quot; class=&quot;org.springframework.remoting.httpinvoker.HttpInvokerServiceExporter&quot;&gt; &lt;property name=&quot;service&quot; ref=&quot;baseService&quot;/&gt; &lt;property name=&quot;serviceInterface&quot; value=&quot;***.***.***.CommonInterface&quot;/&gt;#指的是Common模块的接口 &lt;/bean&gt;&lt;/beans&gt; 引用接口模块12&lt;artifactId&gt;ApiCenter&lt;/artifactId&gt;&lt;packaging&gt;war&lt;/packaging&gt; 在接口实现模块的pom.xml，需要引入对接口模块的依赖12345&lt;dependency&gt; &lt;groupId&gt;**********&lt;/groupId&gt; &lt;artifactId&gt;Common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Spring Mvc配置文件中引入rmi配置文件（新建rmi配置文件）12345678910 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;baseService&quot; class=&quot;org.springframework.remoting.httpinvoker.HttpInvokerProxyFactoryBean&quot;&gt; &lt;property name=&quot;serviceInterface&quot; value=&quot;***.***.***.CommonInterface&quot;/&gt; &lt;property name=&quot;serviceUrl&quot; value=&quot;$&#123;rmi.server.host&#125;/baseService&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; rmi.server.host应当配置在配置文件里头123# RMI 远程调用服务接口rmi.server.host=http://127.0.0.1:8083/Component# Component模块war包部署在tomcat8083端口 调用接口方法：1234567891011121314@Autowiredprivate CommonInterface commonService;/** * 获取商品列表 * * @param idleResModel * @return */@GetMapping(&quot;/list&quot;)public Map&lt;String, Object&gt; getIdleList(@Valid IdleResModel idleResModel) &#123; Map&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put(&quot;test&quot;, commonService.getName()); return resultMap;&#125;]]></content>
      <categories>
        <category>RMI</category>
      </categories>
      <tags>
        <tag>搭建</tag>
        <tag>RMI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Tag]]></title>
    <url>%2F2017%2F08%2FGit-Tag%2F</url>
    <content type="text"><![CDATA[tag我们可以创建一个tag来指向软件开发中的一个关键时期，比如版本号更新的时候可以建一个“v2.0”、“v3.1”之类的标签，这样在以后回顾的时候会比较方便。tag的使用很简单，主要操作有：查看tag、创建tag、验证tag以及共享tag。 查看tag列出所有tag： git tag 这样列出的tag是按字母排序的，和创建时间没关系。如果只是想查看某些tag的话，可以加限定： git tag -l v1.* 这样就只会列出1.几的版本。 创建tag创建轻量级tag： git tag v1.0 这样创建的tag没有附带其他信息，与之相应的是带信息的tag： git tag -a v1.0-m “first version” -m后面带的就是注释信息，这样在日后查看的时候会很有用，这种是普通tag，还有一种有签名的tag： git tag -s v1.0-m “first version” 前提是你有GPG私钥，把上面的a换成s就行了。除了可以为当前的进度添加tag，我们还可以为以前的commit添加tag： 首先查看以前的commitgit log –oneline假如有这样一个commit：8a5cbc2 updated readme这样为他添加taggit tag -a v1.18a5cbc2 删除tag很简单，知道tag名称后： git tag -d v1.0 验证tag如果你有GPG私钥的话就可以验证tag： git tag -v v1.0 共享tag我们在执行git push的时候，tag是不会上传到服务器的，比如现在的github，创建tag后git push，在github网页上是看不到tag的，为了共享这些tag，你必须这样：（在idea直接执行提交设置的tag）git push origin –tags]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛云图片上传]]></title>
    <url>%2F2017%2F08%2F%E4%B8%83%E7%89%9B%E4%BA%91%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[注册注册一个七牛账号，注册链接：点击注册 ，注册成功之后最好实名认证一下，每个月的流量以及空间的容量会增加很多。 新建空间新建一个空间，记下空间名称（bucketName）。在账号里找到密钥：AK，SK。后面开发中会用到这些。 引入依赖使用maven管理，自动下载对应jar包12345678910&lt;dependency&gt; &lt;groupId&gt;com.qiniu&lt;/groupId&gt; &lt;artifactId&gt;pili-sdk-java&lt;/artifactId&gt; &lt;version&gt;1.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.qiniu&lt;/groupId&gt; &lt;artifactId&gt;qiniu-java-sdk&lt;/artifactId&gt; &lt;version&gt;7.1.3&lt;/version&gt;&lt;/dependency&gt; 编编编编编编码初始化七牛配置文件在配置文件中加入七牛配置123456#--------七牛配置qiniu.access.key=你的AKqiniu.secret.key=你的SKqiniu.bucket.name=你的bucketNameqiniu.bucket.host.name=你的外链默认域名#--------七牛配置 文件上传接口12345678910111213141516171819202122232425public interface UploadUtil &#123;String uploadFile(MultipartFile multipartFile) throws UploadException; String uploadFile(String filePath, MultipartFile multipartFile) throws UploadException; String uploadFile(MultipartFile multipartFile, String fileName) throws UploadException; String uploadFile(MultipartFile multipartFile, String fileName, String filePath) throws UploadException; String uploadFile(File file) throws UploadException; String uploadFile(String filePath, File file) throws UploadException; String uploadFile(File file, String fileName) throws UploadException; String uploadFile(File file, String fileName, String filePath) throws UploadException; String uploadFile(byte[] data) throws UploadException; String uploadFile(String filePath, byte[] data) throws UploadException; String uploadFile(byte[] data, String fileName) throws UploadException; String uploadFile(byte[] data, String fileName, String filePath) throws UploadException;&#125; 文件上传接口实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256public class QiniuUtil implements UploadUtil &#123; private final Logger LOGGER = LoggerFactory.getLogger(this.getClass()); private String bucketHostName; private String bucketName; private Auth auth; private UploadManager uploadManager = new UploadManager(); /** * 构造函数 * * @param bucketHostName 七牛域名 * @param bucketName 七牛空间名 * @param auth 七牛授权 */ public QiniuUtil(String bucketHostName, String bucketName, Auth auth) &#123; this.bucketHostName = bucketHostName; this.bucketName = bucketName; this.auth = auth; &#125; public String generate()&#123; return this.generateToken(); &#125; /** * 根据spring mvc 文件接口上传 * * @param multipartFile spring mvc 文件接口 * @return 文件路径 * @throws IOException */ @Override public String uploadFile(MultipartFile multipartFile) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(bytes); &#125; /** * 根据spring mvc 文件接口上传 * * @param filePath 文件前缀,例如:/test或者/test/ * @param multipartFile spring mvc 文件接口 * @return 文件路径 * @throws IOException */ @Override public String uploadFile(String filePath, MultipartFile multipartFile) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(filePath, bytes); &#125; /** * 根据spring mvc 文件接口上传 * * @param multipartFile spring mvc 文件接口 * @param fileName 文件名 * @return 文件路径 * @throws IOException */ @Override public String uploadFile(MultipartFile multipartFile, String fileName) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(bytes, fileName); &#125; /** * 根据spring mvc 文件接口上传 * * @param multipartFile spring mvc 文件接口 * @param fileName 文件名 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws IOException */ @Override public String uploadFile(MultipartFile multipartFile, String fileName, String filePath) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(bytes, fileName, filePath); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(File file) throws UploadException &#123; return this.uploadFile(file, null, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(String filePath, File file) throws UploadException &#123; return this.uploadFile(file, null, filePath); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @param fileName 文件名 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(File file, String fileName) throws UploadException &#123; return this.uploadFile(file, fileName, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @param fileName 文件名 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(File file, String fileName, String filePath) throws UploadException &#123; String key = preHandle(fileName, filePath); Response response = null; try &#123; response = this.uploadManager.put(file, key, this.generateToken()); &#125; catch (QiniuException e) &#123; LOGGER.warn(&quot;QiniuException:&quot;, e); throw new UploadException(e.getMessage()); &#125; return this.getUrlPath(response); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(byte[] data) throws UploadException &#123; return this.uploadFile(data, null, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(String filePath, byte[] data) throws UploadException &#123; return this.uploadFile(data, null, filePath); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @param fileName 文件名 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(byte[] data, String fileName) throws UploadException &#123; return this.uploadFile(data, fileName, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @param fileName 文件名 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(byte[] data, String fileName, String filePath) throws UploadException &#123; String key = preHandle(fileName, filePath); Response response; try &#123; response = this.uploadManager.put(data, key, generateToken()); &#125; catch (QiniuException e) &#123; LOGGER.error(&quot;QiniuException:&quot;, e); throw new UploadException(e.getMessage()); &#125; return this.getUrlPath(response); &#125; private byte[] getBytesWithMultipartFile(MultipartFile multipartFile) &#123; try &#123; return multipartFile.getBytes(); &#125; catch (IOException e) &#123; e.printStackTrace(); return null; &#125; &#125; private String preHandle(String fileName, String filePath) throws UploadException &#123; if (StringUtils.isNotBlank(fileName) &amp;&amp; !fileName.contains(&quot;.&quot;)) &#123; throw new UploadException(&quot;文件名必须包含尾缀&quot;); &#125; if (StringUtils.isNotBlank(filePath) &amp;&amp; !filePath.startsWith(&quot;/&quot;)) &#123; throw new UploadException(&quot;前缀必须以&apos;/&apos;开头&quot;); &#125; String name = StringUtils.isBlank(fileName) ? RandomStringUtils.randomAlphanumeric(32) : fileName; if (StringUtils.isBlank(filePath)) &#123; return name; &#125; String prefix = filePath.replaceFirst(&quot;/&quot;, &quot;&quot;); return (prefix.endsWith(&quot;/&quot;) ? prefix : prefix.concat(&quot;/&quot;)).concat(name); &#125; private String generateToken() &#123; return this.auth.uploadToken(bucketName); &#125; private String getUrlPath(Response response) throws UploadException &#123; if (!response.isOK()) &#123; throw new UploadException(&quot;文件上传失败&quot;); &#125; DefaultPutRet defaultPutRet; try &#123; defaultPutRet = response.jsonToObject(DefaultPutRet.class); &#125; catch (QiniuException e) &#123; LOGGER.warn(&quot;QiniuException&quot;, e); throw new UploadException(e.getMessage()); &#125; String key = defaultPutRet.key; if (key.startsWith(bucketHostName)) &#123; return key; &#125; return bucketHostName + (key.startsWith(&quot;/&quot;) ? key : &quot;/&quot; + key); &#125;&#125; 接口实例化12345678public class UploadFactory &#123; public static UploadUtil createUpload(String accessKey, String secretKeySpec, String bucketHostName, String bucketName) &#123; Auth auth = Auth.create(accessKey, secretKeySpec); return new QiniuUtil(bucketHostName, bucketName, auth); &#125;&#125; 传上你的小黄图12345678910111213141516171819202122@Servicepublic class UploadService extends BaseService &#123; //引入第一步的七牛配置 @Value(&quot;$&#123;qiniu.access.key&#125;&quot;) private String accesskey; @Value(&quot;$&#123;qiniu.secret.key&#125;&quot;) private String secretKey; @Value(&quot;$&#123;qiniu.bucket.name&#125;&quot;) private String bucketName; @Value(&quot;$&#123;qiniu.bucket.host.name&#125;&quot;) private String bucketHostName; public String uploadImage(MultipartFile image) throws UploadException &#123; UploadUtil uploadUtil = UploadFactory.createUpload(this.accesskey, this.secretKey, this.bucketHostName, this.bucketName); return uploadUtil.uploadFile(&quot;/filePath/&quot;, image); &#125;&#125; 简不简单？惊不惊喜？意不意外？开不开心？]]></content>
      <categories>
        <category>七牛</category>
      </categories>
      <tags>
        <tag>七牛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC 视图解析出错]]></title>
    <url>%2F2017%2F07%2FSpringMVC-%E8%A7%86%E5%9B%BE%E8%A7%A3%E6%9E%90%E5%87%BA%E9%94%99%2F</url>
    <content type="text"><![CDATA[当没有在配置文件中配置&lt;mvc:annotation-driven/&gt;,程序执行没有出现问题，但是postman会报如下图的问题： 总结如果没有&lt;mvc:annotation-driven/&gt;，那么所有的Controller可能就没有解析，所有当有请求时候都没有匹配的处理请求类，就都去&lt;mvc:default-servlet-handler/&gt;即default servlet处理了。添加上&lt;mvc:annotation-driven/&gt;后，相应的do请求被Controller处理。总之没有相应的Controller就会被default servlet处理。所以要使用spring mvc中的@Controller注解就必须要配置&lt;mvc:annotation-driven /&gt;否则org.springframework.web.servlet.DispatcherServlet无法找到控制器并把请求分发到控制器]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[孤独的一个人想着热闹]]></title>
    <url>%2F2017%2F07%2F%E5%AD%A4%E7%8B%AC%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BA%BA%E6%83%B3%E7%9D%80%E7%83%AD%E9%97%B9%2F</url>
    <content type="text"><![CDATA[昨夜，吹冷风有人叹息在灯下，在车里，在路上排成曲折一列谁会在意往心里，来这里路灯，一闪一闪闪了困惑，避开刻意拐进眼角，那左转路口一滴泪，送行热闹的夜，降下来了]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用MyBatis Generator自动创建代码]]></title>
    <url>%2F2017%2F07%2F%E4%BD%BF%E7%94%A8MyBatis-Generator%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[由于MyBatis属于一种半自动的ORM框架，所以主要的工作就是配置Mapping映射文件，但是由于手写映射文件很容易出错，所以可利用MyBatis生成器自动生成实体类、DAO接口和Mapping映射文件。这样可以省去很多的功夫，将生成的代码copy到项目工程中即可 上图文件下载地址：http://download.csdn.net/detail/u012909091/7206091 其中有mybatis框架的jar包，数据库驱动程序jar包以及MyBatis生成器jar包。其中的generatorConfig.xml是需要我们来配置的文件，配置如下： 当以上这些完成之后，只需要打开控制台，进入lib目录下，执行脚本：Java -jar mybatis-generator-core-1.3.2.jar -configfile generatorConfig.xml -overwrite即可。 这样在生成之后，就可以在src目录下找到相应的文件夹，每个表格都会对应三个文件：实体类、接口、配置文件 转载要注明出处：谢谢shu_lin]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swagger 炫酷上手]]></title>
    <url>%2F2017%2F07%2FSwagger-%E7%82%AB%E9%85%B7%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[描述API接口文档（OpenAPI规范） 一个例子 #之后为我的备注 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115swagger: &quot;2.0&quot; # OpenAPI规范的版本号info: # 文档描述信息 version: v1.0.0 title: 标题 description: 这个文档的描述schemes: # API的URL - httphost: 127.0.0.1:8080basePath: /MyTestpaths: # API的操作###########API开始################## /player/compare/&#123;playerId&#125;: # http://127.0.0.1:8080/MyTest//player/compare/&#123;playerId&#125;----进行调用api get: tags: # 这个api的标签分类 - player description: 获取球员场均数据 parameters: - in: path # 路径参数（api的url要带上，名称要一致） name: playerId description: 球员id required: true type: string - in: query name: gender description: 性别 required: false type: string enum:# 枚举 - F - M - in: query # 请求参数 name: competitionId description: 赛事id required: false type: string # 此外还有一个消息体参数(in: body) # 引入分页参数，下方的parameters定义 - $ref: &quot;#/parameters/pageSize&quot; - $ref: &quot;#/parameters/page&quot; responses:# 响应 200: # 响应类型（HTTP状态码） description: 请求成功 schema: # 响应内容 type: object # 对象类型 properties: totalCount: type: integer description: 统计数据数量 playerData: type: array# 数组类型 description: 统计数据总和 items: type: object description: 球员统计数据模型 $ref: &apos;#/definitions/PlayerDataModel&apos; 500: # 下文responses定义 $ref: &quot;#/responses/Standard500ErrorResponse&quot; 404: # 下文responses定义 $ref: &quot;#/responses/Standard404ErrorResponse&quot; security: # 安全验证 - access_token: []##############API结束#################securityDefinitions: access_token: type: apiKey name: Authorization in: header definitions: # 自定义模型 Error: required: - code - message properties: code: type: string message: type: string PlayerDataModel: properties: teamId: type: string description: 球队id playerId: type: string description: 球员id playerName: type: string description: 球员名称responses: # 自定义响应模型 Standard500ErrorResponse: description: 请求失败 schema: $ref: &quot;#/definitions/Error&quot; Standard404ErrorResponse: description: 页面不存在parameters: # 自定义参数模型 pageSize: name: pageSize in: query description: 每页大小 type: integer format: int32 required: false page: in: query name: page description: 页码 type: integer format: int32 required: false 详细解释传送门]]></content>
      <categories>
        <category>Swagger</category>
      </categories>
      <tags>
        <tag>Swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个痴]]></title>
    <url>%2F2017%2F07%2F%E4%B8%80%E4%B8%AA%E7%97%B4%2F</url>
    <content type="text"><![CDATA[谁的一抹笑，泛滥在西边的彩霞里，荡开了归鸟的群喧！半扬的嘴角，醉人的笑，依洄在彩虹似的梦？任凭晚风吹尽黄昏的徘徊；任凭孤雁掠走夕阳的彷徨。户外的昏黄已然凝聚成夜的乌黑。她的温存，我的迷醉。假若、不能用沉默，来回复长夜的慰安，我宁愿…独自呐喊，看星斗纵横。枉然？我不是盲目，我只是痴。]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我愿意]]></title>
    <url>%2F2017%2F07%2F%E6%88%91%E6%84%BF%E6%84%8F%2F</url>
    <content type="text"><![CDATA[我愿意是只小鸟 栖息在你木屋房的树林里 纵然飞不到那片天空 我也会尽力向你飞去 我愿意是条小溪 流淌在你树林间的水流里 纵然淌不过那片海洋 我也会全力向你奔去 我愿意是朵小花 开放在水流边的泥土地里 纵然走不进那片土地 我也会尽力向你绽放出所有的美丽 我愿意 我愿意 飞翔在你的记忆里 流淌在你的记忆里 芬芳在你呼吸的每一寸空气里 ——只是为你 我愿意]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蛤蟆]]></title>
    <url>%2F2017%2F07%2F%E8%9B%A4%E8%9F%86%2F</url>
    <content type="text"><![CDATA[一缕又一缕轻烟似的雨隆重的奏歌又有天空的绚彩莫以为这烂漫的旋律能绕出万般的喝彩妄想这烦躁的枯闷抵过夏日骄阳的絢烂一如既往的细细绵绵在雨中奔跑溅开的泥泞荡走了微尘微微的一阵涟漪波折又起伏那咧嘴的蛤蟆看着，笑开了花]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你]]></title>
    <url>%2F2017%2F07%2F%E4%BD%A0%2F</url>
    <content type="text"><![CDATA[拂人的凉意透过秋风的层层阻挠扎破了我裹实的心防贴近胸膛，就要刺穿我的心扉渗进肌肤，就要颤抖我的躯干你像希望奔赴而来像阳光，照在胸口，散开醉人的暖像月光，绕在指尖，缠了岁月温柔像星光，缀在心头，闪着斑斓的梦不畏严寒，你在左右你在心里，我身不由己遇上你，定是上天厚重的恩赐]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我在这里，你找去哪里？]]></title>
    <url>%2F2017%2F07%2F%E6%88%91%E5%9C%A8%E8%BF%99%E9%87%8C%EF%BC%8C%E4%BD%A0%E6%89%BE%E5%8E%BB%E5%93%AA%E9%87%8C%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[飘渺的云端，漫步的流云，翻滚的思念汇成闪电，仿佛被指使，轰隆隆粘上了我的发梢，带着你梦里幽香你在淡淡青草地，轻盈、雀跃的笑从白昼，到黑夜，半刻也不歇寻找，灯火阑珊几束微火缘由是星火斑斓的春日的沐浴给不了远足的马力我在身旁，紧紧跟随连我火辣辣的心，全给你可你现在，又要找去哪里？我在这里，就在这里你找去哪里？我凝望，你能凝望我凝望的影子？]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从前慢]]></title>
    <url>%2F2017%2F07%2F%E4%BB%8E%E5%89%8D%E6%85%A2%2F</url>
    <content type="text"><![CDATA[记得早先少年时 大家诚诚恳恳 说一句是一句 清早上火车站 长街黑暗无行人 卖豆浆的小店冒着热气 从前的日色变得慢 车、马、邮件都慢 一生只够爱一个人 从前的锁也好看 钥匙精美有样子 你锁了，人家就懂了]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hexo搭建博客流程]]></title>
    <url>%2F2017%2F07%2F%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[首先声明，本教程所针对的是windows用户。 安装Git下载并安装git，如果你想了解点Git的基础命令，我推荐以下博文：Git常用的基础命令，史上最全github使用方法：github入门到精通,当然即使你不懂Git的命令，跟着本博文走，也完全没问题。 安装Node.js下载并安装Node.js，此处建议不要下载最新的v6开头的版本，否则每次执行hexo命令都会有提示，建议使用v5开头的版本，Node.js主要用于安装hexo，npm开头的命令都依赖于Node.js，此处我建议安装完毕后重启电脑，因为我当初安装完没重启，结果后面使用命令安装hexo的时候，提示无效的命令，因此推荐重启。当然，你也可以选择等到后面遇到问题，再选择重启。如果出现以下提示则代表你的Node.js没有安装或者还未生效，如果已经安装了则重启电脑，如果没安装则安装再重启电脑。 安装hexo安装前先介绍几个hexo常用的命令,#后面为注释。 $ hexo g #完整命令为hexo generate，用于生成静态文件 $ hexo s #完整命令为hexo server，用于启动服务器，主要用来本地预览 $ hexo d #完整命令为hexo deploy，用于将本地文件发布到github上 $ hexo n #完整命令为hexo new，用于新建一篇文章 鼠标右键任意地方，选择Git Bash，使用以下命令安装hexo（ps：以下命令中的$符号只为了让教程和实际看起来一致，实际输入命令只需输入$ 后面的命令即可） $ npm install hexo-cli -g 如果之后在使用的过程中，遇到以下的错误 ERROR Deployer not found : github 则运行以下命令,或者你直接先运行这个命令更好。 $ npm install hexo-deployer-git –save 接下来创建放置博客文件的文件夹：hexo文件夹。在自己想要的位置创建文件夹，如我hexo文件夹的位置为E:\hexo，名字和地方可以自由选择，当然最好不要放在中文路径下，至于原因，我想很多人懂得。之后进入文件夹，即E:\hexo内，点击鼠标右键，选择Git Bash，执行以下命令，Hexo会自动在该文件夹下下载搭建网站所需的所有文件。 $ hexo init 安装依赖包 $ npm install 让我们看看刚刚下载的hexo文件带来了什么，在E:\hexo内执行以下命令， $ hexo g $ hexo s 然后用浏览器访问http://localhost:4000/，此时，你应该看到了一个漂亮的博客了，当然这个博客只是在本地的，别人是看不到的，hexo3.0使用的默认主题是landscape。轻轻松松就看到了一点成果，是不是很激动，这就是hexo的强大之处，这个本地预览的功能，我真是爱不释手。 hexo的配置文件详细参照 hexo里面有两个常用到的配置文件，分别是整个博客的配置文件E:\hexo_config.yml和主题的配置文件E:\hexo\themes\light_config.yml，此地址是对于我来说，hexo3.0使用的默认主题是landscape，因此你们的地址应该是E:\hexo\themes\landscape_config.yml，下文所有讲到light的地方，你们将之换为自己的主题名即可。本博客使用的主题是基于light改善的主题，目前还在完善中，如果完成的比较好，以后可能发布在github上。如果你想自己挑选喜欢的主题，hexo官方提供了12个主题供你自己选择，使用方法很简单，点击自己想要的主题，进入该主题的Repository，使用Git将主题clone到本地，然后将整个文件夹复制到E:\hexo\themes文件夹下，将E”\hexo_config.yml里的theme名字改为自己下载的主题的文件夹名即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# Hexo Configuration## Docs: http://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Site 这下面的几项配置都很简单，你看我的博客就知道分别是什么意思title: Chillax blog #博客名subtitle: Goals determine what you are going to be #副标题description: Goals determine what you are going to be #用于搜索，没有直观表现author: huangjunhui #作者language: zh-CN #语言timezone: #时区，此处不填写，hexo会以你目前电脑的时区为默认值# URL 暂不配置，使用默认值## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://opiece.me #域名root: /permalink: :year/:month/:day/:title/permalink_defaults:# Directory 暂不配置，使用默认值source_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writing 文章布局等，使用默认值new_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true tab_replace:# Category &amp; Tag 暂不配置，使用默认值default_category: uncategorizedcategory_map:tag_map:# Date / Time format 时间格式，使用默认值## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination ## Set per_page to 0 to disable paginationper_page: 10 #每页显示的文章数，0表示不分页pagination_dir: page# Extensions 插件配置，暂时不配置## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/plugins:- hexo-generator-feedtheme: light #使用的主题，即：E:\myblog\themes文件夹下的主题文件夹名feed: #之后配置rss会用，使用如下配置即可 type: atom path: atom.xml limit: 20 # Deployment 用于部署到github，之前已经配置过## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repository: http://github.com/huangjunhui/huangjunhui.github.io.git branch: master 按照自己的意愿修改完后，执行hexo g，hexo s，打开localhost:4000看看效果。E:\hexo\themes\light_config.yml，此处针对Concise主题，如果使用其他主题，请查看自己主题的帮助文档，NexT主题帮助文档 12345678910111213141516171819202122232425262728293031323334353637menu: #博客右上角的菜单栏，暂时使用默认值 首页: / 归档: /archives 关于: /about #该类对应于E:\hexo\themes\light\layout\_widget下的文件widgets: #站点右边栏，可以参照我的博客看，暂时使用默认值- intro #简介- search #搜索- category #分类- tagcloud #标签云- weibo #微博- blogroll #友情链接excerpt_link: Read more #文章下的Read more，可以改为&apos;阅读全文&apos;plugins: #插件，暂时使用默认值twitter: #twitter username: show_replies: false tweet_count: 5addthis: #SNS分享，暂时使用默认 enable: true pubid: facebook: true twitter: true google: true pinterest: truefancybox: true #图片效果，使用默认值google_analytics: rss: #生成RSS，暂时使用默认值 注册Github帐号已经有Github帐号跳过此步，首先进入Github进行注册，用户名、邮箱和密码之后都需要用到，自己记好。 创建repository百度 部署本地文件到github既然Repository已经创建了，当然是先把博客放到Github上去看看效果。编辑E：\hexo下的_config.yml文件，建议使用Notepad++(Sublime 也可以哈哈哈)。 在_config.yml最下方，添加如下配置(命令中的第一个huangjunhui为Github的用户名,第二个huangjunhui为之前New的Repository的名字,记得改成自己的。另外记得一点，hexo的配置文件中任何’:’后面都是带一个空格的),如果配置以下命令出现ERROR Deployer not found : github，则参考上文的解决方法。 1234deploy: type: git repository: http://github.com/huangjunhui/huangjunhui.github.io.git branch: master 配置好_config.yml并保存后，执行以下命令部署到Github上。如果你是第一次使用Github或者是已经使用过，但没有配置过SSH，则可能需要配置一下，另一种发布到github的配置走原文（我弄的时候没有使用到这一步骤）。 12$ hexo g$ hexo d 执行上面的第二个命令，可能会要你输入用户名和密码，皆为注册Github时的数据，输入密码是不显示任何东西的，输入完毕回车即可。此时，我们的博客已经搭建起来，并发布到Github上了，这时可以登陆自己的Github查看代码是否已经推送到对应Repository，在浏览器访问huangjunhui.github.io就能看到自己的博客了。第一次访问地址，可能访问不了，您可以在几分钟后进行访问，一般不超过10分钟。 发表一篇文章 在Git Bash执行命令：$ hexo new “my new post” 在E:\hexo\source_post中打开my-new-post.md，打开方式使用记事本或notepad++。hexo中写文章使用的是Markdown，没接触过的可以看下Markdown语法说明,一分钟学会Markdown 1234567title: my new post #可以改成中文的，如“新文章”date: 2015-04-08 22:56:29 #发表日期，一般不改动categories: blog #文章文类tags: [博客，文章] #文章标签，多于一项时用这种格式，只有一项时使用tags: blog---#这里是正文，用markdown写，你可以选择写一段显示在首页的简介后，加上&lt;!--more--&gt;#在&lt;!--more--&gt;之前的内容会显示在首页，之后的内容会被隐藏，当游客点击Read more才能看到。 写完文章后，你可以使用1.$ hexo g生成静态文件。2.$ hexo s在本地预览效果。3.hexo d同步到github，然后使用http://你的项目名.github.io进行访问。 12------hexo new page tags 新建标签------hexo new page categories 新建分类 清除缓存清除缓存文件db.json和已生成的静态文件public。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 1$ hexo clean 转载要注明出处：谢谢JoonWhee]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>搭建</tag>
        <tag>博客</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无关风月]]></title>
    <url>%2F2017%2F07%2F%E6%97%A0%E5%85%B3%E9%A3%8E%E6%9C%88%2F</url>
    <content type="text"><![CDATA[风的哭诉在野的其中偶尔会有稀疏的来客走了一遭超脱自然的宁静这静谧的夜要宣誓什么？你给不了万众瞩目的喧嚣，那你就别打扰这我这独处思虑的安静我的爱不是风景你何必在这里流连忘返我的爱不是风景不需要你在这到处留情我的爱不是风景爱是无关风月]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
</search>
