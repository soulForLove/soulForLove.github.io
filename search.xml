<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis缓存淘汰策略]]></title>
    <url>%2F2019%2F04%2FRedis%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[常用的淘汰算法 FIFO：First In First Out，先进先出。判断被存储的时间，离目前最远的数据优先被淘汰。 LRU：Least Recently Used，最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。 LFU：Least Frequently Used，最不经常使用。在一段时间内，数据被使用次数最少的，优先被淘汰。 Redis提供的淘汰策略： noeviction：达到内存限额后返回错误，客户尝试可以导致更多内存使用的命令（大部分写命令，但DEL和一些例外） allkeys-lru：为了给新增加的数据腾出空间，驱逐键先试图移除一部分最近使用较少的（LRC）。 volatile-lru：为了给新增加的数据腾出空间，驱逐键先试图移除一部分最近使用较少的（LRC），但只限于过期设置键。 allkeys-random: 为了给新增加的数据腾出空间，驱逐任意键 volatile-random: 为了给新增加的数据腾出空间，驱逐任意键，但只限于有过期设置的驱逐键。 volatile-ttl: 为了给新增加的数据腾出空间，驱逐键只有秘钥过期设置，并且首先尝试缩短存活时间的驱逐键]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis中keys与scan特点]]></title>
    <url>%2F2019%2F04%2FRedis%E4%B8%ADkeys%E4%B8%8Escan%E7%89%B9%E7%82%B9%2F</url>
    <content type="text"><![CDATA[keys缺点 没有offset、limit参数，不能限制查询个数 keys是遍历算法，复杂度O(n)，数据量大的时候会导致redis卡顿 scan 复杂度O(n)，但是scan是通过游标分步进行，不阻塞 提供limit，可控制返回结果数 同keys一样，提供模式匹配 服务器不需要为游标保存状态，唯一状态是scan返回客户端的游标整数 返回结果可能重复，需要客户端去重 如果遍历过程中有数据修改，改动后的数据不保证同步 单次返回结果是空的，不表示遍历结束，而要看返回的游标值是否为0]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：阻塞队列]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[在阻塞队列中，线程阻塞有这样的两种情况： 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。 阻塞队列的主要方法 方法类型 抛出异常 特殊值 阻塞 超时 插入 add(e) offer(e) put(e) offer(e,time,unit) 移除 remove() poll() take() poll(time,unit) 检查 element() peek() 不可用 不可用 抛出异常：抛出一个异常 特殊值：返回一个特殊值（null 或 false,视情况而定） 阻塞：在成功操作之前，一直阻塞线程 超时：放弃前只在最大的时间内阻塞 插入操作 public abstract boolean add(E paramE)：将指定元素插入此队列中（如果立即可行且不会违反容量限制），成功时返回 true，如果当前没有可用的空间，则抛出IllegalStateException。如果该元素是 NULL，则会抛出 NullPointerException 异常。 public abstract boolean offer(E paramE)：将指定元素插入此队列中（如果立即可行且不会违反容量限制），成功时返回 true，如果当前没有可用的空间，则返回false。 public abstract void put(E paramE) throws InterruptedException： 将指定元素插入此队列中，将等待可用的空间（如果有必要） 12345678910111213public void put(E paramE) throws InterruptedException &#123; checkNotNull(paramE); ReentrantLock localReentrantLock = this.lock; localReentrantLock.lockInterruptibly(); try &#123; while (this.count == this.items.length) this.notFull.await();//如果队列满了，则线程阻塞等待 enqueue(paramE); localReentrantLock.unlock(); &#125; finally &#123; localReentrantLock.unlock(); &#125;&#125; offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间内，还不能往队列中加入 BlockingQueue，则返回失败。 获取数据操作 ： poll(time):取走 BlockingQueue 里排在首位的对象,若不能立即取出,则可以等 time 参数规定的时间,取不到时返回 null; poll(long timeout, TimeUnit unit)：从 BlockingQueue 取出一个队首的对象，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则直到时间超时还没有数据可取，返回失败。 take():取走 BlockingQueue 里排在首位的对象,若 BlockingQueue 为空,阻断进入等待状态直到 BlockingQueue 有新的数据被加入。 drainTo():一次性从 BlockingQueue 获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。 Java 中的阻塞队列 ArrayBlockingQueue ：由数组结构组成的有界阻塞队列 公平、非公平 用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐量。我们可以使用以下代码创建一个公平的阻塞队列：1ArrayBlockingQueue fairQueue = new ArrayBlockingQueue(1000,true); LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。 两个独立锁提高并发 基于链表的阻塞队列，同ArrayListBlockingQueue类似，此队列按照先进先出（FIFO）的原则对元素进行排序。而 LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。LinkedBlockingQueue 会默认一个类似无限大小的容量（Integer.MAX_VALUE）。 PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。 compareTo 排序实现优先 是一个支持优先级的无界队列。默认情况下元素采取自然顺序升序排列。可以自定义实现compareTo()方法来指定元素进行排序规则，或者初始化 PriorityBlockingQueue 时，指定构造参数 Comparator 来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。 DelayQueue：使用优先级队列实现的无界阻塞队列。 缓存失效、定时任务 是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现 Delayed 接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将 DelayQueue 运用在以下应用场景： 缓存系统的设计：可以用 DelayQueue 保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从 DelayQueue 中获取元素时，表示缓存有效期到了。 定时任务调度：使用 DelayQueue 保存当天将会执行的任务和执行时间，一旦从DelayQueue 中获取到任务就开始执行，从比如 TimerQueue 就是使用 DelayQueue实现的。 SynchronousQueue：不存储元素的阻塞队列。 不存储数据、可用于传递数据 是一个不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作，否则不能继续添加元素。SynchronousQueue 可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用，SynchronousQueue的吞吐量高于LinkedBlockingQueue 和ArrayBlockingQueue。 LinkedTransferQueue：由链表结构组成的无界阻塞队列。是 一 个 由 链 表 结 构 组 成 的 无 界 阻 塞 TransferQueue 队 列 。 相 对 于 其 他 阻 塞 队 列 ，LinkedTransferQueue 多了 tryTransfer 和 transfer 方法。 transfer 方法：如果当前有消费者正在等待接收元素（消费者使用 take()方法或带时间限制的poll()方法时），transfer 方法可以把生产者传入的元素立刻 transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer 方法会将元素存放在队列的 tail 节点，并等到该元素被消费者消费了才返回。 tryTransfer 方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回 false。和 transfer 方法的区别是 tryTransfer 方法无论消费者是否接收，方法立即返回。而 transfer 方法是必须等到消费者消费了才返回。 对于带有时间限制的 tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回 false，如果在超时时间内消费了元素，则返回 true。 LinkedBlockingDeque：由链表结构组成的双向阻塞队列是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque 多了 addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast 等方法，以 First 单词结尾的方法，表示插入，获取（peek）或移除双端队列的第一个元素。以 Last 单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素。另外插入方法 add 等同于 addLast，移除方法 remove 等效于 removeFirst。但是 take 方法却等同于 takeFirst，不知道是不是 Jdk 的 bug，使用时还是用带有 First 和 Last 后缀的方法更清楚。在初始化 LinkedBlockingDeque 时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：线程池原理]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量则超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。他的主要特点为：线程复用、控制最大并发数、管理线程。 线程复用每一个 Thread 的类都有一个 start 方法。 当调用 start 启动线程时 Java 虚拟机会调用该类的 run方法。 那么该类的 run() 方法中就是调用了 Runnable 对象的 run() 方法。 我们可以继承重写Thread 类，在其 start 方法中添加不断循环调用传递过来的 Runnable 对象。 这就是线程池的实现原理。循环方法中不断获取 Runnable 是用 Queue 实现的，在获取下一个 Runnable 之前可以是阻塞的。 线程池的组成 线程池管理器：用于创建并管理线程池 工作线程：线程池中的线程 任务接口：每个任务必须实现的接口，用于工作线程调度其运行 任务队列：用于存放待处理的任务，提供一种缓冲机制 Java 中的线程池是通过 Executor 框架实现的，该框架中用到了 Executor，Executors，ExecutorService，ThreadPoolExecutor ，Callable 和 Future、FutureTask 这几个类。ThreadPoolExecutor 的构造方法如下：12345public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,Executors.defaultThreadFactory(), defaultHandler);&#125; corePoolSize：指定了线程池中的线程数量。 maximumPoolSize：指定了线程池中的最大线程数量。 keepAliveTime：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间，即多次时间内会被销毁。 unit：keepAliveTime 的单位。 workQueue：任务队列，被提交但尚未被执行的任务。 threadFactory：线程工厂，用于创建线程，一般用默认的即可。 handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。 拒绝策略线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。JDK 内置的拒绝策略如下： AbortPolicy ： 直接抛出异常，阻止系统正常运行。 CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。 DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。 DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。 以上内置拒绝策略均实现了 RejectedExecutionHandler 接口，若以上策略仍无法满足实际需要，完全可以自己扩展 RejectedExecutionHandler 接口。 Java线程池工作过程 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。 当调用 execute() 方法添加一个任务时，线程池会做如下判断：a) 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；b) 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；c) 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；d) 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常 RejectExecutionException。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：锁的优化]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E9%94%81%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[减少锁持有时间 只用在需要线程安全的方法上加锁 减小锁粒度将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是ConcurrentHashMap。 锁分离最常见的锁分离就是读写锁 ReadWriteLock，根据功能进行分离成读锁和写锁，这样读读不互斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如下面的LinkedBlockingQueue 从头部取出，从尾部放数据 锁粗化通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁。但是，凡事都有一个度，如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 。 123456789public void demoMethod()&#123; synchronized(lock)&#123; //do sth. &#125; //做其他不需要的同步的工作，但能很快执行完毕 synchronized(lock)&#123; //do sth. &#125; &#125; 这种情况，根据锁粗化的思想，应该合并1234567public void demoMethod()&#123; //整合成一次锁请求 synchronized(lock)&#123; //do sth. //做其他不需要的同步的工作，但能很快执行完毕 &#125;&#125; 当然这是有前提的，前提就是中间的那些不需要同步的工作是很快执行完成的。 锁消除 在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作。 也许你会觉得奇怪，既然有些对象不可能被多线程访问，那为什么要加锁呢？写代码时直接不加锁不就好了。但是有时，这些锁并不是程序员所写的，有的是JDK实现中就有锁的，比如Vector和StringBuffer这样的类，它们中的很多方法都是有锁的。当我们在一些不会有线程安全的情况下使用这些类的方法时，达到某些条件时，编译器会将锁消除来提高性能。 123456789101112131415public static void main(String args[]) throws InterruptedException &#123; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 2000000; i++) &#123; createStringBuffer("JVM", "Diagnosis"); &#125; long bufferCost = System.currentTimeMillis() - start; System.out.println("craeteStringBuffer: " + bufferCost + " ms"); &#125; public static String createStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString(); &#125; StringBuffer.append是一个同步操作，但是StringBuffer却是一个局部变量，并且方法也并没有把StringBuffer返回，所以不可能会有多线程去访问它，那么此时StringBuffer中的同步操作就是没有意义的。 开启锁消除是在JVM参数上设置的，当然需要在server模式下：1-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks 并且要开启逃逸分析。 逃逸分析的作用呢，就是看看变量是否有可能逃出作用域的范围：比如上述的StringBuffer，上述代码中craeteStringBuffer的返回是一个String，所以这个局部变量StringBuffer在其他地方都不会被使用。如果将craeteStringBuffer改成123456public static StringBuffer craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb;&#125; 那么这个 StringBuffer被返回后，是有可能被任何其他地方所使用的（譬如被主函数将返回结果put进map啊等等）。那么JVM的逃逸分析可以分析出，这个局部变量 StringBuffer逃出了它的作用域。所以基于逃逸分析，JVM可以判断，如果这个局部变量StringBuffer并没有逃出它的作用域，那么可以确定这个StringBuffer并不会被多线程所访问，那么就可以把这些多余的锁给去掉来提高性能]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：锁分类]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E9%94%81%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[可重入锁 可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。在 JAVA 环境下 ReentrantLock 和 synchronized 都是 可重入锁。 ReadWriteLock 读写锁为了提高性能，Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由 jvm 自己控制的，你只要上好相应的锁即可。 读锁如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁 写锁如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁。Java中读写锁有个接口：java.util.concurrent.locks.ReadWriteLock，也有具体的实现ReentrantReadWriteLock。 共享锁和独占锁 java 并发包提供的加锁模式分为独占锁和共享锁 独占锁独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。 共享锁共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。 AQS 的内部类 Node 定义了两个常量 SHARED 和 EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。 java 的并发包中提供了 ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，或者被一个 写操作访问，但两者不能同时进行。 公平锁与非公平锁公平锁（ Fair ） 加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得 非公平锁（ Nonfair ） 加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待 非公平锁性能比公平锁高 5~10 倍，因为公平锁需要在多核的情况下维护一个队列 Java 中的 synchronized 是非公平锁，ReentrantLock 默认的 lock()方法采用的是非公平锁。 偏向锁/轻量级锁/重量级锁 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀。【但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级】 锁 优点 缺点 使用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行速度较长。 偏向锁Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换ThreadID 的时候依赖一次 CAS 原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的 CAS 原子指令的性能消耗）。上面说过，轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。 轻量级锁“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。 重量级锁(Mutex Lock)Synchronized 是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为“重量级锁”。JDK 中对 Synchronized 做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6 以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。 分段锁 分段锁并非一种实际的锁，而是一种思想ConcurrentHashMap的segment是学习分段锁的最好实践 HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁，假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：AtomicInteger]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9AAtomicInteger%2F</url>
    <content type="text"><![CDATA[此处 AtomicInteger，一个提供原子操作的 Integer 的类，常见的还有AtomicBoolean、AtomicInteger、AtomicLong、AtomicReference 等，他们的实现原理相同，区别在与运算对象类型的不同。令人兴奋地，还可以通过 AtomicReference将一个对象的所有操作转化成原子操作。 在多线程程序中，诸如++i 或 i++等运算不具有原子性，是不安全的线程操作之一。通常我们会使用 synchronized 将该操作变成一个原子操作，但JVM为此类操作特意提供了一些同步类，使得使用更方便，且使程序运行效率变得更高。通过相关资料显示，通常AtomicInteger的性能是 ReentrantLock 的好几倍。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：Semaphore信号量]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9ASemaphore%E4%BF%A1%E5%8F%B7%E9%87%8F%2F</url>
    <content type="text"><![CDATA[Semaphore 是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信号，做完自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。Semaphore 可以用来构建一些对象池，资源池之类的，比如数据库连接池。 实现互斥锁（计数器为 1 ） 我们也可以创建计数为 1 的 Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。 12345678910111213141516// 创建一个计数阈值为 5 的信号量对象// 只能 5 个线程同时访问Semaphore semp = new Semaphore(5);try &#123; // 申请许可 semp.acquire(); try &#123; // 业务逻辑 &#125; catch (Exception e) &#123; &#125; finally &#123; // 释放许可 semp.release(); &#125;&#125; catch (InterruptedException e) &#123;&#125; Semaphore 与 ReentrantLockSemaphore 基本能完成 ReentrantLock 的所有工作，使用方法也与之类似，通过 acquire()与release()方法来获得和释放临界资源。经实测，Semaphone.acquire()方法默认为可响应中断锁，与 ReentrantLock.lockInterruptibly()作用效果一致，也就是说在等待临界资源的过程中可以被Thread.interrupt()方法中断。 此外，Semaphore 也实现了可轮询的锁请求与定时锁的功能，除了方法名 tryAcquire 与 tryLock不同，其使用方法与 ReentrantLock几乎一致。Semaphore也提供了公平与非公平锁的机制，也可在构造函数中进行设定。 Semaphore的锁释放操作也由手动进行，因此与 ReentrantLock 一样，为避免线程因抛出异常而无法正常释放锁的情况发生，释放锁的操作也必须在 finally 代码块中完成。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：ReentrantLock]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9AReentrantLock%2F</url>
    <content type="text"><![CDATA[ReentantLock 继承接口 Lock 并实现了接口中定义的方法，他是一种可重入锁，除了能完成 synchronized 所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。 Lock接口的主要方法 void lock(): 执行此方法时, 如果锁处于空闲状态, 当前线程将获取到锁。相反, 如果锁已经被其他线程持有, 将禁用当前线程, 直到当前线程获取到锁。获得锁就返回 true，不能的话一直等待获得锁。 boolean tryLock()：如果锁可用, 则获取锁, 并立即返回 true, 否则返回 false。该方法和lock()的区别在于, tryLock()只是”试图”获取锁, 如果锁不可用, 不会导致当前线程被禁用,当前线程仍然继续往下执行代码. 而 lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行. void unlock()：执行此方法时, 当前线程将释放持有的锁. 锁只能由持有者释放, 如果线程并不持有锁, 却执行该方法, 可能导致异常的发生. Condition newCondition()：条件对象，获取等待通知组件。该组件和当前的锁绑定，当前线程只有获取了锁，才能调用该组件的 await()方法，而调用后，当前线程将缩放锁。 getHoldCount() ：查询当前线程保持此锁的次数，也就是执行此线程执行lock方法的次数。 getQueueLength（）：返回正等待获取此锁的线程估计数，比如启动 10 个线程，1 个线程获得锁，此时返回的是 9 getWaitQueueLength：（Condition condition）返回等待与此锁相关的给定条件的线程估计数。比如 10 个线程，用同一个 condition 对象，并且此时这 10 个线程都执行了condition 对象的 await 方法，那么此时执行此方法返回 10 hasWaiters(Condition condition)：查询是否有线程等待与此锁有关的给定条件(condition)，对于指定 contidion 对象，有多少线程执行了 condition.await 方法 hasQueuedThread(Thread thread)：查询给定线程是否等待获取此锁 hasQueuedThreads()：是否有线程等待此锁 isFair()：该锁是否公平锁 isHeldByCurrentThread()： 当前线程是否保持锁锁定，线程的执行 lock 方法的前后分别是 false 和 true isLock()：此锁是否有任意线程占用 lockInterruptibly（）：如果当前线程未被中断，获取锁 tryLock（）：尝试获得锁，仅在调用时锁未被线程占用，获得锁 tryLock(long timeout TimeUnit unit)：如果锁在给定等待时间内没有被另一个线程保持，则获取该锁。 非公平锁JVM 按随机、就近原则分配锁的机制则称为不公平锁，ReentrantLock 在构造函数中提供了是否公平锁的初始化方式，默认为非公平锁。非公平锁实际执行的效率要远远超出公平锁，除非程序有特殊需要，否则最常用非公平锁的分配机制。 公平锁公平锁指的是锁的分配机制是公平的，通常先对锁提出获取请求的线程会先被分配到锁，ReentrantLock 在构造函数中提供了是否公平锁的初始化方式来定义公平锁 ReentrantLock与Synchronized ReentrantLock 通过方法 lock()与 unlock()来进行加锁与解锁操作，与synchronized 会被 JVM 自动解锁机制不同，ReentrantLock 加锁后需要手动进行解锁。为了避免程序出现异常而无法正常解锁的情况，使用 ReentrantLock 必须在 finally 控制块中进行解锁操作。 ReentrantLock 相比 synchronized 的优势是可中断、公平锁、多个锁。这种情况下需要使用 ReentrantLock。 相同点 都是用来协调多线程对共享对象、变量的访问 都是可重入锁，同一线程可以多次获得同一个锁 都保证了可见性和互斥性 不同点 ReentrantLock 显示的获得、释放锁，synchronized 隐式获得释放锁 ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性 ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的 ReentrantLock 可以实现公平锁 ReentrantLock 通过 Condition 可以绑定多个条件 底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略，lock 是同步非阻塞，采用的是乐观并发策略 Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现。 synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁。 Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断。 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。 ReentrantLock实现123456789101112131415161718192021222324public class MyService &#123; private Lock lock = new ReentrantLock(); //Lock lock=new ReentrantLock(true);//公平锁 //Lock lock=new ReentrantLock(false);//非公平锁 private Condition condition=lock.newCondition();//创建 Condition public void testMethod() &#123; try &#123; lock.lock();//lock 加锁 //1：wait 方法等待： //System.out.println(&quot;开始 wait&quot;); condition.await(); //通过创建 Condition 对象来使线程 wait，必须先执行 lock.lock 方法获得锁 //:2：signal 方法唤醒 condition.signal();//condition 对象的 signal 方法可以唤醒 wait 线程 for (int i = 0; i &lt; 5; i++) &#123; System.out.println(&quot;ThreadName=&quot; + Thread.currentThread().getName()+ (&quot; &quot; + (i + 1))); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally&#123; lock.unlock(); &#125; &#125;&#125; Condition 类和 Object 类锁方法区别区别 Condition 类的 awiat 方法和 Object 类的 wait 方法等效 Condition 类的 signal 方法和 Object 类的 notify 方法等效 Condition 类的 signalAll 方法和 Object 类的 notifyAll 方法等效 ReentrantLock 类可以唤醒指定条件的线程，而 object 的唤醒是随机的 tryLock 和 lock 和 lockInterruptibly 的区别 tryLock 能获得锁就返回 true，不能就立即返回 false，tryLock(long timeout,TimeUnit unit)，可以增加时间限制，如果超过该时间段还没获得锁，返回 false lock 能获得锁就返回 true，不能的话一直等待获得锁 lock 和 lockInterruptibly，如果两个线程分别执行这两个方法，但此时中断这两个线程，lock 不会抛出异常，而 lockInterruptibly 会抛出异常]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：Synchronized同步锁]]></title>
    <url>%2F2019%2F04%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9ASynchronized%E5%90%8C%E6%AD%A5%E9%94%81%2F</url>
    <content type="text"><![CDATA[synchronized 它可以把任意一个非NULL的对象当作锁，属于独占式的悲观锁，同时属于可重入锁。 作用范围 作用于方法时，锁住的是对象的实例(this)； 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久代PermGen(jdk1.8则是 metaspace)，永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程； synchronized 作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。 核心组件 Wait Set：那些调用 wait 方法被阻塞的线程被放置在这里； Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List 中那些有资格成为候选资源的线程被移动到 Entry List 中； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为 OnDeck； Owner：当前已经获取到所资源的线程被称为 Owner； !Owner：当前释放锁的线程。 实现 JVM 每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争，JVM 会将一部分线程移动到 EntryList 中作为候选竞争线程。 Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList 中的某个线程为 OnDeck 线程（一般是最先进去的那个线程）。 Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM 中，也把这种选择行为称之为“竞争切换”。 OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者 notifyAll 唤醒，会重新进去 EntryList 中。 处于 ContentionList、EntryList、WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux 内核下采用 pthread_mutex_lock 内核函数实现的）。 Synchronized 是非公平锁。 Synchronized 在线程进入 ContentionList 时，等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁资源。参考：https://blog.csdn.net/zqz_zqz/article/details/70233767 每个对象都有个 monitor 对象，加锁就是在竞争 monitor 对象，代码块加锁是在前后分别加上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个标记位来判断的 synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。 Java1.6，synchronized 进行了很多的优化，有适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等，效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中，均对该关键字的实现机理做了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀； JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking 来禁用偏向锁]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：自旋锁]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E8%87%AA%E6%97%8B%E9%94%81%2F</url>
    <content type="text"><![CDATA[如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。 自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。 线程自旋是需要消耗cpu的，说白了就是让cpu在做无用功，如果一直获取不到锁，那线程也不能一直占用cpu自旋做无用功，所以需要设定一个自旋等待的最大时间。 如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。 自旋锁的优缺点 优点 自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换 缺点 如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着茅坑不 拉屎，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cpu的线程又不能获取到cpu，造成 cpu 的浪费，所以这种情况下我们要关闭自旋锁。 自旋锁时间阈值(1.6 引入了适应性自旋锁)自旋锁的目的是为了占着 CPU 的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而会影响整体系统的性能。因此自旋的周期选择额外重要。JVM对于自旋周期的选择，jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM还针对当前CPU的负荷情况做了较多的优化。 如果平均负载小于CPUs则一直自旋 如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞 如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋 自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差） 自旋时会适当放弃线程优先级之间的差异 自旋锁的开启 JDK1.6中-XX:+UseSpinning开启； -XX:PreBlockSpin=10 为自旋次数； JDK1.7后，去掉此参数，由jvm控制；]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：乐观锁与悲观锁]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81%2F</url>
    <content type="text"><![CDATA[悲观锁：适合写操作多的场景，先加锁可以保证写操作时数据正确。乐观锁：适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为不会修改，所以不会上锁，但在更新的时候会判断一下在此期间这个数据有没有更新，可以使用版本号机制和CAS(Compare And Swap)算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁一般会使用版本号机制或CAS算法实现。 实现方式版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 CAS算法 需要读写的内存值 V 进行比较的值 A 要写入的新值 B 当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 乐观锁的缺点 ABA 问题 如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值 循环时间长开销大 自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销 只能保证一个共享变量的原子操作 CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作 悲观锁总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加锁（读锁、写锁、行锁等），当其他线程想要访问数据时，都需要阻塞挂起。可以依靠数据库实现，如行锁、读锁和写锁等，都是在操作之前加锁，在Java中，synchronized的思想也是悲观锁。 补充synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：线程方法]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%BA%BF%E7%A8%8B%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[start线程调用该方法将启动线程，使之从新建状态进入就绪队列排队，一旦轮到它来享用CPU资源时，就可以脱离创建它的线程独立开始自己的生命周期了。 run-线程执行Thread类的run()方法与Runnable接口中的run()方法的功能和作用相同，都用来定义线程对象被调度之后所执行的操作，都是系统自动调用而用户程序不得引用的方法。 wait-线程等待调用该方法的线程进入 WAITING 状态，只有等待另外线程的通知(notify/notifyAll)或被中断才会返回，需要注意的是调用 wait()方法后，会释放对象的锁。因此，wait 方法一般用在同步方法或同步代码块中。 sleep-线程睡眠sleep 导致当前线程休眠，与 wait 方法不同的是 sleep 不会释放当前占有的锁,sleep(long)会导致线程进入 TIMED-WATING 状态，而 wait()方法会导致当前线程进入 WATING 状态 yield-线程让步yield 会使当前线程让出 CPU 执行时间片，与其他线程一起重新竞争 CPU 时间片。一般情况下，优先级高的线程有更大的可能性成功竞争得到 CPU 时间片，但这又不是绝对的，有的操作系统对线程优先级并不敏感 interrupt-线程中断中断一个线程，其本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标识位。这个线程本身并不会因此而改变状态(如阻塞，终止等) 调用 interrupt()方法并不会中断一个正在运行的线程。也就是说处于 Running 状态的线程并不会因为被中断而被终止，仅仅改变了内部维护的中断标识位而已 若调用 sleep()而使线程处于 TIMED-WATING 状态，这时调用interrupt()方法，会抛出InterruptedException,从而使线程提前结束 TIMED-WATING 状态。 许多声明抛出 InterruptedException 的方法(如Thread.sleep(long mills 方法))，抛出异常前，都会清除中断标识位，所以抛出异常后，调用isInterrupted()方法将会返回 false。 中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。比如,你想终止一个线程thread的时候，可以调用thread.interrupt()方法，在线程的run方法内部可以根据 thread.isInterrupted()的值来优雅的终止线程 join-等待线程终止 join(0)的意思不是A线程等待B线程0秒，而是A线程等待B线程无限时间，直到B线程执行完毕，即join(0)等价于join();join(10)，则表示A线程会等待B线程执行10毫秒，10毫秒过后，A、B线程并行执行 join() 方法，放弃当前线程的执行，等待其他线程终止，在当前线程中调用一个线程的 join() 方法，则当前线程转为阻塞状态，等到另一个线程结束，当前线程再由阻塞状态变为就绪状态，等待 cpu notifyObject 类中的 notify() 方法，唤醒在此对象监视器上等待的单个线程，如果所有线程都在此对象上等待，则会选择唤醒其中一个线程，选择是任意的，并在对实现做出决定时发生，线程通过调用其中一个 wait() 方法，在对象的监视器上等待，直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程，被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争。类似的方法还有 notifyAll() ，唤醒再次监视器上等待的所有线程 其他方法 sleep()：强迫一个线程睡眠Ｎ毫秒。 isAlive()： 判断一个线程是否存活。 join()： 等待线程终止。 activeCount()： 程序中活跃的线程数。 enumerate()： 枚举程序中的线程。 currentThread()： 得到当前线程。 isDaemon()： 一个线程是否为守护线程。 setDaemon()： 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束) setName()： 为线程设置一个名称。 wait()： 强迫一个线程等待。 notify()： 通知一个线程继续运行。 setPriority()： 设置一个线程的优先级。 getPriority(): 获得一个线程的优先级 sleep和wait的区别 sleep方法属于Thread类，wait方法属于Object类 sleep()方法导致了程序暂停执行指定的时间，让出 cpu给其他线程，但是监控状态依然保持着，当指定的时间到了又会自动恢复运行状态 在调用 sleep()方法的过程中，线程不会释放对象锁 而当调用 wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify()/notifyAll()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态 start与run区别 start()方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，可以直接继续执行下面的代码 通过调用 Thread 类的 start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行 方法 run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行 run 函数当中的代码。 Run 方法运行结束， 此线程终止。然后 CPU 再调度其它线程]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：线程生命周期]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%BA%BF%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。在线程的生命周期中，它要经过新建(New)、就绪(Runnable)、运行(Running)、阻塞(Blocked)和死亡(Dead)这5 种状态。尤其是当线程启动以后，它不可能一直”霸占”着 CPU 独自运行，所以 CPU 需要在多条线程之间切换，于是线程状态也会多次在运行、阻塞之间切换。 新建状态NEW当程序使用 new 关键字创建了一个线程之后，该线程就处于新建状态，此时仅由 JVM 为其分配内存，并初始化其成员变量的值 就绪状态(RUNNABLE )当线程对象调用了 start()方法之后，该线程处于就绪状态。Java 虚拟机会为其创建方法调用栈和程序计数器，等待调度运行。 运行状态(RUNNING)如果处于就绪状态的线程获得了 CPU，开始执行 run()方法的线程执行体，则该线程处于运行状态。 阻塞状态(BLOCKED) 阻塞状态是指线程因为某种原因放弃了 cpu 使用权，也即让出了 cpu timeslice，暂时停止运行。直到线程进入可运行/就绪(runnable)状态，才有机会再次获得 cpu timeslice 转到运行(running)状态。 阻塞的情况分三种： 等待阻塞( o.wait-&gt; 等待对列)：运行(running)的线程执行 o.wait()方法，JVM 会把该线程放入等待队列(waitting queue)中 同步阻塞 (lock-&gt; 锁池)：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线程放入锁池(lock pool)中 其他阻塞 (sleep/join)：运行(running)的线程执行 Thread.sleep(long ms)或 t.join()方法，或者发出了 I/O 请求时，JVM 会把该线程置为阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O处理完毕时，线程重新转入可运行(runnable)状态。 线程死亡(DEAD)线程会以下面三种方式结束，结束后就是死亡状态。 正常结束run()或 call()方法执行完成，线程正常结束 异常结束线程抛出一个未捕获的 Exception 或 Error 调用stop-已废弃直接调用该线程的 stop()方法来结束该线程(该方法通常容易导致死锁，不推荐使用)终止线程四种方式 正常运行结束 使用退出标志退出线程一般 run()方法执行完，线程就会正常结束，但是有些线程需要长时间的运行，只有在外部某些条件满足的情况下，才能关闭这些线程。使用一个变量来控制循环，例如：最直接的方法就是设一个boolean 类型的标志，并通过设置这个标志为 true或 false 来控制 while循环是否退出 12345678public class ThreadSafe extends Thread &#123; public volatile boolean exit = false;// volatile保证数据可见性，使得exit值同步 public void run() &#123; while (!exit)&#123; //do something &#125; &#125;&#125; Interrupt 方法结束线程使用 interrupt()方法来中断线程有两种情况： 线程处于阻塞状态 如使用了 sleep/同步锁的 wait/socket 中的 receiver,accept 等方法时，会使线程处于阻塞状态。当调用线程的 interrupt()方法时，会抛出InterruptException 异常。通常很多人认为只要调用 interrupt 方法线程就会结束，实际上是错的， 一定要先捕获 InterruptedException 异常之后通过 break 来跳出循环，才能正常结束 run 方法 线程未处于阻塞状态 使用 isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置 true，和使用自定义的标志来控制循环是一样的道理 123456789101112public class ThreadSafe extends Thread &#123; public void run() &#123; while (!isInterrupted())&#123; //非阻塞过程中通过判断中断标志来退出 try&#123; Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出 &#125;catch(InterruptedException e)&#123; e.printStackTrace(); break;//捕获到异常之后，执行 break 跳出循环 &#125; &#125; &#125;&#125; stop 方法终止线程（线程不安全，已废弃） thread.stop()调用之后，创建子线程的线程就会抛出 ThreadDeatherror 的错误，并且会释放子线程所持有的所有锁。 一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用 stop 方法来终止线程。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之多线程并发：Java线程实现/创建方式]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%EF%BC%9AJava%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0-%E5%88%9B%E5%BB%BA%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[## 继承Thread类&gt; Thread实质上是实现了Runnable接口的一个实例。启动线程的唯一方法是通过Thread的start()实例方法。start()是一个native方法，将启动新线程，并执行run()方法。1234567public TestThread extends Thread()&#123; public void run()&#123; System.out.println(&quot;TestThread run&quot;); &#125;&#125;TestThread test = new TestThread();test.start(); 实现Runnable接口 如果此时类已经继承了其他的父类，那么无法直接继承Thread，则可以实现一个Runnable。 12345public class MyThread extends OtherClass implements Runnable &#123; public void run() &#123; System.out.println(&quot;MyThread.run()&quot;); &#125; &#125; 启动MyThread，需要首先实例化一个Thread，然后将MyThread作为一个target传入 123MyThread myThread = new MyThread(); Thread thread = new Thread(myThread); thread.start(); 当传入一个 Runnable target 参数给 Thread 后，Thread 的 run()方法就会调用target.run() 12345public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; ExecutorService 、Callable 、Future有返回值线程 有返回值的任务 Callable，无返回值的任务 Runnable 执行Callable任务后，可以获取一个 Future 的对象，在该对象上调用 get 就可以获取到 Callable 任务返回的 Object 了，再结合线程池接口 ExecutorService 就可以实现传说中有返回结果的多线程了。1234567891011121314151617//创建一个线程池ExecutorService pool = Executors.newFixedThreadPool(taskSize);// 创建多个有返回值的任务List&lt;Future&gt; list = new ArrayList&lt;Future&gt;();for (int i = 0; i &lt; taskSize; i++) &#123; Callable c = new MyCallable(i + &quot; &quot;); // 执行任务并获取 Future 对象 Future f = pool.submit(c); list.add(f);&#125;// 关闭线程池pool.shutdown();// 获取所有并发任务的运行结果for (Future f : list) &#123; // 从 Future 对象上获取任务的返回值，并输出到控制台 System.out.println(&quot;res：&quot; + f.get().toString());&#125; 基于线程池的方式线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建，不需要的时候销毁，是非常浪费资源的。那么我们就可以使用缓存的策略，也就是使用线程池。 123456789101112131415// 创建线程池ExecutorService threadPool = Executors.newFixedThreadPool(10);while(true) &#123; threadPool.execute(new Runnable() &#123; // 提交多个线程任务，并执行 @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; is running ..&quot;); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;);&#125; 4种线程池 Java 里面线程池的顶级接口是 Executor，但是严格意义上讲 Executor 并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是 ExecutorService。 线程池底层都是通过ThreadPoolExecutor来实现的。1234567ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize: 表示需要设置的线程个数；maximumPoolSize: 线程池允许的最大线程个数； keepAliveTime: 空闲线程存活的时间，超过这个时间就会被回收； unit: 存活时间的单位；workQueue: 需要执行的任务队列。threadFactory: 线程工厂，用于创建线程，一般用默认的即可；handler: 拒绝策略，当任务太多来不及处理，如何拒绝任务； 拒绝策略： 直接丢弃（DiscardPolicy） 丢弃队列中最老的任务(DiscardOldestPolicy) 抛异常(AbortPolicy) 将任务分给调用线程来执行(CallerRunsPolicy) newCachedThreadPool：可缓存线程池 如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 工作线程的创建数量几乎没有限制(数目限制为Interger. MAX_VALUE), 可灵活的往线程池中添加线程。 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。 在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有可能会造成系统瘫痪。12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; SynchronousQueue：SynchronousQueue是无界的，是一种无缓冲的等待队列，但是由于该Queue本身的特性，在某次添加元素put后必须等待其他线程取走take后才能继续添加；可以认为SynchronousQueue是一个缓存值为1的阻塞队列，但是 isEmpty()方法永远返回是true，remainingCapacity() 方法永远返回是0，remove()和removeAll() 方法永远返回是false，iterator()方法永远返回空，peek()方法永远返回null。声明一个SynchronousQueue有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别:如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO先进先出队列来阻塞多余的生产者和消费者，从而体系整体的公平策略；但如果是非公平模式（SynchronousQueue默认）：SynchronousQueue采用非公平锁，同时配合一个LIFO后进先出队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。 newFixedThreadPool 创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。(可控制线程最大并发数，超出的线程会在队列中等待) 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。 如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。 如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。 在某个线程被显式地关闭之前，池中的线程将一直存在。 LinkedBlockingQueue是无界的，是一个无界缓存的等待队列。基于链表的阻塞队列，内部维持着一个数据缓冲队列（该队列由链表构成）。当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行 1234public ScheduledThreadPoolExecutor(int corePoolSize) &#123; ThreadPoolExecutor(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); &#125; schedule：延迟执行一次 scheduleAtFixedRate：固定的频率来执行某项计划，它不受计划执行时间的影响 scheduleWithFixedDelay：无论任务执行多长时间，等执行完了，再延迟指定的时间，受计划执行时间的影响12345678910111213141516171819ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool(3);scheduledThreadPool.schedule(newRunnable()&#123; @Override public void run() &#123; System.out.println(&quot;延迟三秒&quot;); &#125;&#125;, 3, TimeUnit.SECONDS);scheduledThreadPool.scheduleAtFixedRate(newRunnable()&#123; @Override public void run() &#123; System.out.println(&quot;延迟 1 秒后每三秒执行一次（不受计划执行时间的影响）&quot;); &#125; &#125;,1,3,TimeUnit.SECONDS);scheduledThreadPool.scheduleWithFixedDelay(newRunnable()&#123; @Override public void run() &#123; System.out.println(&quot;延迟 1 秒后每三秒执行一次（受计划执行时间的影响）&quot;); &#125; &#125;,1,3,TimeUnit.SECONDS); DelayedWorkQueue 使用优先级队列DelayedWorkQueue，保证添加到队列中的任务，会按照任务的延时时间进行排序，延时时间少的任务首先被获取。 元素个数超过数组长度，就会调用grow()方法，进行数组扩容。 将新元素e添加到优先级队列中对应的位置，通过siftUp方法，保证按照元素的优先级排序。 如果新插入的元素是队列头，即更换了队列头，那么就要唤醒正在等待获取任务的线程。这些线程可能是因为原队列头元素的延时时间没到，而等待的。 NewSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 这个线程池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; LinkedBlockingQueue是无界的，是一个无界缓存的等待队列。基于链表的阻塞队列，内部维持着一个数据缓冲队列（该队列由链表构成）。当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之Java集合]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8BJava%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[集合类存放于 Java.util 包中，主要有 3 种：set(集）、list(列表包含 Queue）和 map(映射)。 Collection：Collection 是集合 List、Set、Queue 的最基本的接口。 Iterator：迭代器，可以通过迭代器遍历集合中的数据 Map：是映射表的基础接口 List List里存放的对象是有序的，同时也是可以重复的，List关注的是索引，拥有一系列和索引相关的方法，查询速度快。因为往list集合里插入或删除数据时，会伴随着后面数据的移动，所有插入删除数据速度慢。 说明 ArrayList在内存不够时默认是扩展50% + 1个，Vector是默认扩展1倍。 Vector属于线程安全级别的，但是大多数情况下不使用Vector，因为线程安全需要更大的系统开销。 一般使用ArrayList和LinkedList比较多，LinkedList不存在get()的操作，不能单个定位，ArrayList是顺序存储结构，LinkedList是链表存储结构 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据 ArrayList（常用、数组实现，对元素快速随机访问）ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要讲已经有数组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除 Vector（数组实现、线程同步、需高花费）Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢 LinkedList（链表结构、Queue）LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用 ArrayList和LinkedList在用法上没有区别，但是在功能上还是有区别的。LinkedList经常用在增删操作较多而查询操作很少的情况下，ArrayList则相反 Set Set集合不允许出现重复数据允许包含值为null的元素，但最多只能有一个null元素。 Set 注重独一无二的性质,该体系集合用于存储无序(存入和取出的顺序不一定相同)元素，值不能重复。对象的相等性本质是对象 hashCode 值（java 是依据对象的内存地址计算出的此序号）判断的，如果想要让两个不同的对象视为相等的，就必须覆盖 Object 的 hashCode 方法和 equals 方法。 HashSet HashSet中不能有重复的元素 HashSet是无序的 HashSet也是基于HashMap实现 哈希表边存放的是哈希值。HashSet 存储元素的顺序并不是按照存入时的顺序（和 List 显然不同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals 方法 如果 equls 结果为 true ，HashSet 就视为同一个元素。如果 equals 为 false 就不是同一个元素。 HashSet 通过 hashCode 值来确定元素在内存中的位置。一个 hashCode 位置上可以存放多个元素。 TreeSet TreeSet中不能有重复的元素； TreeSet具有排序功能，缺省是按照自然排序进行排列 TreeSet中的元素必须实现Comparable接口并重写compareTo()方法，TreeSet判断元素是否重复 、以及确定元素的顺序靠的都是这个方法 基于TreeMap实现 TreeSet()是使用二叉树的原理对新 add()的对象按照指定的顺序排序（升序、降序），每增加一个对象都会进行排序，将对象插入的二叉树指定的位置。 Integer 和 String 对象都可以进行默认的 TreeSet 排序，而自定义类的对象是不可以的，自己定义的类必须实现 Comparable 接口，并且覆写相应的 compareTo()函数，才可以正常使用。 在覆写 compare()函数时，要返回相应的值才能使 TreeSet 按照一定的规则来排序 比较此对象与指定对象的顺序。如果该对象小于、等于或大于指定对象，则分别返回负整数、零或正整数。 Map Map集合中存储的是键值对，键不能重复，值可以重复。根据键得到值，对map集合遍历时先得到键的set集合，对set集合进行遍历，得到相应的值 Map遍历：KeySet()、entrySet()keySet其实是遍历了2次，一次是转为iterator，一次就是从HashMap中取出key所对于的value。而entryset只是遍历了第一次，它把key和value都放到了entry中，所以entrySet效率较高 HashMap(数组+ 链表+ 红黑树)HashMap是最常用的Map，它根据键的HashCode值存储数据，根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。因为键对象不可以重复，所以HashMap最多只允许一条记录的键为Null，允许多条记录的值为Null，是非同步的 HashMap是无序的散列映射表； HashMap通过Hash 算法来决定存储位置 底层实现是哈希表java7实现大方向上，HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。上图中，每个绿色的实体是嵌套类 Entry 的实例，Entry 包含四个属性：key, value, hash 值和用于单向链表的 next。 capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。 loadFactor：负载因子，默认为 0.75。 threshold：扩容的阈值，等于 capacity * loadFactorjava8实现 Java8 对 HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+红黑树 组成。 根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。为了降低这部分的开销，在 Java8 中，当链表中的元素超过了 8 个以后，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。 ConcurrentHashMap（线程安全） JDK1.7分析：ConcurrentHashMap采用 分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构 JDK1.8分析：1.8的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构 CAS的思想：三个参数，一个当前内存值V、旧的预期值A、即将更新的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。 Segment 段ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一些。整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为分段锁。 线程安全（Segment 继承 ReentrantLock 加锁）ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。 并行度（默认 16 ）concurrencyLevel：并行级别、并发数、Segment 数。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。 HashtableHashtable与HashMap类似，是HashMap的线程安全版，它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了Hashtale在写入时会比较慢，它继承自Dictionary类，不同的是它不允许记录的键或者值为null，同时效率较低 TreeMapTreeMap实现SortMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序（自然顺序），也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。不允许key值为空，非同步的 适用于按自然顺序或自定义顺序遍历键(key)。 底层是二叉树 提供compareTo，可以定义排序方法 LinkedHashMapLinkedHashMap保存了记录的插入顺序，在用Iteraor遍历LinkedHashMap时，先得到的记录肯定是先插入的，在遍历的时候会比HashMap慢，有HashMap的全部特性。 主要实现类区别Vector VS ArrayList vector是线程同步的，所以它也是线程安全的，而arraylist是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用arraylist效率比较高。 如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%，而arraylist增长率为目前数组长度的50%。如果在集合中使用数据量比较大的数据，用vector有一定的优势。 如果查找一个指定位置的数据，vector和arraylist使用的时间是相同的，如果频繁的访问数据，这个时候使用vector和arraylist都可以。而如果移动一个指定位置会导致后面的元素都发生移动，这个时候就应该考虑到使用linklist,因为它移动一个指定位置的数据时其它元素不移动。 ArrayList 和Vector是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，都允许直接序号索引元素，但是插入数据要涉及到数组元素移动等内存操作，所以索引数据快，插入数据慢，Vector由于使用了synchronized方法（线程安全）所以性能上比ArrayList要差，LinkedList使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快 ArrayList VS LinkedList ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 这一点要看实际情况的。若只对单条数据插入或删除，ArrayList的速度反而优于LinkedList。但若是批量随机的插入删除数据，LinkedList的速度大大优于ArrayList. 因为ArrayList每插入一条数据，要移动插入点及之后的所有数据 HashMap VS TreeMap HashMap通过hashcode对其内容进行快速查找，而TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。 在Map 中插入、删除和定位元素，HashMap是最好的选择。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现。两个map中的元素一样，但顺序不一样，导致hashCode()不一样。同样做测试：123在HashMap中，同样的值的map,顺序不同，equals时，false;而在treeMap中，同样的值的map,顺序不同,equals时，true，说明treeMap在equals()时是整理了顺序了的 HashTable VS HashMap 同步性:Hashtable是线程安全的，也就是说是同步的，而HashMap是线程序不安全的，不是同步的。 HashMap允许存在一个为null的key，多个为null的value 。 hashtable的key和value都不允许为null 参考：JAVA集合类汇总、深入理解Java集合]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之JVM：类加载机制]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8BJVM%EF%BC%9A%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[面试题1234567891011121314151617181920212223242526272829303132333435363738394041class SingletonA&#123; private static SingletonA singleton = new SingletonA(); public static int a; public static int b= 0; private SingletonA()&#123; a++; b++; &#125; public static SingletonA getInstance()&#123; return singleton; &#125;&#125;class SingletonB&#123; public static int a; public static int b= 0; private static SingletonB singleton = new SingletonB(); private SingletonB()&#123; a++; b++; &#125; public static SingletonB getInstance()&#123; return singleton; &#125;&#125;public static void main(String[] args) &#123; SingletonA singleton = SingletonA.getInstance(); System.out.println(&quot;SingletonA a:&quot; + singleton.a); System.out.println(&quot;SingletonA b:&quot; + singleton.b); SingletonB singleton = SingletonB .getInstance(); System.out.println(&quot;SingletonB a:&quot; + singleton.a); System.out.println(&quot;SingletonB b:&quot; + singleton.b); &#125; 运行的结果：1234SingletonA a: 1 SingletonA b: 0 SingletonB a: 1 SingletonB b: 1 SingletonA 解析过程：1234567891011121、首先执行main中的SingletonA singleton = SingletonA .getInstance(); 2、类的加载：加载类SingletonA 3、类的验证 4、类的准备：为静态变量分配内存，设置默认值。这里为singleton(引用类型)设置为null,a,b（基本数据类型）设置默认值0 5、类的初始化（按照赋值语句进行修改）： 执行private static SingletonA singleton = new SingletonA(); 执行SingletonA 的构造器：a++;b++; 此时a，b均等于1 执行 public static int a; public static int b= 0; 此时a=1，b=0 SingletonB 解析过程：123456789101112131、首先执行main中的SingletonB singleton = SingletonB.getInstance(); 2、类的加载：加载类SingletonB3、类的验证 4、类的准备：为静态变量分配内存，设置默认值。这里为a,b（基本数据类型）设置默认值0,singleton(引用类型)设置为null, 5、类的初始化（按照赋值语句进行修改）： 执行 public static int value2 = 0; 此时value2=0(value1不变，依然是0); 执行 private static SingletonB singleton = new SingletonB(); 执行SingletonB的构造器：a++;b++; 此时a，b均等于1,即为最后结果 含义类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产出是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向我们提供了访问方法区内的数据结构的接口。 类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误(LinkageError错误)如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误 加载.class文件的方式： 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 生命周期其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 加载查找并加载类的二进制数据加载时类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 加载方式： 命令行启动应用时候由JVM初始化加载 通过Class.forName()方法动态加载 通过ClassLoader.loadClass()方法动态加载 Class.forName()和ClassLoader.loadClass()加载的区别： Class.forName()：将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块； ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。 Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。连接验证 验证：确保被加载的类的正确性 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型等等。 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外、这个类的父类是否继承了不允许被继承的类等等。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行，如果无法通过符号引用验证，那么将会抛出一个java.lang.IncompatibleClassChangeError异常的子类… 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备 正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。 这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。 假设一个类变量的定义为： 1public static int value = 520； 那么变量value在准备阶段过后的初始值为0，而不是520，因为这时候尚未开始执行任何Java方法，而把value赋值为520的public static指令是在程序编译后，存放于类构造器()方法之中的，所以把value赋值为520的动作将在初始化阶段才会执行。 如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。 假设上面的类变量value被定义为： 1public static final int value = 524； 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为524。可以理解为static final常量在编译期就将其结果放入了常量池中。 解析 虚拟机将常量池内的符号引用替换成直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 符号引用：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时可以无歧义的定位到目标即可。直接引用：可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。 初始化初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式： 声明类变量是指定初始值 使用静态代码块为类变量指定初始值 JVM初始化步骤： 假如这个类还没有被加载和连接，则程序先加载并连接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有初始化语句，则系统依次执行这些初始化语句 虚拟机规范严格规定了有且只有5中情况（jdk1.7）必须对类进行“初始化”（加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic、invokestatic这四条字节码指令时，如果类还没有进行过初始化，则需要先触发其初始化。生成这四条指令最常见的Java场景是：使用new关键字实例化对象时、读取或设置一个类的静态字段（static）时（被static修饰又被final修饰的，已在编译期把结果放入常量池的静态字段除外）、以及调用一个类的静态方法时。 使用Java.lang.refect包的方法对类进行反射调用时(比如：Class.forName(“com.lzt.Test”))，如果类还没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先执行该主类。 当使用jdk1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 虚拟机规定只有这五种情况才会触发类的初始化，称为对一个类进行主动引用，除此之外所有引用类的方式都不会触发其初始化，称为被动引用。下面举一些例子来说明被动引用。 通过子类引用父类中的静态字段，这时对子类的引用为被动引用，因此不会初始化子类，只会初始化父类12345678910111213141516171819class Father&#123; public static int f= 66; static&#123; System.out.println(&quot;父类初始化&quot;); &#125;&#125; class Child extends Father&#123; static&#123; System.out.println(&quot;子类初始化&quot;); &#125;&#125; public class StaticTest&#123; public static void main(String[] args)&#123; System.out.println(Child.f); &#125;&#125; 输出的结果如下：12父类初始化66 对于静态字段，只有直接定义这个字段的类才会被初始化，因此，通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。 常量在编译阶段会存入调用它的类的常量池中，本质上没有直接引用到定义该常量的类，因此不会触发定义常量的类的初始化12345678910111213class Contant&#123; public static final String NAME = &quot;常量哦哦哦&quot;; static&#123; System.out.println(&quot;初始化Contant类&quot;); &#125;&#125; public class Test&#123; public static void main(String[] args)&#123; System.out.println(Contant.NAME); &#125;&#125; 执行后输出的结果如下：1常量哦哦哦 虽然程序中引用了Contant类的常量NAME，但是在编译阶段将此常量的值“我是常量”存储到了调用它的类Test的常量池中，对常量Contant.NAME的引用实际上转化为了Test类对自身常量池的引用。也就是说，实际上Test的Class文件之中并没有Contant类的符号引用入口，这两个类在编译成Class文件后就不存在任何联系了。 通过数组定义来引用类，不会触发类的初始化1234567891011class Contant&#123; static&#123; System.out.println(&quot;初始化Contant&quot;); &#125;&#125; public class ArrayTest&#123; public static void main(String[] args)&#123; Contant[] contant= new Contant[6]; &#125;&#125; 执行后没有输出任何信息，因此Contant类并没有被初始化。 但这段代码里触发了另一个类的初始化，它是一个由虚拟机自动生成的、直接继承于java.lang.Object的子类，创建动作由字节码指令newarray触发，很明显，这是一个对数组引用类型的初初始化，而该数组中的元素仅仅包含一个对Contant类的引用，并没有对其进行初始化。如果我们加入对contant数组中各个Contant类元素的实例化代码，便会触发Contant类的初始化，如下：12345678910111213class Contant&#123; static&#123; System.out.println(&quot;初始化Contant类&quot;); &#125;&#125; public class ArrayTest&#123; public static void main(String[] args)&#123; Contant[] contant= new Contant[6]; for(Contant con:contant) con = new Contant(); &#125;&#125; 这样便会得到如下输出结果：(这里的new触发了Contant类) 1初始化Const类 接口的初始化过程与类初始化过程的不同：接口也有初始化过程，上面的代码中我们都是用静态语句块来输出初始化信息的，而在接口中不能使用“static{}”语句块，但编译器仍然会为接口生成类构造器，用于初始化接口中定义的成员变量（实际上是static final修饰的全局常量）。 二者在初始化时最主要的区别是：当一个类在初始化时，要求其父类全部已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化该父接口。这点也与类初始化的情况很不同，回过头来看第2个例子就知道，调用类中的static final常量时并不会 触发该类的初始化，但是调用接口中的static final常量时便会触发该接口的初始化。 结束生命周期在如下几种情况下，Java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 类加载器 父类加载器并不是通过继承关系来实现的，而是采用组合实现的。 类加载器可以大致划分为以下三类： 启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。 扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.开头的类），开发者可以直接使用扩展类加载器。 应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点： 在执行非置信代码之前，自动验证数字签名。 动态地创建符合用户特定需要的定制化构建类。 从特定的场所取得java class，例如数据库中和网络中。 类加载机制： 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 双亲委派模型双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 双亲委派机制: 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 123456789101112131415161718192021222324252627public Class&lt;?&gt; loadClass(String name)throws ClassNotFoundException &#123; return loadClass(name, false);&#125;protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException &#123; // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) &#123; //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try &#123; if (parent != null) &#123; //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 双亲委派模型意义： 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行 破坏双亲委派模型双亲委派模型很好的解决了各个类加载器加载基础类的统一性问题。即越基础的类由越上层的加载器进行加载。 若加载的基础类中需要回调用户代码，而这时顶层的类加载器无法识别这些用户代码，怎么办呢？这时就需要破坏双亲委派模型了。下面介绍两个例子来讲解破坏双亲委派模型的过程： JNDI破坏双亲委派模型JNDI是Java标准服务，它的代码由启动类加载器去加载。但是JNDI需要回调独立厂商实现的代码，而类加载器无法识别这些回调代码（SPI）。为了解决这个问题，引入了一个线程上下文类加载器。 可通过Thread.setContextClassLoader()设置。 利用线程上下文类加载器去加载所需要的SPI代码，即父类加载器请求子类加载器去完成类加载的过程，而破坏了双亲委派模型。 Spring破坏双亲委派模型 Spring要对用户程序进行组织和管理，而用户程序一般放在WEB-INF目录下，由WebAppClassLoader类加载器加载，而Spring由Common类加载器或Shared类加载器加载。 问：Spring是如何访问WEB-INF下的用户程序呢？答：使用线程上下文类加载器。 Spring加载类所用的classLoader都是通过Thread.currentThread().getContextClassLoader()获取的。当线程创建时会默认创建一个AppClassLoader类加载器（对应Tomcat中的WebAppclassLoader类加载器）： setContextClassLoader(AppClassLoader)。利用这个来加载用户程序。即任何一个线程都可通过getContextClassLoader()获取到WebAppclassLoader。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之JVM：GC垃圾收集器]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8BJVM%EF%BC%9AGC%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Java 堆内存被划分为新生代和年老代两部分，新生代主要使用复制算法 ；年老代主要使用标记-整理和标记-清除垃圾回收算法，因此 java 虚拟中针对新生代和年老代分别提供了多种不同的垃圾收集器，JDK1.6 中 Sun HotSpot 虚拟机的垃圾收集器如下： Serial 收集器（单线程、 复制算法）Serial是最基本垃圾收集器，使用复制算法。Serial 垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器 ParNew 收集器（Serial+多线程 多线程）ParNew 垃圾收集器其实是 Serial 收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样，ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。ParNew 收集器默认开启和 CPU 数目相同的线程数，可通过-XX:ParallelGCThreads参数来限制垃圾收集器的线程数ParNew虽然是除了多线程外和Serial收集器几乎完全一样，但是ParNew垃圾收集器是很多java虚拟机运行在 Server 模式下新生代的默认垃圾收集器 Parallel Scavenge 收集器（多线程复制算法、高效）Parallel Scavenge 收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器，它重点关注的是程序达到一个可控制的吞吐量（Thoughput，CPU 用于运行用户代码的时间/CPU 总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)），高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。自适应调节策略也是ParallelScavenge 收集器与 ParNew 收集器的一个重要区别。 Serial Old 收集器（单线程标记整理算法）Serial Old 是 Serial 垃圾收集器年老代版本，它同样是个单线程的收集器，使用标记-整理算法，这个收集器也主要是运行在 Client 默认的 java 虚拟机默认的年老代垃圾收集器。 Parallel Old 收集器（多线程标记整理算法）Parallel Old收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在JDK1.6才开始提供。在 JDK1.6 之前，新生代使用 ParallelScavenge 收集器只能搭配年老代的 Serial Old 收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old 正是为了在年老代同样提供吞吐量优先的垃圾收集器，如果系统对吞吐量要求比较高，可以优先考虑新生代 Parallel Scavenge和年老代 Parallel Old 收集器的搭配策略。 CMS 收集器（多线程标记清除算法） CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。是基于多线程的“标记-清除”算法。 初始标记（Stop The World）只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。 并发标记（Stop The World）进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程。 重新标记为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 并发清除清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。 CMS 收集器工作过程： 优点： 并发收集 低停顿 缺点： 对CPU资源非常敏感 无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次的Full GC的产生。 使用“标记-清除”算法会导致大量内存空间碎片（碎片过多，当分配大对象的时候可能无法找到足够大的连续空间进行分配，从而提前触发Full GC） G1收集器Garbage first 垃圾收集器是目前垃圾收集器理论发展的最前沿成果，相比与 CMS 收集器，G1 收集器两个最突出的改进是： 基于标记-整理算法，不产生内存碎片。 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 G1是一款面向服务端应用的垃圾收集器。 并行与并发 分代收集 空间整合 可预测的停顿 G1把堆内存划分为分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但是新生代和老年代不再是物理隔离的了，而是一部分Region(不需要连续)的集合。G1跟踪各个Region里面的垃圾堆积的价值大小(回收所获得的空间大小以及回收所需时间的经验值)，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region(这也是Garbage-First名称的由来)。这种使用Rrgion划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 G1收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之JVM：Java引用类型]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8BJVM%EF%BC%9AJava%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[强引用在 Java 中最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。 软引用软引用需要用 SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。 弱引用弱引用需要用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。 虚引用虚引用需要 PhantomReference 类来实现，它不能单独使用，必须和引用队列联合使用。虚引用的主要作用是跟踪对象被垃圾回收的状态。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之JVM：垃圾回收与算法]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8BJVM%EF%BC%9A%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%8E%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[如何确定垃圾引用计数法在 Java 中，引用和对象是有关联的。如果要操作对象则必须用引用进行。因此，很显然一个简单的办法是通过引用计数来判断一个对象是否可以回收。每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。 可达性分析从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。 在Java语言中，GC Roots包括： 虚拟机栈中引用的对象。 方法区中类静态属性实体引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 要注意的是，不可达对象不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记过程。两次标记后仍然是可回收对象，则将面临回收。 标记-清除算法“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这种算法虽然实现简单，内存效率高，不易产生碎片，但是最大的问题是可用内存被压缩到了原本的一半。且存活对象增多的话，Copying 算法的效率会大大降低。[图片上传失败…(image-580a95-1553689761459)] 标记-整理算法标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。[图片上传失败…(image-26ac3c-1553689761459)] 分代收集算法GC分代的基本假设：绝大部分对象的生命周期都非常短暂，存活时间短。“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。 内存分配与回收策略内存分配的2种方式： 选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定 指针碰撞Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离 空闲列表Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录回收策略 对象优先在Eden区分配大多数情况下，对象在新生代Eden区分配。当Eden区没有足够的空间进行分配时，虚拟机将发起一次MinorGC。 大对象直接进入老年代所谓的大对象，指的是需要大量连续内存空间的Java对象，典型的大对象就是那种很长的字符串或数组。 长期存活的对象将进入老年代（-XX:MaxTenuringThreshold）当对象在 Survivor 区躲过一次 GC 后，其年龄就会+1。默认情况下年龄到达 15 的对象会被移到老生代中。 动态年龄判断如果在Survivor空间中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄 空间分配担保虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次的Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。 Minor GC与Full GC有什么不一样？ 新生代GC（MinorGC）：指发生在新生代的垃圾收集动作，因为Java对象大都具备朝生夕灭的特性，所以Minor GC 非常频繁，一般回收速度也比较快； 老年代GC（Major GC / Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温系列之JVM：内存区域]]></title>
    <url>%2F2019%2F03%2F%E9%87%8D%E6%B8%A9%E7%B3%BB%E5%88%97%E4%B9%8BJVM%EF%BC%9A%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[JVM内存区域 线程私有：【程序计数器、虚拟机栈、本地方法栈】 线程共享：【方法区（永久区）、Java堆】—–线程共享区域随虚拟机的启动/关闭而创建/销毁 直接内存：直接内存并不是 JVM 运行时数据区的一部分, 但也会被频繁的使用: 在 JDK 1.4 引入的 NIO 提供了基于 Channel 与 Buffer 的 IO 方式, 它可以使用 Native 函数库直接分配堆外内存, 然后使用DirectByteBuffer 对象作为这块内存的引用进行操作(详见: Java I/O 扩展), 这样就避免了在 Java堆和 Native 堆中来回复制数据, 因此在一些场景中可以显著提高性能。 线程私有数据区域生命周期与线程相同, 依赖用户线程的启动/结束 而 创建/销毁(在 Hotspot VM内， 每个线程都与操作系统的本地线程直接映射, 因此这部分内存区域的存/否跟随本地线程的生/死对应） 程序计数器( 线程私有)一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，每条线程都要有一个独立的程序计数器，这类内存也称为“线程私有”的内存。正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址）。如果还是 Native 方法，则为空。这个内存区域是唯一一个在虚拟机中没有规定任何 OutOfMemoryError 情况的区域。 虚拟机栈( 线程私有)虚拟机栈是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接(Dynamic Linking)、 方法返回值和异常分派（ Dispatch Exception）。栈帧随着方法调用而创建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算作方法结束。 本地方法区( 线程私有)本地方法区和 Java Stack 作用类似, 区别是虚拟机栈为执行 Java 方法服务, 而本地方法栈则为Native 方法服务, 如果一个 VM 实现使用 C-linkage 模型来支持 Native 调用, 那么该栈将会是一个C 栈，但 HotSpot VM 直接就把本地方法栈和虚拟机栈合二为一。 堆（Heap- 线程共享）- 运行时数据区是被线程共享的一块内存区域，创建的对象和数组都保存在 Java 堆内存中，也是垃圾收集器进行垃圾收集的最重要的内存区域。由于现代 VM 采用分代收集算法, 因此 Java 堆从 GC 的角度还可以细分为: 新生代( Eden 区 、 From Survivor 区 和 To Survivor 区 )和老年代。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区/永久代（线程共享）永久代(Permanent Generation), 用于存储被 JVM 加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 HotSpot VM把GC分代收集扩展至方法区, 即使用Java堆的永久代来实现方法区, 这样 HotSpot 的垃圾收集器就可以像管理 Java 堆一样管理这部分内存,而不必为方法区开发专门的内存管理器(永久带的内存回收的主要目标是针对常量池的回收和类型的卸载, 因此收益一般很小)。 运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述等信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 Java 虚拟机对 Class 文件的每一部分（自然也包括常量池）的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的要求，这样才会被虚拟机认可、装载和执行。 JVM运行时内存 Java 堆从 GC 的角度还可以细分为: 新生代( Eden 区 、 From Survivor 区 和 To Survivor 区 )和老年代。 新生代 是用来存放新生的对象。一般占据堆的1/3空间。由于频繁创建对象，所以新生代会频繁触发MinorGC 进行垃圾回收。新生代又分为 Eden 区、FromSurvivor、ToSurvivor 三个区。 Eden区Java新对象的出生地（如果新创建的对象占用内存很大，则直接分配到老年代）。当Eden区内存不够的时候就会触发MinorGC，对新生代区进行一次垃圾回收。 From Survivor上一次 GC 的幸存者，作为这一次 GC 的被扫描者。 To Survivor保留了一次 MinorGC 过程中的幸存者。 MinorGC的过程（复制-&gt;清空-&gt;互换）MinorGC 采用复制算法。 Eden、FromSurvivor复制到 ToSurvivor，年龄+1首先，把 Eden和 FromSurvivor区域中存活的对象复制到 ToSurvivor区域（如果有对象的年龄以及达到了老年的标准，则复制到老年代区），同时把这些对象的年龄+1（如果 ToSurvivor不够位置了就放到老年区）； 清空 Eden 、 FromSurvivor然后，清空 Eden 和 FromSurvivor中的对象； ToSurvivor和 FromSurvivor互换最后，ToSurvivor和 FromSurvivor互换，原 ToSurvivor成为下一次 GC 时的 FromSurvivor区。 老年代 主要存放应用程序中生命周期长的内存对象。 老年代的对象比较稳定，所以 MajorGC 不会频繁执行。在进行 MajorGC 前一般都先进行了一次 MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次 MajorGC 进行垃圾回收腾出空间。 MajorGC 采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没有标记的对象。MajorGC 的耗时比较长，因为要扫描再回收。MajorGC 会产生内存碎片，为了减少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满了装不下的时候，就会抛出 OOM（Out of Memory）异常。 永久代指内存的永久保存区域，主要存放 Class 和 Meta（元数据）的信息,Class 在被加载的时候被放入永久区域，它和和存放实例的区域不同,GC 不会在主程序运行期对永久区域进行清理。所以这也导致了永久代的区域会随着加载的 Class 的增多而胀满，最终抛出 OOM 异常。 JAVA8 与元数据在Java8中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间的本质和永久代类似，元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入 nativememory, 字符串池和类的静态变量放入 java 堆中，这样可以加载多少类的元数据就不再由MaxPermSize 控制, 而由系统的实际可用空间来控制。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>重温</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最近]]></title>
    <url>%2F2018%2F12%2F%E6%9C%80%E8%BF%91%2F</url>
    <content type="text"><![CDATA[做一个有想法的人。 年初的目标还没有完成，却已到了年底啊啊啊啊啊啊啊。 有很多想做想学想去改变的东西，三分钟热度撑不住想法，坚持才行。 五月份，在选择的关卡，其实并没有深入的去了解自己想去想做的事情，很片面，也很幼稚的去做出决定。一段较为纠结的时间段，可能让自己学到的，就是知道了自己不想做什么事情，想做什么。 十一月份是新的开始，也是新的挑战，一个人，能做事，且做好。 世界很大，我想去看看，更想带你去看看。 是随便乱写的哈哈哈，希望明年的自己更Xiang Yang。]]></content>
      <categories>
        <category>我的</category>
      </categories>
      <tags>
        <tag>我的</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存与数据库一致性之缓存穿透、缓存雪崩、key重建方案]]></title>
    <url>%2F2018%2F10%2F%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%80%E8%87%B4%E6%80%A7%E4%B9%8B%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81key%E9%87%8D%E5%BB%BA%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[缓存穿透预防及优化 缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，但是出于容错的考虑，如果从存储层查不到数据则不写入缓存层 如下图所示整个过程分为如下 3 步： 缓存层不命中 存储层不命中，所以不将空结果写回缓存 返回空结果 缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。 缓存穿透问题可能会使后端存储负载加大，由于很多后端存储不具备高并发性，甚至可能造成后端存储宕掉。通常可以在程序中分别统计总调用数、缓存层命中数、存储层命中数，如果发现大量存储层空命中，可能就是出现了缓存穿透问题。造成缓存穿透的基本有两个： 第一，业务自身代码或者数据出现问题 第二，一些恶意攻击、爬虫等造成大量空命中 缓存穿透的解决方法缓存空对象如下图所示，当第 2 步存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取，保护了后端数据源。 缓存空对象会有两个问题： 空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间（如果是攻击，问题更严重）比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。 缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为 5 分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。 布隆过滤器拦截 这种方法适用于数据命中不高，数据相对固定实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少。 如下图所示，在访问缓存层和存储层之前，将存在的 key 用布隆过滤器提前保存起来，做第一层拦截。 例如： 一个个性化推荐系统有 4 亿个用户 ID，每个小时算法工程师会根据每个用户之前历史行为做出来的个性化放到存储层中，但是最新的用户由于没有历史行为，就会发生缓存穿透的行为，为此可以将所有有个性化推荐数据的用户做成布隆过滤器。如果布隆过滤器认为该用户 ID 不存在，那么就不会访问存储层，在一定程度保护了存储层。 有关布隆过滤器的相关知识，可以参考： Bloom Filter(布隆过滤器)的概念和原理可以利用 Redis 的 Bitmaps 实现布隆过滤器，GitHub 上已经开源了类似的方案，读者可以进行参考 方案对比 解决缓存穿透 适用场景 维护成本 缓存空对象 1、数据命中不高 2、 数据频繁变化实时性高 1、代码维护简单 2、需要过多的缓存空间 3、数据不一致 布隆过滤器 1、数据命中不高 2、数据相对固定实时性低 1、代码维护复杂 2、缓存空间占用少 缓存雪崩问题优化由于缓存层承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。缓存雪崩的英文原意是 stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。 预防和解决缓存雪崩问题，可以从以下三个方面进行着手: 保证缓存层服务高可用性如果缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如前面介绍过的 Redis Sentinel 和 Redis Cluster 都实现了高可用 依赖隔离组件为后端限流并降级无论是缓存层还是存储层都会有出错的概率，可以将它们视同为资源。作为并发量较大的系统，假如有一个资源不可用，可能会造成线程全部 hang 在这个资源上，造成整个系统不可用。降级在高并发系统中是非常正常的：比如推荐服务中，如果个性化推荐服务不可用，可以降级补充热点数据，不至于造成前端页面是开天窗。 在实际项目中，我们需要对重要的资源 ( 例如 Redis、 MySQL、 Hbase、外部接口 ) 都进行隔离，让每种资源都单独运行在自己的线程池中，即使个别资源出现了问题，对其他服务没有影响。但是线程池如何管理，比如如何关闭资源池，开启资源池，资源池阀值管理，这些做起来还是相当复杂的，这里推荐一个 Java 依赖隔离工具 Hystrix 提前演练在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定 缓存热点key重建优化使用缓存 + 过期时间的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求。但是有两个问题如果同时出现，可能就会对应用造成致命的危害： 当前 key 是一个热点 key( 例如一个热门的娱乐新闻），并发量非常大。 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次 IO、多个依赖等。 在缓存失效的瞬间，有大量线程来重建缓存 ( 如下图)，造成后端负载加大，甚至可能会让应用崩溃。 热点key失效后大量线程重建缓存 要解决这个问题也不是很复杂，但是不能为了解决这个问题给系统带来更多的麻烦，所以需要制定如下目标: 减少重建缓存的次数 数据尽可能一致 较少的潜在危险 互斥锁(mutex key)此方法只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可，整个过程如图 : 下面代码使用 Redis 的 setnx 命令实现上述功能。 从Redis获取数据，如果值不为空，则直接返回值，否则往下执行 如果 set(nx 和 ex) 结果为 true，说明此时没有其他线程重建缓存，那么当前线程执行缓存构建逻辑。 如果 setnx(nx 和 ex) 结果为 false，说明此时已经有其他线程正在执行构建缓存的工作，那么当前线程将休息指定时间(例如这里是50毫秒，取决于构建缓存的速度)后，重新执行函数，直到获取到数据。 永远不过期 从缓存层面来看，确实没有设置过期时间，所以不会出现热点 key 过期后产生的问题，也就是“物理”不过期。 从功能层面来看，为每个 value 设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。整个过程如下图所示： 从实战看，此方法有效杜绝了热点key产生的问题，但唯一不足的就是重构缓存期间，会出现数据不一致的情况，这取决于应用方是否容忍这种不一致。下面代码使用 Redis 进行模拟： 对比作为一个并发量较大的应用，在使用缓存时有三个目标: 加快用户访问速度，提高用户体验。 降低后端负载，减少潜在的风险，保证系统平稳。 保证数据“尽可能”及时更新。 互斥锁 (mutex key)： 这种方案思路比较简单，但是存在一定的隐患，如果构建缓存过程出现问题或者时间较长，可能会存在死锁和线程池阻塞的风险，但是这种方法能够较好的降低后端存储负载并在一致性上做的比较好。永远不过期：这种方案由于没有设置真正的过期时间，实际上已经不存在热点 key 产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。 解决方案 优点 缺点 简单分布式锁 1、思路简单2、保证一致性 1、代码复杂性增大 2、存在死锁的风险3、存在线程池阻塞的风险 “永远不过期” 基本杜绝热点key问题 1、可能存在数据不一致 2、增加代码维护成本以及内存成本 参考]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从ConcurrentHashMap看Java多线程核心技术]]></title>
    <url>%2F2018%2F10%2F%E4%BB%8EConcurrentHashMap%E7%9C%8BJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[本文转发自技术世界，原文链接 http://www.jasongj.com/java/concurrenthashmap/ 注：本章的代码均基于JDK 1.7.0_67 线程不安全的HashMap众所周知，HashMap是非线程安全的。而HashMap的线程不安全主要体现在resize时的死循环及使用迭代器时的fast-fail上。 HashMap工作原理HashMap数据结构常用的底层数据结构主要有数组和链表。数组存储区间连续，占用内存较多，寻址容易，插入和删除困难。链表存储区间离散，占用内存较少，寻址困难，插入和删除容易。 HashMap要实现的是哈希表的效果，尽量实现O(1)级别的增删改查。它的具体实现则是同时使用了数组和链表，可以认为最外层是一个数组，数组的每个元素是一个链表的表头。 HashMap寻址方式对于新插入的数据或者待读取的数据，HashMap将Key的哈希值对数组长度取模，结果作为该Entry在数组中的index。在计算机中，取模的代价远高于位操作的代价，因此HashMap要求数组的长度必须为2的N次方。此时将Key的哈希值对2^N-1进行与运算，其效果即与取模等效。HashMap并不要求用户在指定HashMap容量时必须传入一个2的N次方的整数，而是会通过Integer.highestOneBit算出比指定整数小的最大的2^N值，其实现方法如下。12345678public static int highestOneBit(int i) &#123; i |= (i &gt;&gt; 1); i |= (i &gt;&gt; 2); i |= (i &gt;&gt; 4); i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1);&#125; 由于Key的哈希值的分布直接决定了所有数据在哈希表上的分布或者说决定了哈希冲突的可能性，因此为防止糟糕的Key的hashCode实现（例如低位都相同，只有高位不相同，与2^N-1取与后的结果都相同），JDK 1.7的HashMap通过如下方法使得最终的哈希值的二进制形式中的1尽量均匀分布从而尽可能减少哈希冲突。 1234int h = hashSeed;h ^= k.hashCode();h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); resize死循环transfer方法当HashMap的size超过Capacity*loadFactor时，需要对HashMap进行扩容。具体方法是，创建一个新的，长度为原来Capacity两倍的数组，保证新的Capacity仍为2的N次方，从而保证上述寻址方式仍适用。同时需要通过如下transfer方法将原来的所有数据全部重新插入（rehash）到新的数组中。 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 该方法并不保证线程安全，而且在多线程并发调用时，可能出现死循环。其执行过程如下。从步骤2可见，转移时链表顺序反转。 遍历原数组中的元素 对链表上的每一个节点遍历：用next取得要转移那个元素的下一个，将e转移到新数组的头部，使用头插法插入节点 循环2，直到链表节点全部转移 循环1，直到所有元素全部转移 单线程rehash单线程情况下，rehash无问题。下图演示了单线程条件下的rehash过程 多线程并发下的rehash这里假设有两个线程同时执行了put操作并引发了rehash，执行了transfer方法，并假设线程一进入transfer方法并执行完next = e.next后，因为线程调度所分配时间片用完而“暂停”，此时线程二完成了transfer方法的执行。此时状态如下。 接着线程1被唤醒，继续执行第一轮循环的剩余部分 123e.next = newTable[1] = nullnewTable[1] = e = key(5)e = next = key(9) 结果如下图所示: 接着执行下一轮循环，结果状态图如下所示: 继续下一轮循环，结果状态图如下所示: 此时循环链表形成，并且key(11)无法加入到线程1的新数组。在下一次访问该链表时会出现死循环。 Fast-fail产生原因在使用迭代器的过程中如果HashMap被修改，那么ConcurrentModificationException将被抛出，也即Fast-fail策略。 当HashMap的iterator()方法被调用时，会构造并返回一个新的EntryIterator对象，并将EntryIterator的expectedModCount设置为HashMap的modCount（该变量记录了HashMap被修改的次数）。 12345678HashIterator() &#123; expectedModCount = modCount; if (size &gt; 0) &#123; // advance to first entry Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125;&#125; 在通过该Iterator的next方法访问下一个Entry时，它会先检查自己的expectedModCount与HashMap的modCount是否相等，如果不相等，说明HashMap被修改，直接抛出ConcurrentModificationException。该Iterator的remove方法也会做类似的检查。该异常的抛出意在提醒用户及早意识到线程安全问题。 线程安全解决方案单线程条件下，为避免出现ConcurrentModificationException，需要保证只通过HashMap本身或者只通过Iterator去修改数据，不能在Iterator使用结束之前使用HashMap本身的方法修改数据。因为通过Iterator删除数据时，HashMap的modCount和Iterator的expectedModCount都会自增，不影响二者的相等性。如果是增加数据，只能通过HashMap本身的方法完成，此时如果要继续遍历数据，需要重新调用iterator()方法从而重新构造出一个新的Iterator，使得新Iterator的expectedModCount与更新后的HashMap的modCount相等。 多线程条件下，可使用Collections.synchronizedMap方法构造出一个同步Map，或者直接使用线程安全的ConcurrentHashMap。 Java 7基于分段锁的ConcurrentHashMap数据结构Java 7中的ConcurrentHashMap的底层数据结构仍然是数组和链表。与HashMap不同的是，ConcurrentHashMap最外层不是一个大的数组，而是一个Segment的数组。每个Segment包含一个与HashMap数据结构差不多的链表数组。整体数据结构如下图所示。 寻址方式在读写某个Key时，先取该Key的哈希值。并将哈希值的高N位对Segment个数取模从而得到该Key应该属于哪个Segment，接着如同操作HashMap一样操作这个Segment。为了保证不同的值均匀分布到不同的Segment，需要通过如下方法计算哈希值。 12345678910111213private int hash(Object k) &#123; int h = hashSeed; if ((0 != h) &amp;&amp; (k instanceof String)) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h += (h &lt;&lt; 15) ^ 0xffffcd7d; h ^= (h &gt;&gt;&gt; 10); h += (h &lt;&lt; 3); h ^= (h &gt;&gt;&gt; 6); h += (h &lt;&lt; 2) + (h &lt;&lt; 14); return h ^ (h &gt;&gt;&gt; 16);&#125; 同样为了提高取模运算效率，通过如下计算，ssize即为大于concurrencyLevel的最小的2的N次方，同时segmentMask为2^N-1。这一点跟上文中计算数组长度的方法一致。对于某一个Key的哈希值，只需要向右移segmentShift位以取高sshift位，再与segmentMask取与操作即可得到它在Segment数组上的索引。 123456789int sshift = 0;int ssize = 1;while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1;&#125;this.segmentShift = 32 - sshift;this.segmentMask = ssize - 1;Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; 同步方式Segment继承自ReentrantLock，所以我们可以很方便的对每一个Segment上锁。 对于读操作，获取Key所在的Segment时，需要保证可见性(请参考如何保证多线程条件下的可见性)。具体实现上可以使用volatile关键字，也可使用锁。但使用锁开销太大，而使用volatile时每次写操作都会让所有CPU内缓存无效，也有一定开销。ConcurrentHashMap使用如下方法保证可见性，取得最新的Segment。 1Segment&lt;K,V&gt; s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u) 获取Segment中的HashEntry时也使用了类似方法12HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE) 对于写操作，并不要求同时获取所有Segment的锁，因为那样相当于锁住了整个Map。它会先获取该Key-Value对所在的Segment的锁，获取成功后就可以像操作一个普通的HashMap一样操作该Segment，并保证该Segment的安全性。同时由于其它Segment的锁并未被获取，因此理论上可支持concurrencyLevel（等于Segment的个数）个线程安全的并发读写。 获取锁时，并不直接使用lock来获取，因为该方法获取锁失败时会挂起（参考可重入锁）。事实上，它使用了自旋锁，如果tryLock获取锁失败，说明锁被其它线程占用，此时通过循环再次以tryLock的方式申请锁。如果在循环过程中该Key所对应的链表头被修改，则重置retry次数。如果retry次数超过一定值，则使用lock方法申请锁。 这里使用自旋锁是因为自旋锁的效率比较高，但是它消耗CPU资源比较多，因此在自旋次数超过阈值时切换为互斥锁。 size操作put、remove和get操作只需要关心一个Segment，而size操作需要遍历所有的Segment才能算出整个Map的大小。一个简单的方案是，先锁住所有Sgment，计算完后再解锁。但这样做，在做size操作时，不仅无法对Map进行写操作，同时也无法进行读操作，不利于对Map的并行操作。 为更好支持并发操作，ConcurrentHashMap会在不上锁的前提逐个Segment计算3次size，如果某相邻两次计算获取的所有Segment的更新次数（每个Segment都与HashMap一样通过modCount跟踪自己的修改次数，Segment每修改一次其modCount加一）相等，说明这两次计算过程中无更新操作，则这两次计算出的总size相等，可直接作为最终结果返回。如果这三次计算过程中Map有更新，则对所有Segment加锁重新计算Size。该计算方法代码如下 12345678910111213141516171819202122232425262728293031323334353637public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn&apos;t retry try &#123; for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; 不同之处ConcurrentHashMap与HashMap相比，有以下不同点: ConcurrentHashMap线程安全，而HashMap非线程安全 HashMap允许Key和Value为null，而ConcurrentHashMap不允许 HashMap不允许通过Iterator遍历的同时通过HashMap修改，而ConcurrentHashMap允许该行为，并且该更新对后续的遍历可见 Java 8基于CAS的ConcurrentHashMap数据结构Java 7为实现并行访问，引入了Segment这一结构，实现了分段锁，理论上最大并发度与Segment个数相等。Java 8为进一步提高并发性，摒弃了分段锁的方案，而是直接使用一个大的数组。同时为了提高哈希碰撞下的寻址性能，Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N))）。其数据结构如下图所示 寻址方式Java 8的ConcurrentHashMap同样是通过Key的哈希值与数组长度取模确定该Key在数组中的索引。同样为了避免不太好的Key的hashCode设计，它通过如下方法计算得到Key的最终哈希值。不同的是，Java 8的ConcurrentHashMap作者认为引入红黑树后，即使哈希冲突比较严重，寻址效率也足够高，所以作者并未在哈希值的计算上做过多设计，只是将Key的hashCode值与其高16位作异或并保证最高位为0（从而保证最终结果为正整数）。 123static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; 同步方式对于put操作，如果Key对应的数组元素为null，则通过CAS操作将其设置为当前值。如果Key对应的数组元素（也即链表表头或者树的根元素）不为null，则对该元素使用synchronized关键字申请锁，然后进行操作。如果该put操作使得当前链表长度超过一定阈值，则将该链表转换为树，从而提高寻址效率。 对于读操作，由于数组被volatile关键字修饰，因此不用担心数组的可见性问题。同时每个元素是一个Node实例（Java 7中每个元素是一个HashEntry），它的Key值和hash值都由final修饰，不可变更，无须关心它们被修改后的可见性问题。而其Value及对下一个元素的引用由volatile修饰，可见性也有保障。 123456static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next;&#125; 对于Key对应的数组元素的可见性，由Unsafe的getObjectVolatile方法保证。 123static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; size操作put方法和remove方法都会通过addCount方法维护Map的size。size方法通过sumCount获取由addCount方法维护的Map的size。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程相关技术点]]></title>
    <url>%2F2018%2F09%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E7%82%B9%2F</url>
    <content type="text"><![CDATA[本文转发自技术世界，原文链接 http://www.jasongj.com/java/multi_thread/ sleep和wait到底什么区别其实这个问题应该这么问——sleep和wait有什么相同点。因为这两个方法除了都能让当前线程暂停执行完，几乎没有其它相同点。 wait方法是Object类的方法，这意味着所有的Java类都可以调用该方法。sleep方法是Thread类的静态方法。 wait是在当前线程持有wait对象锁的情况下，暂时放弃锁，并让出CPU资源，并积极等待其它线程调用同一对象的notify或者notifyAll方法。注意，即使只有一个线程在等待，并且有其它线程调用了notify或者notifyAll方法，等待的线程只是被激活，但是它必须得再次获得锁才能继续往下执行。换言之，即使notify被调用，但只要锁没有被释放，原等待线程因为未获得锁仍然无法继续执行。测试代码如下所示 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.Date;public class Wait &#123; public static void main(String[] args) &#123; Thread thread1 = new Thread(() -&gt; &#123; synchronized (Wait.class) &#123; try &#123; System.out.println(new Date() + &quot; Thread1 is running&quot;); Wait.class.wait(); System.out.println(new Date() + &quot; Thread1 ended&quot;); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; &#125;); thread1.start(); Thread thread2 = new Thread(() -&gt; &#123; synchronized (Wait.class) &#123; try &#123; System.out.println(new Date() + &quot; Thread2 is running&quot;); Wait.class.notify(); // Don&apos;t use sleep method to avoid confusing for(long i = 0; i &lt; 200000; i++) &#123; for(long j = 0; j &lt; 100000; j++) &#123;&#125; &#125; System.out.println(new Date() + &quot; Thread2 release lock&quot;); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; for(long i = 0; i &lt; 200000; i++) &#123; for(long j = 0; j &lt; 100000; j++) &#123;&#125; &#125; System.out.println(new Date() + &quot; Thread2 ended&quot;); &#125;); // Don&apos;t use sleep method to avoid confusing for(long i = 0; i &lt; 200000; i++) &#123; for(long j = 0; j &lt; 100000; j++) &#123;&#125; &#125; thread2.start(); &#125;&#125; 执行结果如下 12345Tue Jun 14 22:51:11 CST 2016 Thread1 is runningTue Jun 14 22:51:23 CST 2016 Thread2 is runningTue Jun 14 22:51:36 CST 2016 Thread2 release lockTue Jun 14 22:51:36 CST 2016 Thread1 endedTue Jun 14 22:51:49 CST 2016 Thread2 ended 从运行结果可以看出 thread1执行wait后，暂停执行 thread2执行notify后，thread1并没有继续执行，因为此时thread2尚未释放锁，thread1因为得不到锁而不能继续执行 thread2执行完synchronized语句块后释放锁，thread1得到通知并获得锁，进而继续执行 注意：wait方法需要释放锁，前提条件是它已经持有锁。所以wait和notify（或者notifyAll）方法都必须被包裹在synchronized语句块中，并且synchronized后锁的对象应该与调用wait方法的对象一样。否则抛出IllegalMonitorStateException sleep方法告诉操作系统至少指定时间内不需为线程调度器为该线程分配执行时间片，并不释放锁（如果当前已经持有锁）。实际上，调用sleep方法时并不要求持有任何锁。 12345678910111213141516171819202122232425262728293031323334353637383940package com.test.thread;import java.util.Date;public class Sleep &#123; public static void main(String[] args) &#123; Thread thread1 = new Thread(() -&gt; &#123; synchronized (Sleep.class) &#123; try &#123; System.out.println(new Date() + &quot; Thread1 is running&quot;); Thread.sleep(2000); System.out.println(new Date() + &quot; Thread1 ended&quot;); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; &#125;); thread1.start(); Thread thread2 = new Thread(() -&gt; &#123; synchronized (Sleep.class) &#123; try &#123; System.out.println(new Date() + &quot; Thread2 is running&quot;); Thread.sleep(2000); System.out.println(new Date() + &quot; Thread2 ended&quot;); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; for(long i = 0; i &lt; 200000; i++) &#123; for(long j = 0; j &lt; 100000; j++) &#123;&#125; &#125; &#125;); // Don&apos;t use sleep method to avoid confusing for(long i = 0; i &lt; 200000; i++) &#123; for(long j = 0; j &lt; 100000; j++) &#123;&#125; &#125; thread2.start(); &#125;&#125; 执行结果如下 1234Thu Jun 16 19:46:06 CST 2016 Thread1 is runningThu Jun 16 19:46:08 CST 2016 Thread1 endedThu Jun 16 19:46:13 CST 2016 Thread2 is runningThu Jun 16 19:46:15 CST 2016 Thread2 ended 由于thread 1和thread 2的run方法实现都在同步块中，无论哪个线程先拿到锁，执行sleep时并不释放锁，因此其它线程无法执行。直到前面的线程sleep结束并退出同步块（释放锁），另一个线程才得到锁并执行。 注意：sleep方法并不需要持有任何形式的锁，也就不需要包裹在synchronized中。 本文所有示例均基于Java HotSpot(TM) 64-Bit Server VM 调用sleep方法的线程，在jstack中显示的状态为sleeping。 1java.lang.Thread.State: TIMED_WAITING (sleeping) 调用wait方法的线程，在jstack中显示的状态为on object monitor 1java.lang.Thread.State: WAITING (on object monitor) synchronized几种用法 每个Java对象都可以用做一个实现同步的互斥锁，这些锁被称为内置锁。线程进入同步代码块或方法时自动获得内置锁，退出同步代码块或方法时自动释放该内置锁。进入同步代码块或者同步方法是获得内置锁的唯一途径。 实例同步方法synchronized用于修饰实例方法（非静态方法）时，执行该方法需要获得的是该类实例对象的内置锁（同一个类的不同实例拥有不同的内置锁）。如果多个实例方法都被synchronized修饰，则当多个线程调用同一实例的不同同步方法（或者同一方法）时，需要竞争锁。但当调用的是不同实例的方法时，并不需要竞争锁。 静态同步方法synchronized用于修饰静态方法时，执行该方法需要获得的是该类的class对象的内置锁（一个类只有唯一一个class对象）。调用同一个类的不同静态同步方法时会产生锁竞争。 同步代码块synchronized用于修饰代码块时，进入同步代码块需要获得synchronized关键字后面括号内的对象（可以是实例对象也可以是class对象）的内置锁。 synchronized使用总结锁的使用是为了操作临界资源的正确性，而往往一个方法中并非所有的代码都操作临界资源。换句话说，方法中的代码往往并不都需要同步。此时建议不使用同步方法，而使用同步代码块，只对操作临界资源的代码，也即需要同步的代码加锁。这样做的好处是，当一个线程在执行同步代码块时，其它线程仍然可以执行该方法内同步代码块以外的部分，充分发挥多线程并发的优势，从而相较于同步整个方法而言提升性能。 释放Java内置锁的唯一方式是synchronized方法或者代码块执行结束。若某一线程在synchronized方法或代码块内发生死锁，则对应的内置锁无法释放，其它线程也无法获取该内置锁（即进入跟该内置锁相关的synchronized方法或者代码块）。 使用jstack dump线程栈时，可查看到相关线程通过synchronized获取到或等待的对象，但Locked ownable synchronizers仍然显示为None。下例中，线程thead-test-b已获取到类型为java.lang.Double的对象的内置锁（monitor），且该对象的内存地址为0x000000076ab95cb8 12345678&quot;thread-test-b&quot; #11 prio=5 os_prio=31 tid=0x00007fab0190b800 nid=0x5903 runnable [0x0000700010249000] java.lang.Thread.State: RUNNABLE at com.jasongj.demo.TestJstack.lambda$1(TestJstack.java:27) - locked &lt;0x000000076ab95cb8&gt; (a java.lang.Double) at com.jasongj.demo.TestJstack$$Lambda$2/1406718218.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None Java中的锁重入锁Java中的重入锁（即ReentrantLock）与Java内置锁一样，是一种排它锁。使用synchronized的地方一定可以用ReentrantLock代替。 重入锁需要显示请求获取锁，并显示释放锁。为了避免获得锁后，没有释放锁，而造成其它线程无法获得锁而造成死锁，一般建议将释放锁操作放在finally块里，如下所示。 123456try&#123; renentrantLock.lock(); // 用户操作&#125; finally &#123; renentrantLock.unlock();&#125; 如果重入锁已经被其它线程持有，则当前线程的lock操作会被阻塞。除了lock()方法之外，重入锁（或者说锁接口）还提供了其它获取锁的方法以实现不同的效果。 lockInterruptibly() 该方法尝试获取锁，若获取成功立即返回；若获取不成功则阻塞等待。与lock方法不同的是，在阻塞期间，如果当前线程被打断（interrupt）则该方法抛出InterruptedException。该方法提供了一种解除死锁的途径。 tryLock() 该方法试图获取锁，若该锁当前可用，则该方法立即获得锁并立即返回true；若锁当前不可用，则立即返回false。该方法不会阻塞，并提供给用户对于成功获利锁与获取锁失败进行不同操作的可能性。 tryLock(long time, TimeUnit unit) 该方法试图获得锁，若该锁当前可用，则立即获得锁并立即返回true。若锁当前不可用，则等待相应的时间（由该方法的两个参数决定）：1）若该时间内锁可用，则获得锁，并返回true；2）若等待期间当前线程被打断，则抛出InterruptedException；3）若等待时间结束仍未获得锁，则返回false。 重入锁可定义为公平锁或非公平锁，默认实现为非公平锁。 公平锁是指多个线程获取锁被阻塞的情况下，锁变为可用时，最新申请锁的线程获得锁。可通过在重入锁（RenentrantLock）的构造方法中传入true构建公平锁，如Lock lock = new RenentrantLock(true) 非公平锁是指多个线程等待锁的情况下，锁变为可用状态时，哪个线程获得锁是随机的。synchonized相当于非公平锁。可通过在重入锁的构造方法中传入false或者使用无参构造方法构建非公平锁。 使用jstack dump线程栈时，可查看到获取到或正在等待的锁对象，获取到该锁的线程会在Locked ownable synchronizers处显示该锁的对象类型及内存地址。在下例中，从Locked ownable synchronizers部分可看到，线程thread-test-e获取到公平重入锁，且该锁对象的内存地址为0x000000076ae3d708 1234567&quot;thread-test-e&quot; #17 prio=5 os_prio=31 tid=0x00007fefaa0b6800 nid=0x6403 runnable [0x0000700002939000] java.lang.Thread.State: RUNNABLE at com.jasongj.demo.TestJstack.lambda$4(TestJstack.java:64) at com.jasongj.demo.TestJstack$$Lambda$5/466002798.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - &lt;0x000000076af86810&gt; (a java.util.concurrent.locks.ReentrantLock$FairSync) 而线程thread-test-f由于未获取到锁，而处于WAITING(parking)状态，且它等待的锁正是上文线程thread-test-e获取的锁（内存地址0x000000076af86810） 123456789101112131415&quot;thread-test-f&quot; #18 prio=5 os_prio=31 tid=0x00007fefaa9b2800 nid=0x6603 waiting on condition [0x0000700002a3c000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x000000076af86810&gt; (a java.util.concurrent.locks.ReentrantLock$FairSync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199) at java.util.concurrent.locks.ReentrantLock$FairSync.lock(ReentrantLock.java:224) at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285) at com.jasongj.demo.TestJstack.lambda$5(TestJstack.java:69) at com.jasongj.demo.TestJstack$$Lambda$6/33524623.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None 读写锁锁可以保证原子性和可见性。而原子性更多是针对写操作而言。对于读多写少的场景，一个读操作无须阻塞其它读操作，只需要保证读和写或者写与写不同时发生即可。此时，如果使用重入锁（即排它锁），对性能影响较大。Java中的读写锁（ReadWriteLock）就是为这种读多写少的场景而创造的。 实际上，ReadWriteLock接口并非继承自Lock接口，ReentrantReadWriteLock也只实现了ReadWriteLock接口而未实现Lock接口。ReadLock和WriteLock，是ReentrantReadWriteLock类的静态内部类，它们实现了Lock接口。 一个ReentrantReadWriteLock实例包含一个ReentrantReadWriteLock.ReadLock实例和一个ReentrantReadWriteLock.WriteLock实例。通过readLock()和writeLock()方法可分别获得读锁实例和写锁实例，并通过Lock接口提供的获取锁方法获得对应的锁。 读写锁的锁定规则如下： 获得读锁后，其它线程可获得读锁而不能获取写锁 获得写锁后，其它线程既不能获得读锁也不能获得写锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.test.thread;import java.util.Date;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;public class ReadWriteLockDemo &#123; public static void main(String[] args) &#123; ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); new Thread(() -&gt; &#123; readWriteLock.readLock().lock(); try &#123; System.out.println(new Date() + &quot;\tThread 1 started with read lock&quot;); try &#123; Thread.sleep(2000); &#125; catch (Exception ex) &#123; &#125; System.out.println(new Date() + &quot;\tThread 1 ended&quot;); &#125; finally &#123; readWriteLock.readLock().unlock(); &#125; &#125;).start(); new Thread(() -&gt; &#123; readWriteLock.readLock().lock(); try &#123; System.out.println(new Date() + &quot;\tThread 2 started with read lock&quot;); try &#123; Thread.sleep(2000); &#125; catch (Exception ex) &#123; &#125; System.out.println(new Date() + &quot;\tThread 2 ended&quot;); &#125; finally &#123; readWriteLock.readLock().unlock(); &#125; &#125;).start(); new Thread(() -&gt; &#123; Lock lock = readWriteLock.writeLock(); lock.lock(); try &#123; System.out.println(new Date() + &quot;\tThread 3 started with write lock&quot;); try &#123; Thread.sleep(2000); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; System.out.println(new Date() + &quot;\tThread 3 ended&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;).start(); &#125;&#125; 执行结果如下 123456Sat Jun 18 21:33:46 CST 2016 Thread 1 started with read lockSat Jun 18 21:33:46 CST 2016 Thread 2 started with read lockSat Jun 18 21:33:48 CST 2016 Thread 2 endedSat Jun 18 21:33:48 CST 2016 Thread 1 endedSat Jun 18 21:33:48 CST 2016 Thread 3 started with write lockSat Jun 18 21:33:50 CST 2016 Thread 3 ended 从上面的执行结果可见，thread 1和thread 2都只需获得读锁，因此它们可以并行执行。而thread 3因为需要获取写锁，必须等到thread 1和thread 2释放锁后才能获得锁。 条件锁条件锁只是一个帮助用户理解的概念，实际上并没有条件锁这种锁。对于每个重入锁，都可以通过newCondition()方法绑定若干个条件对象。 条件对象提供以下方法以实现不同的等待语义 await() 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出IllegalMonitorStateException。调用该方法外，当前线程会释放当前已经获得的锁（这一点与上文讲述的Java内置锁的wait方法一致），并且等待其它线程调用该条件对象的signal()或者signalAll()方法（这一点与Java内置锁wait后等待notify()或notifyAll()很像）。或者在等待期间，当前线程被打断，则wait()方法会抛出InterruptedException并清除当前线程的打断状态。 await(long time, TimeUnit unit) 适用条件和行为与await()基本一致，唯一不同点在于，指定时间之内没有收到signal()或signalALL()信号或者线程中断时该方法会返回false;其它情况返回true。 awaitNanos(long nanosTimeout) 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出IllegalMonitorStateException。nanosTimeout指定该方法等待信号的的最大时间（单位为纳秒）。若指定时间内收到signal()或signalALL()则返回nanosTimeout减去已经等待的时间；若指定时间内有其它线程中断该线程，则抛出InterruptedException并清除当前线程的打断状态；若指定时间内未收到通知，则返回0或负数。 awaitUninterruptibly() 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出IllegalMonitorStateException。调用该方法后，结束等待的唯一方法是其它线程调用该条件对象的signal()或signalALL()方法。等待过程中如果当前线程被中断，该方法仍然会继续等待，同时保留该线程的中断状态。 awaitUntil(Date deadline) 适用条件与行为与awaitNanos(long nanosTimeout)完全一样，唯一不同点在于它不是等待指定时间，而是等待由参数指定的某一时刻。 调用条件等待的注意事项 调用上述任意条件等待方法的前提都是当前线程已经获得与该条件对象对应的重入锁。 调用条件等待后，当前线程让出CPU资源。 上述等待方法结束后，方法返回的前提是它能重新获得与该条件对象对应的重入锁。如果无法获得锁，仍然会继续等待。这也是awaitNanos(long nanosTimeout)可能会返回负值的原因。 一旦条件等待方法返回，则当前线程肯定已经获得了对应的重入锁。 重入锁可以创建若干个条件对象，signal()和signalAll()方法只能唤醒相同条件对象的等待。 一个重入锁上可以生成多个条件变量，不同线程可以等待不同的条件，从而实现更加细粒度的的线程间通信。 signal()与signalAll() signal() 若有一个或若干个线程在等待该条件变量，则该方法会唤醒其中的一个（具体哪一个，无法预测）。调用该方法的前提是当前线程持有该条件变量对应的锁，否则抛出IllegalMonitorStateException。 signalALL() 若有一个或若干个线程在等待该条件变量，则该方法会唤醒所有等待。调用该方法的前提是当前线程持有该条件变量对应的锁，否则抛出IllegalMonitorStateException。 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.test.thread;import java.util.Date;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class ConditionTest &#123; public static void main(String[] args) throws InterruptedException &#123; Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); new Thread(() -&gt; &#123; lock.lock(); try &#123; System.out.println(new Date() + &quot;\tThread 1 is waiting&quot;); try &#123; long waitTime = condition.awaitNanos(TimeUnit.SECONDS.toNanos(2)); System.out.println(new Date() + &quot;\tThread 1 remaining time &quot; + waitTime); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; System.out.println(new Date() + &quot;\tThread 1 is waken up&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;).start(); new Thread(() -&gt; &#123; lock.lock(); try&#123; System.out.println(new Date() + &quot;\tThread 2 is running&quot;); try &#123; Thread.sleep(4000); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; condition.signal(); System.out.println(new Date() + &quot;\tThread 2 ended&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;).start(); &#125;&#125; 执行结果如下 12345Sun Jun 19 15:59:09 CST 2016 Thread 1 is waitingSun Jun 19 15:59:09 CST 2016 Thread 2 is runningSun Jun 19 15:59:13 CST 2016 Thread 2 endedSun Jun 19 15:59:13 CST 2016 Thread 1 remaining time -2003467560Sun Jun 19 15:59:13 CST 2016 Thread 1 is waken up 从执行结果可以看出，虽然thread 2一开始就调用了signal()方法去唤醒thread 1，但是因为thread 2在4秒钟后才释放锁，也即thread 1在4秒后才获得锁，所以thread 1的await方法在4秒钟后才返回，并且返回负值。 信号量Semaphore信号量维护一个许可集，可通过acquire()获取许可（若无可用许可则阻塞），通过release()释放许可，从而可能唤醒一个阻塞等待许可的线程。 与互斥锁类似，信号量限制了同一时间访问临界资源的线程的个数，并且信号量也分公平信号量与非公平信号量。而不同的是，互斥锁保证同一时间只会有一个线程访问临界资源，而信号量可以允许同一时间多个线程访问特定资源。所以信号量并不能保证原子性。 信号量的一个典型使用场景是限制系统访问量。每个请求进来后，处理之前都通过acquire获取许可，若获取许可成功则处理该请求，若获取失败则等待处理或者直接不处理该请求。 信号量的使用方法: acquire(int permits) 申请permits（必须为非负数）个许可，若获取成功，则该方法返回并且当前可用许可数减permits；若当前可用许可数少于permits指定的个数，则继续等待可用许可数大于等于permits；若等待过程中当前线程被中断，则抛出InterruptedException。 acquire() 等价于acquire(1)。 acquireUninterruptibly(int permits) 申请permits（必须为非负数）个许可，若获取成功，则该方法返回并且当前可用许可数减permits；若当前许可数少于permits，则继续等待可用许可数大于等于permits；若等待过程中当前线程被中断，继续等待可用许可数大于等于permits，并且获取成功后设置线程中断状态。 acquireUninterruptibly() 等价于acquireUninterruptibly(1)。 drainPermits() 获取所有可用许可，并返回获取到的许可个数，该方法不阻塞。 tryAcquire(int permits) 尝试获取permits个可用许可，如果当前许可个数大于等于permits，则返回true并且可用许可数减permits；否则返回false并且可用许可数不变。 tryAcquire() 等价于tryAcquire(1)。 tryAcquire(int permits, long timeout, TimeUnit unit) 尝试获取permits（必须为非负数）个许可，若在指定时间内获取成功则返回true并且可用许可数减permits；若指定时间内当前线程被中断，则抛出InterruptedException；若指定时间内可用许可数均小于permits，则返回false。 tryAcquire(long timeout, TimeUnit unit) 等价于tryAcquire(1, long timeout, TimeUnit unit)* release(int permits) 释放permits个许可，该方法不阻塞并且某线程调用release方法前并不需要先调用acquire方法。 release() 等价于release(1)。 注意：与wait/notify和await/signal不同，acquire/release完全与锁无关，因此acquire等待过程中，可用许可满足要求时acquire可立即返回，而不用像锁的wait和条件变量的await那样重新获取锁才能返回。或者可以理解成，只要可用许可满足需求，就已经获得了锁。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解ThreadLocal]]></title>
    <url>%2F2018%2F08%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3ThreadLocal%2F</url>
    <content type="text"><![CDATA[本文转发自技术世界，原文链接 http://www.jasongj.com/java/threadlocal/《Java并发编程：深入剖析ThreadLocal》 ThreadLocal的理解 ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储。ThreadLocal 提供了线程本地的实例。它与普通变量的区别在于，每个使用该变量的线程都会初始化一个完全独立的实例副本。ThreadLocal 变量通常被private static修饰。当一个线程结束时，它所使用的所有 ThreadLocal 相对的实例副本都可被回收 ThreadLocal 适用于每个线程需要自己独立的实例且该实例需要在多个方法中被使用，也即变量在线程间隔离而在方法或类间共享的场景 例子： 12345678910111213141516class ConnectionManager &#123; private static Connection connect = null; public static Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public static void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; 假设有这样一个数据库链接管理类，这段代码在单线程中使用是没有任何问题的，但是如果在多线程中使用呢？很显然，在多线程中使用会存在线程安全问题：第一，这里面的2个方法都没有进行同步，很可能在openConnection方法中会多次创建connect；第二，由于connect是共享变量，那么必然在调用connect的地方需要使用到同步来保障线程安全，因为很可能一个线程在使用connect进行数据库操作，而另外一个线程调用closeConnection关闭链接。 所以出于线程安全的考虑，必须将这段代码的两个方法进行同步处理，并且在调用connect的地方需要进行同步处理。 这样将会大大影响程序执行效率，因为一个线程在使用connect进行数据库操作的时候，其他线程只有等待。 那么大家来仔细分析一下这个问题，这地方到底需不需要将connect变量进行共享？事实上，是不需要的。假如每个线程中都有一个connect变量，各个线程之间对connect变量的访问实际上是没有依赖关系的，即一个线程不需要关心其他线程是否对这个connect进行了修改的。 到这里，可能会有朋友想到，既然不需要在线程之间共享这个变量，可以直接这样处理，在每个需要使用数据库连接的方法中具体使用时才创建数据库链接，然后在方法调用完毕再释放这个连接。比如下面这样： 12345678910111213141516171819202122232425262728class ConnectionManager &#123; private Connection connect = null; public Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; class Dao&#123; public void insert() &#123; ConnectionManager connectionManager = new ConnectionManager(); Connection connection = connectionManager.openConnection(); //使用connection进行操作 connectionManager.closeConnection(); &#125;&#125; 这样处理确实也没有任何问题，由于每次都是在方法内部创建的连接，那么线程之间自然不存在线程安全问题。但是这样会有一个致命的影响：导致服务器压力非常大，并且严重影响程序执行性能。由于在方法中需要频繁地开启和关闭数据库连接，这样不尽严重影响程序执行效率，还可能导致服务器压力巨大。 那么这种情况下使用ThreadLocal是再适合不过的了，因为ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。 12345678910private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;; public static Connection getConnection() &#123;return connectionHolder.get();&#125; 但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 深入解析ThreadLocal先了解一下ThreadLocal类提供的几个方法：1234public T get() &#123; &#125;public void set(T value) &#123; &#125;public void remove() &#123; &#125;protected T initialValue() &#123; &#125; get()方法是用来获取ThreadLocal在当前线程中保存的变量副本，set()用来设置当前线程中变量的副本，remove()用来移除当前线程中变量的副本，initialValue()是一个protected方法，一般是用来在使用时进行重写的，它是一个延迟加载方法 ThreadLocal维护线程与实例的映射既然每个访问 ThreadLocal 变量的线程都有自己的一个“本地”实例副本。一个可能的方案是 ThreadLocal 维护一个 Map，键是 Thread，值是它在该 Thread 内的实例。线程通过该 ThreadLocal 的 get() 方案获取实例时，只需要以线程为键，从 Map 中找出对应的实例即可。该方案如下图所示 该方案可满足上文提到的每个线程内一个独立备份的要求。每个新线程访问该 ThreadLocal 时，需要向 Map 中添加一个映射，而每个线程结束时，应该清除该映射。这里就有两个问题： 增加线程与减少线程均需要写Map，故需保证该Map线程安全。 线程结束时，需要保证它所访问的所有 ThreadLocal 中对应的映射均删除，否则可能会引起内存泄漏。 其中锁的问题，是 JDK 未采用该方案的一个原因。 Thread维护ThreadLocal与实例的映射上述方案中，出现锁的问题，原因在于多线程访问同一个 Map。如果该 Map 由 Thread 维护，从而使得每个 Thread 只访问自己的 Map，那就不存在多线程写的问题，也就不需要锁。该方案如下图所示。 该方案虽然没有锁的问题，但是由于每个线程访问某 ThreadLocal 变量后，都会在自己的 Map 内维护该 ThreadLocal 变量与具体实例的映射，如果不删除这些引用（映射），则这些 ThreadLocal 不能被回收，可能会造成内存泄漏。后文会介绍 JDK 如何解决该问题。 ThreadLocal 在 JDK 8 中的实现ThreadLocalMap与内存泄漏该方案中，Map 由 ThreadLocal 类的静态内部类 ThreadLocalMap 提供。该类的实例维护某个 ThreadLocal 与具体实例的映射。与 HashMap 不同的是，ThreadLocalMap 的每个 Entry 都是一个对键的弱引用，这一点从super(k)可看出。另外，每个 Entry 都包含了一个对值的强引用。 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 使用弱引用的原因在于，当没有强引用指向 ThreadLocal 变量时，它可被回收，从而避免上文所述 ThreadLocal 不能被回收而造成的内存泄漏的问题。 但是，这里又可能出现另外一种内存泄漏的问题。ThreadLocalMap 维护 ThreadLocal 变量与具体实例的映射，当 ThreadLocal 变量被回收后，该映射的键变为 null，该 Entry 无法被移除。从而使得实例被该 Entry 引用而无法被回收造成内存泄漏。 注：Entry虽然是弱引用，但它是ThreadLocal类型的弱引用（也即上文所述它是对键的弱引用），而非具体实例的的弱引用，所以无法避免具体实例相关的内存泄漏。 读取实例12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 读取实例时，线程首先通过getMap(t)方法获取自身的 ThreadLocalMap。从如下该方法的定义可见，该 ThreadLocalMap 的实例是 Thread 类的一个字段，即由 Thread 维护 ThreadLocal 对象与具体实例的映射，这一点与上文分析一致。123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 获取到 ThreadLocalMap 后，通过map.getEntry(this)方法获取该 ThreadLocal 在当前线程的 ThreadLocalMap 中对应的 Entry。该方法中的 this 即当前访问的 ThreadLocal 对象。 如果获取到的 Entry 不为 null，从 Entry 中取出值即为所需访问的本线程对应的实例。如果获取到的 Entry 为 null，则通过setInitialValue()方法设置该 ThreadLocal 变量在该线程中对应的具体实例的初始值。 设置初始值12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 该方法为 private 方法，无法被重载。 首先，通过initialValue()方法获取初始值。该方法为public方法，且默认返回null。所以典型用法中常常重载该方法。上例中即在内部匿名类中将其重载。 然后拿到该线程对应的 ThreadLocalMap 对象，若该对象不为 null，则直接将该 ThreadLocal 对象与对应实例初始值的映射添加进该线程的 ThreadLocalMap中。若为 null，则先创建该 ThreadLocalMap 对象再将映射添加其中。 这里并不需要考虑 ThreadLocalMap 的线程安全问题。因为每个线程有且只有一个 ThreadLocalMap 对象，并且只有该线程自己可以访问它，其它线程不会访问该 ThreadLocalMap，也即该对象不会在多个线程中共享，也就不存在线程安全的问题。 设置实例12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 该方法先获取该线程的 ThreadLocalMap 对象，然后直接将 ThreadLocal 对象（即代码中的 this）与目标实例的映射添加进 ThreadLocalMap 中。当然，如果映射已经存在，就直接覆盖。另外，如果获取到的 ThreadLocalMap 为 null，则先创建该 ThreadLocalMap 对象。 防止内存泄漏对于已经不再被使用且已被回收的 ThreadLocal 对象，它在每个线程内对应的实例由于被线程的 ThreadLocalMap 的 Entry 强引用，无法被回收，可能会造成内存泄漏。 针对该问题，ThreadLocalMap 的 set 方法中，通过 replaceStaleEntry 方法将所有键为 null 的 Entry 的值设置为 null，从而使得该值可被回收。另外，会在 rehash 方法中通过 expungeStaleEntry 方法将键和值为 null 的 Entry 设置为 null 从而使得该 Entry 可被回收。通过这种方式，ThreadLocal 可防止内存泄漏。 1234567891011121314151617181920private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; ThreadLocal的应用场景ThreadLocal适用于以下两种场景： 每个线程需要有自己单独的实例 实例需要在多个方法中共享，但不希望被多线程共享 最常见的ThreadLocal使用场景为用来解决数据库连接、Session管理等 总结 ThreadLocal 并不解决线程间共享数据的问题 ThreadLocal 通过隐式的在不同线程内创建独立实例副本避免了实例线程安全的问题 每个线程持有一个 Map 并维护了 ThreadLocal 对象与具体实例的映射，该 Map 由于只被持有它的线程访问，故不存在线程安全以及锁的问题 ThreadLocalMap 的 Entry 对 ThreadLocal 的引用为弱引用，避免了 ThreadLocal 对象无法被回收的问题 ThreadLocalMap 的 set 方法通过调用 replaceStaleEntry 方法回收键为 null 的 Entry 对象的值（即为具体实例）以及 Entry 对象本身从而防止内存泄漏 ThreadLocal 适用于变量在线程间隔离且在方法间共享的场景]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[当我们说线程安全时，到底在说什么]]></title>
    <url>%2F2018%2F08%2F%E5%BD%93%E6%88%91%E4%BB%AC%E8%AF%B4%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%97%B6%EF%BC%8C%E5%88%B0%E5%BA%95%E5%9C%A8%E8%AF%B4%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[本文转发自技术世界，原文链接 http://www.jasongj.com/java/thread_safe/ 多线程编程中的三个核心概念原子性这一点，跟数据库事务的原子性概念差不多，即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）。 关于原子性，一个非常经典的例子就是银行转账问题：比如A和B同时向C转账10万元。如果转账操作不具有原子性，A在向C转账时，读取了C的余额为20万，然后加上转账的10万，计算出此时应该有30万，但还未来及将30万写回C的账户，此时B的转账请求过来了，B发现C的余额为20万，然后将其加10万并写回。然后A的转账操作继续——将30万写回C的余额。这种情况下C的最终余额为30万，而非预期的40万。 可见性可见性是指，当多个线程并发访问共享变量时，一个线程对共享变量的修改，其它线程能够立即看到。可见性问题是好多人忽略或者理解错误的一点。 CPU从主内存中读数据的效率相对来说不高，现在主流的计算机中，都有几级缓存。每个线程读取共享变量时，都会将该变量加载进其对应CPU的高速缓存里，修改该变量后，CPU会立即更新该缓存，但并不一定会立即将其写回主内存（实际上写回主内存的时间不可预期）。此时其它线程（尤其是不在同一个CPU上执行的线程）访问该变量时，从主内存中读到的就是旧的数据，而非第一个线程更新后的数据。 这一点是操作系统或者说是硬件层面的机制，所以很多应用开发人员经常会忽略。 顺序性顺序性指的是，程序执行的顺序按照代码的先后顺序执行。 以下面这段代码为例 1234boolean started = false; // 语句1long counter = 0L; // 语句2counter = 1; // 语句3started = true; // 语句4 从代码顺序上看，上面四条语句应该依次执行，但实际上JVM真正在执行这段代码时，并不保证它们一定完全按照此顺序执行。 处理器为了提高程序整体的执行效率，可能会对代码进行优化，其中的一项优化方式就是调整代码顺序，按照更高效的顺序执行代码。 讲到这里，有人要着急了——什么，CPU不按照我的代码顺序执行代码，那怎么保证得到我们想要的效果呢？实际上，大家大可放心，CPU虽然并不保证完全按照代码顺序执行，但它会保证程序最终的执行结果和代码顺序执行时的结果一致。 Java如何解决多线程并发问题Java如何保证原子性锁和同步常用的保证Java操作原子性的工具是锁和同步方法（或者同步代码块）。使用锁，可以保证同一时间只有一个线程能拿到锁，也就保证了同一时间只有一个线程能执行申请锁和释放锁之间的代码。 123456789public void testLock () &#123; lock.lock(); try&#123; int j = i; i = j + 1; &#125; finally &#123; lock.unlock(); &#125;&#125; 与锁类似的是同步方法或者同步代码块。使用非静态同步方法时，锁住的是当前实例；使用静态同步方法时，锁住的是该类的Class对象；使用静态代码块时，锁住的是synchronized关键字后面括号内的对象。下面是同步代码块示例 123456public void testLock () &#123; synchronized (anyObject)&#123; int j = i; i = j + 1; &#125;&#125; 无论使用锁还是synchronized，本质都是一样，通过锁来实现资源的排它性，从而实际目标代码段同一时间只会被一个线程执行，进而保证了目标代码段的原子性。这是一种以牺牲性能为代价的方法。 CAS（compare and swap）基础类型变量自增（i++）是一种常被新手误以为是原子操作而实际不是的操作。Java中提供了对应的原子操作类来实现该操作，并保证原子性，其本质是利用了CPU级别的CAS指令。由于是CPU级别的指令，其开销比需要操作系统参与的锁的开销小。AtomicInteger使用方法如下。 12345678AtomicInteger atomicInteger = new AtomicInteger();for(int b = 0; b &lt; numThreads; b++) &#123; new Thread(() -&gt; &#123; for(int a = 0; a &lt; iteration; a++) &#123; atomicInteger.incrementAndGet(); &#125; &#125;).start();&#125; Java如何保证可见性Java提供了volatile关键字来保证可见性。当使用volatile修饰某个变量时，它会保证对该变量的修改会立即被更新到内存中，并且将其它缓存中对该变量的缓存设置成无效，因此其它线程需要读取该值时必须从主内存中读取，从而得到最新的值。 Java如何保证顺序性上文讲过编译器和处理器对指令进行重新排序时，会保证重新排序后的执行结果和代码顺序执行的结果一致，所以重新排序过程并不会影响单线程程序的执行，却可能影响多线程程序并发执行的正确性。 Java中可通过volatile在一定程序上保证顺序性，另外还可以通过synchronized和锁来保证顺序性。 synchronized和锁保证顺序性的原理和保证原子性一样，都是通过保证同一时间只会有一个线程执行目标代码段来实现的。 除了从应用层面保证目标代码段执行的顺序性外，JVM还通过被称为happens-before原则隐式地保证顺序性。两个操作的执行顺序只要可以通过happens-before推导出来，则JVM会保证其顺序性，反之JVM对其顺序性不作任何保证，可对其进行任意必要的重新排序以获取高效率。 happens-before原则（先行发生原则） 传递规则：如果操作1在操作2前面，而操作2在操作3前面，则操作1肯定会在操作3前发生。该规则说明了happens-before原则具有传递性 锁定规则：一个unlock操作肯定会在后面对同一个锁的lock操作前发生。这个很好理解，锁只有被释放了才会被再次获取 volatile变量规则：对一个被volatile修饰的写操作先发生于后面对该变量的读操作 程序次序规则：一个线程内，按照代码顺序执行 线程启动规则：Thread对象的start()方法先发生于此线程的其它动作 线程终结原则：线程的终止检测后发生于线程中其它的所有操作 线程中断规则： 对线程interrupt()方法的调用先发生于对该中断异常的获取 对象终结规则：一个对象构造先于它的finalize发生 volatile适用场景volatile适用于不需要保证原子性，但却需要保证可见性的场景。一种典型的使用场景是用它修饰用于停止线程的状态标记。如下所示 1234567891011boolean isRunning = false;public void start () &#123; new Thread( () -&gt; &#123; while(isRunning) &#123; someOperation(); &#125; &#125;).start();&#125;public void stop () &#123; isRunning = false;&#125; 在这种实现方式下，即使其它线程通过调用stop()方法将isRunning设置为false，循环也不一定会立即结束。可以通过volatile关键字，保证while循环及时得到isRunning最新的状态从而及时停止循环，结束线程。 线程安全十万个为什么问：平时项目中使用锁和synchronized比较多，而很少使用volatile，难道就没有保证可见性？答：锁和synchronized即可以保证原子性，也可以保证可见性。都是通过保证同一时间只有一个线程执行目标代码段来实现的。 问：锁和synchronized为何能保证可见性？答：根据JDK 7的Java doc中对concurrent包的说明，一个线程的写结果保证对另外线程的读操作可见，只要该写操作可以由happen-before原则推断出在读操作之前发生。 The results of a write by one thread are guaranteed to be visible to a read by another thread only if the write operation happens-before the read operation. The synchronized and volatile constructs, as well as the Thread.start() and Thread.join() methods, can form happens-before relationships. 问：既然锁和synchronized即可保证原子性也可保证可见性，为何还需要volatile？答：synchronized和锁需要通过操作系统来仲裁谁获得锁，开销比较高，而volatile开销小很多。因此在只需要保证可见性的条件下，使用volatile的性能要比使用锁和synchronized高得多。 问：既然锁和synchronized可以保证原子性，为什么还需要AtomicInteger这种的类来保证原子操作？答：锁和synchronized需要通过操作系统来仲裁谁获得锁，开销比较高，而AtomicInteger是通过CPU级的CAS操作来保证原子性，开销比较小。所以使用AtomicInteger的目的还是为了提高性能。 问：还有没有别的办法保证线程安全？答：有。尽可能避免引起非线程安全的条件——共享变量。如果能从设计上避免共享变量的使用，即可避免非线程安全的发生，也就无须通过锁或者synchronized以及volatile解决原子性、可见性和顺序性的问题。 问：synchronized即可修饰非静态方式，也可修饰静态方法，还可修饰代码块，有何区别？答：synchronized修饰非静态同步方法时，锁住的是当前实例；synchronized修饰静态同步方法时，锁住的是该类的Class对象；synchronized修饰静态代码块时，锁住的是synchronized关键字后面括号内的对象。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap的ReHash图解]]></title>
    <url>%2F2018%2F07%2FHashMap%E7%9A%84ReHash%E5%9B%BE%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[resize方法 123456789101112void resize(intnewCapacity)&#123; Entry[] oldTable = table; intoldCapacity = oldTable.length; ...... //创建一个新的Hash Table Entry[] newTable =new Entry[newCapacity]; //将Old Hash Table上的数据迁移到New Hash Table上 transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);&#125; transfer方法 1234567891011121314151617181920void transfer(Entry[] newTable)&#123; Entry[] src = table; intnewCapacity = newTable.length; //下面这段代码的意思是： // 从OldTable里摘一个元素出来，然后放到NewTable中 for(intj = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if(e != null) &#123; src[j] =null; do&#123; Entry&lt;K,V&gt; next = e.next; inti = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125;while (e != null); &#125; &#125;&#125; 单线程下的ReHash 用key mod 一下表的大小（也就是数组的长度）。 最上面的是old hash 表，其中的Hash表的size=2, 所以key = 3, 7, 5，在mod 2以后都冲突在table[1]这里了。 接下来的三个步骤是Hash表 resize成4，然后所有的&lt;key,value&gt; 重新rehash的过程 详细描述可以看下面这张图： 并发下的Rehash 假设我们有两个线程。我用红色和浅蓝色标注了一下。 1234567do&#123; Entry&lt;K,V&gt; next = e.next;// &lt;--假设线程一执行到这里就被调度挂起了 inti = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next;&#125;while (e != null); 而我们的线程二执行完成了。于是我们有下面的这个样子。 注意，因为Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。我们可以看到链表的顺序被反转后。 线程一被调度回来执行。 先是执行 newTalbe[i] = e; 然后是e = next，导致了e指向了key(7)， 而下一次循环的next = e.next导致了next指向了key(3) 线程一继续执行 把key(7)摘下来，放到newTable[i]的第一个，然后把e和next往下移 环形链接出现 e.next = newTable[i] 导致 key(3).next 指向了 key(7)注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。 当我们的线程一调用到HashTable.get(11)时，悲剧就出现了——Infinite Loop]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存与数据库一致性之缓存更新设计]]></title>
    <url>%2F2018%2F06%2F%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%80%E8%87%B4%E6%80%A7%E4%B9%8B%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[缓存更新场景介绍缓存是一种提高系统读性能的常见技术，对于读多写少的应用场景，我们经常使用缓存来进行优化. 例如对于用户的余额信息表account(uid, money)，业务上的需求是： （1）查询用户的余额，SELECT money FROM account WHERE uid=XXX，占99%的请求 （2）更改用户余额，UPDATE account SET money=XXX WHERE uid=XXX，占1%的请求 由于大部分的请求是查询，我们在缓存中建立uid到money的键值对，能够极大降低数据库的压力。 读操作流程有了数据库和缓存两个地方存放数据之后（uid-&gt;money），每当需要读取相关数据时（money），操作流程一般是这样的：（1）读取缓存中是否有相关数据，uid-&gt;money（2）如果缓存中有相关数据money，则返回【这就是所谓的数据命中“hit”】（3）如果缓存中没有相关数据money，则从数据库读取相关数据money【这就是所谓的数据未命中“miss”】，放入缓存中uid-&gt;money，再返回缓存的命中率 = 命中缓存请求个数/总缓存访问请求个数 = hit/(hit+miss)上面举例的余额场景，99%的读，1%的写，这个缓存的命中率是非常高的，会在95%以上。 问题当数据money发生变化的时候：（1）是更新缓存中的数据，还是淘汰缓存中的数据呢？（2）是先操纵数据库中的数据再操纵缓存中的数据，还是先操纵缓存中的数据再操纵数据库中的数据呢？（3）缓存与数据库的操作，在架构上是否有优化的空间呢？ 更新缓存 VS 淘汰缓存 更新缓存：数据不但写入数据库，还会写入缓存优点：缓存不会增加一次miss，命中率高 淘汰缓存：数据只会写入数据库，不会写入缓存，只会把数据淘汰掉优点：简单 那到底是选择更新缓存还是淘汰缓存呢？主要取决于“更新缓存的复杂度”。 例如，上述场景，只是简单的把余额money设置成一个值，那么：（1）淘汰缓存的操作为deleteCache(uid)（2）更新缓存的操作为setCache(uid, money)更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率。如果余额是通过很复杂的数据计算得出来的，更新缓存的代价很大，此时我们应该更倾向于淘汰缓存。淘汰缓存操作简单，并且带来的副作用只是增加了一次cache miss，建议作为通用的处理方式。 先操作数据库 vs 先操作缓存当写操作发生时，假设淘汰缓存作为对缓存通用的处理方式，又面临两种抉择：（1）先写数据库，再淘汰缓存（2）先淘汰缓存，再写数据库 对于一个不能保证事务性的操作，一定涉及“哪个任务先做，哪个任务后做”的问题，解决这个问题的方向是：如果出现不一致，谁先做对业务的影响较小，就谁先执行。由于写数据库与淘汰缓存不能保证原子性，谁先谁后同样要遵循上述原则。 假设先写数据库，再淘汰缓存第一步写数据库操作成功，第二步淘汰缓存失败，则会出现DB中是新数据，Cache中是旧数据，数据不一致。 假设先淘汰缓存，再写数据库第一步淘汰缓存成功，第二步写数据库失败，则只会引发一次Cache miss。 结论：数据和缓存的操作时序，结论是清楚的：先淘汰缓存，再写数据库。 缓存架构优化 上述缓存架构有一个缺点：业务方需要同时关注缓存与DB，有没有进一步的优化空间呢？有两种常见的方案，一种主流方案(服务化)，一种非主流方案（异步缓存更新） 服务化加入一个服务层，向上游提供帅气的数据访问接口，向上游屏蔽底层数据存储的细节，这样业务线不需要关注数据是来自于cache还是DB 异步缓存更新业务线所有的写操作都走数据库，所有的读操作都总缓存，由一个异步的工具来做数据库与缓存之间数据的同步 要有一个init cache的过程，将需要缓存的数据全量写入cache 如果DB有写操作，异步更新程序读取binlog，更新cache 在（1）和（2）的合作下，cache中有全部的数据，这样：（a）业务线读cache，一定能够hit（很短的时间内，可能有脏数据），无需关注数据库（b）业务线写DB，cache中能得到异步更新，无需关注缓存 将大大简化业务线的调用逻辑，存在的缺点是，如果缓存的数据业务逻辑比较复杂，async-update异步更新的逻辑可能也会比较复杂 总结 淘汰缓存是一种通用的缓存处理方式 先淘汰缓存，再写数据库的时序是毋庸置疑的 服务化是向业务方屏蔽底层数据库与缓存复杂性的一种通用方式 拓展缓存穿透我们在项目中使用缓存通常都是先检查缓存中是否存在，如果存在直接返回缓存内容，如果不存在就直接查询数据库然后再缓存查询结果返回。这个时候如果我们查询的某一个数据在缓存中一直不存在，就会造成每一次请求都查询DB，这样缓存就失去了意义，在流量大时，可能DB就挂掉了。要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 解决方案：（1）缓存空对象，设置短暂的过期时间（2）布隆过滤器拦截 有一个比较巧妙的作法是，可以将这个不存在的key预先设定一个值，比如，”key” , “&amp;&amp;”。在返回这个&amp;&amp;值的时候，我们的应用就可以认为这是不存在的key，那我们的应用就可以决定是否继续等待继续访问，还是放弃掉这次操作。如果继续等待访问，过一个时间轮询点后，再次请求这个key，如果取到的值不再是&amp;&amp;，则可以认为这时候key有值了，从而避免了透传到数据库，从而把大量的类似请求挡在了缓存之中。 缓存并发-缓存击穿有时候如果网站并发访问高，一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况，如果并发确实很大，这也可能造成DB压力过大，还有缓存频繁更新的问题。 解决方案：锁、互斥锁 缓存失效-缓存雪崩引起这个问题的主要原因还是高并发的时候，平时我们设定一个缓存的过期时间时，可能有一些会设置1分钟啊，5分钟这些，并发很高时可能会出在某一个时间同时生成了很多的缓存，并且过期时间都一样，这个时候就可能引发一当过期时间到后，这些缓存同时失效，请求全部转发到DB，DB可能会压力过重。 解决方案：随机过期时间，降低过期时间的重复率]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis底层数据结构]]></title>
    <url>%2F2018%2F06%2FRedis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Redis底层数据结构类型简单动态字符串（simple dynamic string）SDS Redis 没有直接使用C语言传统的字符串表示，而是自己构建了一种名为简单动态字符串（simple dynamic string SDS）的抽象类型，并将SDS用作Redis 的默认字符串表示;除了用来保存字符串以外，SDS还被用作缓冲区（buffer）AOF(持久化)模块中的AOF缓冲区 SDS的定义 区别于C语言字符串，具有良好的伸缩性，在获取字符串长度，字符串修改，防止缓存区溢出等性能都比C语言字符串好 Redis 中定义动态字符串的结构：1234567891011121314/* * 保存字符串对象的结构 */ struct sdshdr &#123; // buf 中已占用空间的长度 int len; // buf 中剩余可用空间的长度(初次分配空间，一般没有空余，在对字符串修改的时候，会有剩余空间出现)-预分配 int free; // 数据空间 char buf[]; &#125;; SDS 与 C 字符串的区别 获取字符串长度（SDS O（1）/C 字符串 O(n)） 传统的C字符串: 使用长度为N+1 的字符串数组来表示长度为N 的字符串，所以为了获取一个长度为C字符串的长度，必须遍历整个字符串。 SDS：SDS 的数据结构中，有专门用于保存字符串长度的变量，我们可以通过获取len 属性的值，直接知道字符串长度 杜绝缓冲区溢出 C 字符串 不记录字符串长度，除了获取的时候复杂度高以外，还容易忘了为字符串重新分配足够的空间，从而导致缓冲区溢出 Redis 中SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性： 当我们需要对一个SDS进行修改的时候，redis会在执行拼接操作之前，预先检查给定SDS空间是否足够，如果不够，会先拓展SDS 的空间，然后再执行拼接操作 减少修改字符串时带来的内存重分配次数 C语言字符串在进行字符串的扩充和收缩的时候，都会面临着内存空间的重新分配问题 字符串拼接会产生字符串的内存空间的扩充，在拼接的过程中，原来的字符串的大小很可能小于拼接后的字符串的大小，那么这样的话，就会导致一旦忘记申请分配空间，就会导致内存的溢出。 字符串在进行收缩的时候，内存空间会相应的收缩，而如果在进行字符串的切割的时候，没有对内存的空间进行一个重新分配，那么这部分多出来的空间就成为了内存泄露 SDS：对SDS进行拓展，则需要进行空间的拓展，这时候redis 会将SDS的长度修改为N字节，并且将未使用空间同样修改为N字节，此时如果再次进行修改，因为在上一次修改字符串的时候已经拓展了空间，再次进行修改字符串的时候如果发现空间足够使用，因此无须进行空间拓展通过这种预分配策略，SDS将连续增长N次字符串所需的内存重分配次数从必定N次降低为最多N次 惰性空间释放SDS 提供了相应的API，让我们可以在有需要的时候，自行释放SDS的空余空间通过惰性空间释放，SDS避免了缩短字符串时所需的内存重分配操作，并未将来可能有的增长操作提供了优化 二进制安全 C 字符串中的字符必须符合某种编码，并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存想图片，音频，视频，压缩文件这样的二进制数据 在Redis中，不是靠空字符来判断字符串的结束的，而是通过len这个属性。那么，即便是中间出现了空字符对于SDS来说，读取该字符仍然是可以的 兼容部分C字符串函数虽然SDS 的API 都是二进制安全的，但他们一样遵循C字符串以空字符串结尾的惯例 对比总结 C 字符串 SDS 获取字符串长度的复杂度为O（N) 获取字符串长度的复杂度为O(1) API 是不安全的，可能会造成缓冲区溢出 API 是安全的，不会造成缓冲区溢出 修改字符串长度N次必然需要执行N次内存重分配 修改字符串长度N次最多执行N次内存重分配 只能保存文本数据 可以保存二进制数据和文本文数据 可以使用所有&lt;String.h&gt;库中的函数 可以使用一部分&lt;string.h&gt;库中的函数 链表 顺序存储对象信息，有用于缓存链表长度的属性，在插入删除对象功能中有良好性能，避免环的产生 链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。链表在Redis 中的应用非常广泛，比如列表键的底层实现之一就是链表。当一个列表键包含了数量较多的元素，又或者列表中包含的元素都是比较长的字符串时，Redis 就会使用链表作为列表键的底层实现。 链表的数据结构每个链表节点使用一个 listNode结构表示（adlist.h/listNode）：12345typedef struct listNode&#123; struct listNode *prev; struct listNode * next; void * value; &#125; 多个链表节点组成的双端链表： 通过直接操作list 来操作链表会更加方便:1234567891011121314typedef struct list&#123; //表头节点 listNode * head; //表尾节点 listNode * tail; //链表长度 unsigned long len; //节点值复制函数 void *(*dup) (void *ptr); //节点值释放函数 void (*free) (void *ptr); //节点值对比函数 int (*match)(void *ptr, void *key);&#125; dup 函数用于复制链表节点所保存的值； free 函数用于释放链表节点所保存的值； match 函数则用于对比链表节点所保存的值和另一个输入值是否相等。list 组成的结构图： 特性 双端：链表节点带有prev 和next 指针，获取某个节点的前置节点和后置节点的时间复杂度都是O（N） 无环：表头节点的 prev 指针和表尾节点的next 都指向NULL，对立案表的访问时以NULL为截止 表头和表尾：因为链表带有head指针和tail 指针，程序获取链表头结点和尾节点的时间复杂度为O(1) 长度计数器：链表中存有记录链表长度的属性 len 多态：链表节点使用 void* 指针来保存节点值，并且可以通过list 结构的dup 、 free、 match三个属性为节点值设置类型特定函数。 字典 key-value 存储方式，通过hash值计算，判断key的存储，当容量过大，会通过rehash重新分配字典大小 字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对的抽象数据结构。在字典中，一个键（key）可以和一个值（value）进行关联，字典中的每个键都是独一无二的。在C语言中，并没有这种数据结构，但是Redis 中构建了自己的字典实现 字典的定义 哈希表Redis 字典所使用的哈希表由 dict.h/dictht 结构定义：1234567891011typedef struct dictht &#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used;&#125; 一个空的字典的结构图如下：可以看到，在结构中存有指向dictEntry 数组的指针，而我们用来存储数据的空间既是dictEntry 哈希表节点（ dictEntry ）dictEntry 结构定义：123456789101112typeof struct dictEntry&#123; //键 void *key; //值 union&#123; void *val; uint64_tu64; int64_ts64; &#125; struct dictEntry *next;&#125; 在数据结构中，我们清楚key 是唯一的，但是我们存入里面的key 并不是直接的字符串，而是一个hash 值，通过hash 算法，将字符串转换成对应的hash 值，然后在dictEntry 中找到对应的位置。这时候我们会发现一个问题，如果出现hash 值相同的情况怎么办？Redis 采用了链地址法：当k1 和k0 的hash 值相同时，将k1中的next 指向k0 想成一个链表。 字典1234567891011typedef struct dict &#123; // 类型特定函数 dictType *type; // 私有数据 void *privedata; // 哈希表 dictht ht[2]; // rehash 索引 in trehashidx;&#125; type 属性 和privdata 属性是针对不同类型的键值对，为创建多态字典而设置的。ht 属性是一个包含两个项（两个哈希表）的数组 普通状态下的字典： 解决哈希冲突 在上述分析哈希节点的时候我们有讲到：在插入一条新的数据时，会进行哈希值的计算，如果出现了hash值相同的情况，Redis 中采用了连地址法（separate chaining）来解决键冲突。每个哈希表节点都有一个next 指针，多个哈希表节点可以使用next 构成一个单向链表，被分配到同一个索引上的多个节点可以使用这个单向链表连接起来解决hash值冲突的问题。 举个栗子：现在哈希表中有以下的数据：k0 和k1 我们现在要插入k2，通过hash 算法计算到k2 的hash 值为2，即我们需要将k2 插入到dictEntry[2]中： 在插入后我们可以看到，dictEntry指向了k2，k2的next指向了k1，从而完成了一次插入操作（这里选择表头插入是因为哈希表节点中没有记录链表尾节点位置） Rehash 随着对哈希表的不断操作，哈希表保存的键值对会逐渐的发生改变，为了让哈希表的负载因子维持在一个合理的范围之内，我们需要对哈希表的大小进行相应的扩展或者压缩，这时候，我们可以通过 rehash（重新散列）操作来完成 目前的哈希表状态我们可以看到，哈希表中的每个节点都已经使用到了，这时候我们需要对哈希表进行拓展 为哈希表分配空间哈希表空间分配规则： 如果执行的是拓展操作，那么ht[1] 的大小为第一个大于等于ht[0].used*2的2的n次幂 如果执行的是收缩操作，那么ht[1] 的大小为第一个大于等于ht[0].used的2的n次幂因此这里我们为ht[1] 分配 空间为8， 数据转移将ht[0]中的数据转移到ht[1]中，在转移的过程中，需要对哈希表节点的数据重新进行哈希值计算数据转移后的结果： 释放ht[0]将ht[0]释放，然后将ht[1]设置成ht[0]，最后为ht[1]分配一个空白哈希表： 渐进式 rehash上面我们说到，在进行拓展或者压缩的时候，可以直接将所有的键值对rehash 到ht[1]中，这是因为数据量比较小。在实际开发过程中，这个rehash 操作并不是一次性、集中式完成的，而是分多次、渐进式地完成的。渐进式rehash 的详细步骤：123451、为ht[1] 分配空间，让字典同时持有ht[0]和ht[1]两个哈希表2、在几点钟维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash 开始3、在rehash 进行期间，每次对字典执行CRUD操作时（增加只针对ht[1]），程序除了执行指定的操作以外，还会将ht[0]中的数据rehash 到ht[1]表中，并且将rehashidx加一4、当ht[0]中所有数据转移到ht[1]中时，将rehashidx 设置成-1，表示rehash 结束 采用渐进式rehash 的好处在于它采取分而治之的方式，避免了集中式rehash 带来的庞大计算量 哈希表的扩展与收缩 当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作：12服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ；服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ； 其中哈希表的负载因子可以通过公式：12# 负载因子 = 哈希表已保存节点数量 / 哈希表大小load_factor = ht[0].used / ht[0].size 跳跃表概述跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表是一种随机化的数据,跳跃表以有序的方式在层次化的链表中保存元素，效率和平衡树媲美——查找、删除、添加等操作都可以在对数期望时间下完成，并且比起平衡树来说，跳跃表的实现要简单直观得多。 Redis 只在两个地方用到了跳跃表，一个是实现有序集合键，另外一个是在集群节点中用作内部数据结构 跳跃表的定义跳跃表的完整结构： Redis 的跳跃表 主要由两部分组成：zskiplist（链表）和zskiplistNode （节点） zskiplistNode（节点） 数据结构：123456789101112131415typedef struct zskiplistNode&#123; //层 struct zskiplistLevel&#123; //前进指针 struct zskiplistNode *forward; //跨度 unsigned int span; &#125; level[]; //后退指针 struct zskiplistNode *backward; //分值 double score; //成员对象 robj *obj;&#125; 层：level 数组可以包含多个元素，每个元素都包含一个指向其他节点的指针。 前进指针：用于指向表尾方向的前进指针 跨度：用于记录两个节点之间的距离 后退指针：用于从表尾向表头方向访问节点 分值和成员：跳跃表中的所有节点都按分值从小到大排序。成员对象指向一个字符串，这个字符串对象保存着一个SDS值 zskiplist 数据结构：123456789typedef struct zskiplist &#123; //表头节点和表尾节点 structz skiplistNode *header,*tail; //表中节点数量 unsigned long length; //表中层数最大的节点的层数 int level;&#125;zskiplist; 从结构图中我们可以清晰的看到，header，tail分别指向跳跃表的头结点和尾节点。level 用于记录最大的层数，length 用于记录我们的节点数量。 总结 跳跃表是有序集合的底层实现之一 主要有zskiplist 和zskiplistNode两个结构组成 每个跳跃表节点的层高都是1至32之间的随机数 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的对象必须是唯一的 节点按照分值的大小从大到小排序，如果分值相同，则按成员对象大小排序 整数集合 整数集合是集合建的底层实现之一，当一个集合中只包含整数，且这个集合中的元素数量不多时，redis就会使用整数集合intset作为集合的底层实现 【其实就是一个特殊的集合，里面存储的数据只能够是整数，并且数据量不能过大】 结构12345678910111213typedef struct intset&#123; //编码方式 uint32_t enconding; // 集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[];&#125;1、encoding：用于定义整数集合的编码方式2、length：用于记录整数集合中变量的数量3、contents：用于保存元素的数组，虽然我们在数据结构图中看到，intset将数组定义为int8_t，但实际上数组保存的元素类型取决于encoding 整数集合的升级 intset 在默认情况下会帮我们设定整数集合中的编码方式，但是当我们存入的整数不符合整数集合中的编码格式时，就需要使用到Redis 中的升级策略来解决 Intset 中升级整数集合并添加新元素共分为三步进行： 根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间 将底层数组现有的所有元素都转换成新的编码格式，重新分配空间 将新元素加入到底层数组中 整数集合升级的好处 提升灵活性 节约内存 总结 整数集合是集合建的底层实现之一 整数集合的底层实现为数组，这个数组以有序，无重复的范式保存集合元素，在有需要时，程序会根据新添加的元素类型改变这个数组的类型 升级操作为整数集合带来了操作上的灵活性，并且尽可能地节约了内存 整数集合只支持升级操作，不支持降级操作 压缩列表 压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值， 要么就是长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。 构成压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含任意多个节点（entry）， 每个节点可以保存一个字节数组或者一个整数值。 属性 类型 长度 用途 zlbytes uint32_t 4 字节 记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend 的位置时使用。 zltail uint32_t 4 字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。 zllen uint16_t 2 字节 记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。 entryX 列表节点 不定 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend uint8_t 1 字节 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 连锁更新 添加新节点可能会引发连锁更新之外， 删除节点也可能会引发连锁更新 总结 压缩列表是一种为了节约内存而开发的顺序型数据结构 压缩列表被用作列表键和哈希键的底层实现之一 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值 添加新节点到压缩列表，可能会引发连锁更新操作，删除节点也可能会引发连锁更新 对象字符串对象如果字符串对象保存的是一个字符串值，并且这个字符串值的长度小于等于39字节，那么字符串对象将使用embstr编码的方式来保存这个字符串值 embstr 编码是专门用于保存短字符串的一种优化编码方式， 这种编码和 raw 编码一样， 都使用 redisObject 结构和 sdshdr 结构来表示字符串对象， 但 raw 编码会调用两次内存分配函数来分别创建 redisObject 结构和 sdshdr 结构， 而 embstr 编码则通过调用一次内存分配函数来分配一块连续的空间， 空间中依次包含 redisObject 和 sdshdr 两个结构 embstr 编码的字符串对象在执行命令时， 产生的效果和 raw 编码的字符串对象执行命令时产生的效果是相同的，但使用embstr 编码的字符串对象来保存短字符串值有以下好处： embstr 编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次。 释放 embstr 编码的字符串对象只需要调用一次内存释放函数， 而释放 raw 编码的字符串对象需要调用两次内存释放函数。 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起raw编码的字符串对象能够更好地利用缓存带来的优势。 字符串对象保存各类型值的编码方式： 值 编码 可以用 long 类型保存的整数。 int 可以用 long double 类型保存的浮点数。 embstr 或者 raw 字符串值， 或者因为长度太大而没办法用 long 类型表示的整数， 又或者因为长度太大而没办法用 long double 类型表示的浮点数。 embstr 或者 raw int 编码的字符串对象和 embstr 编码的字符串对象在条件满足的情况下， 会被转换为 raw 编码的字符串对象。对于 int 编码的字符串对象来说， 如果我们向对象执行了一些命令， 使得这个对象保存的不再是整数值， 而是一个字符串值， 那么字符串对象的编码将从 int 变为 raw 。 列表对象 列表对象的编码可以是 ziplist 或者 linkedlist 。 ziplist 编码的列表对象使用压缩列表作为底层实现， 每个压缩列表节点（entry）保存了一个列表元素 linkedlist 编码的列表对象使用双端链表作为底层实现， 每个双端链表节点（node）都保存了一个字符串对象， 而每个字符串对象都保存了一个列表元素 当列表对象可以同时满足以下两个条件时， 列表对象使用 ziplist 编码： 列表对象保存的所有字符串元素的长度都小于 64 字节； 列表对象保存的元素数量小于 512 个； 以上两个条件的上限值是可以修改的， 具体请看配置文件中关于 list-max-ziplist-value 选项和 list-max-ziplist-entries 选项的说明 不能满足这两个条件的列表对象需要使用 linkedlist 编码。 哈希对象 哈希对象的编码可以是 ziplist 或者 hashtable ziplist 编码的哈希对象使用压缩列表作为底层实现， 每当有新的键值对要加入到哈希对象时， 程序会先将保存了键的压缩列表节点推入到压缩列表表尾， 然后再将保存了值的压缩列表节点推入到压缩列表表尾， 因此： 保存了同一键值对的两个节点总是紧挨在一起， 保存键的节点在前， 保存值的节点在后； 先添加到哈希对象中的键值对会被放在压缩列表的表头方向， 而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。 hashtable 编码的哈希对象使用字典作为底层实现， 哈希对象中的每个键值对都使用一个字典键值对来保存 当哈希对象可以同时满足以下两个条件时， 哈希对象使用 ziplist 编码： 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节； 哈希对象保存的键值对数量小于 512 个； 这两个条件的上限值是可以修改的， 具体请看配置文件中关于 hash-max-ziplist-value 选项和 hash-max-ziplist-entries 选项的说明 不能满足这两个条件的哈希对象需要使用 hashtable 编码。 集合对象 集合对象的编码可以是 intset 或者 hashtable intset 编码的集合对象使用整数集合作为底层实现， 集合对象包含的所有元素都被保存在整数集合里面 hashtable 编码的集合对象使用字典作为底层实现， 字典的每个键都是一个字符串对象， 每个字符串对象包含了一个集合元素， 而字典的值则全部被设置为 NULL 当集合对象可以同时满足以下两个条件时， 对象使用 intset 编码： 集合对象保存的所有元素都是整数值； 集合对象保存的元素数量不超过 512 个； 第二个条件的上限值是可以修改的， 具体请看配置文件中关于 set-max-intset-entries 选项的说明。 不能满足这两个条件的集合对象需要使用 hashtable 编码。 有序集合对象 有序集合的编码可以是 ziplist 或者 skiplist ziplist 编码的有序集合对象使用压缩列表作为底层实现每个集合元素使用两个紧挨在一起的压缩列表节点来保存， 第一个节点保存元素的成员（member）， 而第二个元素则保存元素的分值（score）压缩列表内的集合元素按分值从小到大进行排序， 分值较小的元素被放置在靠近表头的方向， 而分值较大的元素则被放置在靠近表尾的方向 skiplist 编码的有序集合对象使用 zset 结构作为底层实现一个 zset 结构同时包含一个字典和一个跳跃表 内存回收因为 C 语言并不具备自动的内存回收功能， 所以 Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对象的引用计数信息， 在适当的时候自动释放对象并进行内存回收 对象的引用计数信息会随着对象的使用状态而不断变化： 在创建一个新对象时， 引用计数的值会被初始化为 1 ； 当对象被一个新程序使用时， 它的引用计数值会被增一； 当对象不再被一个程序使用时， 它的引用计数值会被减一； 当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。 对象的整个生命周期可以划分为创建对象、操作对象、释放对象三个阶段。 对象共享除了用于实现引用计数内存回收机制之外， 对象的引用计数属性还带有对象共享的作用 在 Redis 中， 让多个键共享同一个值对象需要执行以下两个步骤： 将数据库键的值指针指向一个现有的值对象； 将被共享的值对象的引用计数增一。 目前来说， Redis 会在初始化服务器时， 创建一万个字符串对象， 这些对象包含了从 0 到 9999 的所有整数值， 当服务器需要用到值为 0 到 9999 的字符串对象时， 服务器就会使用这些共享对象， 而不是新创建对象 创建共享字符串对象的数量可以通过修改 redis.h/REDIS_SHARED_INTEGERS 常量来修改 如果我们创建一个值为 100 的键 A ， 并使用 OBJECT REFCOUNT 命令查看键 A 的值对象的引用计数， 我们会发现值对象的引用计数为 2 ：12345redis&gt; SET A 100OKredis&gt; OBJECT REFCOUNT A(integer) 2 引用这个值对象的两个程序分别是持有这个值对象的服务器程序， 以及共享这个值对象的键 A 如果这时我们再创建一个值为 100 的键 B ， 那么键 B 也会指向包含整数值 100 的共享对象， 使得共享对象的引用计数值变为 312345678redis&gt; SET B 100OKredis&gt; OBJECT REFCOUNT A(integer) 3redis&gt; OBJECT REFCOUNT B(integer) 3 这些共享对象不单单只有字符串键可以使用， 那些在数据结构中嵌套了字符串对象的对象（linkedlist 编码的列表对象、 hashtable 编码的哈希对象、 hashtable 编码的集合对象、以及 zset 编码的有序集合对象）都可以使用这些共享对象 12345678910为什么 Redis 不共享包含字符串的对象？当服务器考虑将一个共享对象设置为键的值对象时， 程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同， 只有在共享对象和目标对象完全相同的情况下， 程序才会将共享对象用作键的值对象， 而一个共享对象保存的值越复杂， 验证共享对象和目标对象是否相同所需的复杂度就会越高， 消耗的 CPU 时间也会越多： 如果共享对象是保存整数值的字符串对象， 那么验证操作的复杂度为 O(1) ； 如果共享对象是保存字符串值的字符串对象， 那么验证操作的复杂度为 O(N) ； 如果共享对象是包含了多个值（或者对象的）对象， 比如列表对象或者哈希对象， 那么验证操作的复杂度将会是 O(N^2) 。因此， 尽管共享更复杂的对象可以节约更多的内存， 但受到 CPU 时间的限制， Redis 只对包含整数值的字符串对象进行共享。 总结 Redis 数据库中的每个键值对的键和值都是一个对象。 Redis 共有字符串、列表、哈希、集合、有序集合五种类型的对象，每种类型的对象至少都有两种或以上的编码方式，不同的编码可以在不同的使用场景上优化对象的使用效率。 服务器在执行某些命令之前， 会先检查给定键的类型能否执行指定的命令， 而检查一个键的类型就是检查键的值对象的类型。 Redis 的对象系统带有引用计数实现的内存回收机制， 当一个对象不再被使用时， 该对象所占用的内存就会被自动释放。 Redis 会共享值为 0 到 9999 的字符串对象。 对象会记录自己的最后一次被访问的时间， 这个时间可以用于计算对象的空转时间 参考文档传送门]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven依赖关系中Scope的作用]]></title>
    <url>%2F2018%2F06%2Fmaven%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E4%B8%ADScope%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介在POM 4中，中还引入了，它主要管理依赖的部署。目前可以使用5个值： compile，缺省值，适用于所有阶段，会随着项目一起发布。 provided，类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar。 runtime，只在运行时使用，如JDBC驱动，适用运行和测试阶段。 test，只在测试时使用，用于编译和运行测试代码。不会随项目发布。 system，类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它。 compile （编译范围）compile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用,同时它们也会被打包 provided （已提供范围）provided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包 runtime （运行时范围）runtime依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC驱动实现。 test （测试范围）test范围依赖 在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用 system （系统范围）system范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖）]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cron表达式]]></title>
    <url>%2F2018%2F06%2Fcron%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[语法格式1、Seconds Minutes Hours DayofMonth Month DayofWeek Year2、Seconds Minutes Hours DayofMonth Month DayofWeek 对应的含义Seconds:可出现”, - /“四个字符，有效范围为0-59的整数Minutes:可出现”, - /“四个字符，有效范围为0-59的整数Hours:可出现”, - /“四个字符，有效范围为0-23的整数DayofMonth:可出现”, - / ? L W C”八个字符，有效范围为0-31的整数Month:可出现”, - /“四个字符，有效范围为1-12的整数或JAN-DEcDayofWeek:可出现”, - / ? L C #”八个字符，有效范围为1-7的整数或SUN-SAT两个范围。1表示星期天，2表示星期一， 依次类推Year:可出现”, - * /“四个字符，有效范围为1970-2099年 特殊字符含义 * 表示所有值 ? 表示未说明的值，即不关心它为何值 - 表示一个指定的范围 , 表示附加一个可能值 / 符号前表示开始时间，符号后表示每次递增的值 L 用在day-of-month字段意思是 “这个月最后一天”；用在 day-of-week字段, 它简单意思是 “7” or “SAT”。 如果在day-of-week字段里和数字联合使用，它的意思就是 “这个月的最后一个星期几” – 例如： “6L” means “这个月的最后一个星期五”. 当我们用“L”时，不指明一个列表值或者范围是很重要的，不然的话，我们会得到一些意想不到的结果 W只能用在day-of-month字段。用来描叙最接近指定天的工作日（周一到周五）。例如：在day-of-month字段用“15W”指“最接近这个 月第15天的工作日”，即如果这个月第15天是周六，那么触发器将会在这个月第14天即周五触发；如果这个月第15天是周日，那么触发器将会在这个月第16天即周一触发；如果这个月第15天是周二，那么就在触发器这天触发。注意一点：这个用法只会在当前月计算值，不会越过当前月。“W”字符仅能在 day-of-month指明一天，不能是一个范围或列表。也可以用“LW”来指定这个月的最后一个工作日。 # 只能用在day-of-week字段。用来指定这个月的第几个周几。例：在day-of-week字段用”6#3”指这个月第3个周五（6指周五，3指第3个）。如果指定的日期不存在，触发器就不会触发 C指和calendar联系后计算过的值。例：在day-of-month字段用“5C”指在这个月第5天或之后包括calendar的第一天；在day-of-week字段用“1C”指在这周日或之后包括calendar的第一天 范例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152每隔5秒执行一次：*/5 * * * * ?每隔1分钟执行一次：0 */1 * * * ?每天23点执行一次：0 0 23 * * ?每天凌晨1点执行一次：0 0 1 * * ?每月1号凌晨1点执行一次：0 0 1 1 * ?每月最后一天23点执行一次：0 0 23 L * ?每周星期天凌晨1点实行一次：0 0 1 ? * L在26分、29分、33分执行一次：0 26,29,33 * * * ?每天的0点、13点、18点、21点都执行一次：0 0 0,13,18,21 * * ?每隔5分钟执行一次：0 0/5 * * * ?每天中午12点触发 ：0 0 12 * * ?每天上午10:15触发 :0 15 10 ? * *每天上午10:15触发 :0 15 10 * * ?每天上午10:15触发：0 15 10 * * ? *2005年的每天上午10:15触发 ：0 15 10 * * ? 2005在每天下午2点到下午2:59期间的每1分钟触发 ：0 * 14 * * ?在每天下午2点到下午2:55期间的每5分钟触发 ：0 0/5 14 * * ?在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 ：0 0/5 14,18 * * ?在每天下午2点到下午2:05期间的每1分钟触发 ：0 0-5 14 * * ?每年三月的星期三的下午2:10和2:44触发 ：0 10,44 14 ? 3 WED周一至周五的上午10:15触发 ：0 15 10 ? * MON-FRI每月15日上午10:15触发 ：0 15 10 15 * ?每月最后一日的上午10:15触发 ：0 15 10 L * ?每月的最后一个星期五上午10:15触发 ：0 15 10 ? * 6L2002年至2005年的每月的最后一个星期五上午10:15触发 ：0 15 10 ? * 6L 2002-2005每月的第三个星期五上午10:15触发 ：0 15 10 ? * 6#3]]></content>
      <categories>
        <category>cron</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>cron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Liquibase小知识]]></title>
    <url>%2F2018%2F06%2FLiquibase%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[liquibase相关 不依赖于特定的数据库，目前支持包括Oracle/Sql Server/DB2/MySql/Sybase/PostgreSQL/Caché等12种数据库，这样在数据库的部署和升级环节可帮助应用系统支持多数据库 提供数据库比较功能，比较结果保存在XML中，基于该XML你可用Liquibase轻松部署或升级数据库 以XML存储数据库变化，其中以作者和ID唯一标识一个变化（ChangSet），支持数据库变化的合并，因此支持多开发人员同时工作 在数据库中保存数据库修改历史（DatabaseChangeHistory），在数据库升级时自动跳过已应用的变化（ChangSet）提供变化应用的回滚功能，可按时间、数量或标签（tag）回滚已应用的变化。通过这种方式，开发人员可轻易的还原数据库在任何时间点的状态 可生成数据库修改文档（HTML格式） 提供数据重构的独立的IDE和Eclipse插件 目录以及文件解释 data 存放初始化数据文件 schemas存放数据结构变动脚本 changelog.xml主要执行文件，引入相关数据变动脚本 liquibase.properties数据库配置文件 pom.xml引入数据库依赖以及liquibase插件 liquibase常用命令changelogSync : 將changelog中未套用至db的change logs标识成已同步changelogSyncSQL : 同changelogSync，但只產生sql，而不執行同步到dbgenerateChangeLog : 將目前数据库的结构(默认不包含数据)生成 xmldbDoc : 產生像java doc的文件diff : 比對兩個数据库間的差異status : 顯示目前change set有那些change log會被套用到dbrollbackSql:根据回滚版本生成回滚sqlrollback:根据回滚版本生成回滚sql，并在数据库中执行update : 将changeLog.xml中的数据变动changeset脚本转化为sql语句，直接在数据库中执行updateSQL : 将changeLog.xml中的数据变动changeset脚本转化为sql语句，并输出到对应的文件中 Flyway VS Liquibase Flyway简单，直接写sql保存文件不支持回滚数据库迁移问题(SQL语句并不是一个广泛兼容的语言，有些关键字是独有的，如果flyway就需要兼容写两套sql脚本) Liquibase支持多种格式（xml/json/yaml/sql）支持多种数据库迁移可读性强支持回滚 传送门]]></content>
      <categories>
        <category>liquibase</category>
      </categories>
      <tags>
        <tag>liquibase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis常见数据类型操作命令]]></title>
    <url>%2F2018%2F05%2FRedis%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Key keys *—查询所有key exists key—判断key是否存在 move key db—移除当前库的key值 expire key 秒钟—设定过期时间 ttl key —查看多少秒后过期，-1永不过期，-2已过期 type key —查看key类型 FLUSHALL—清空所有数据库String set/get/del/append（追加）/strlen（获取key长度） incr（递增1）/decr（递减1）/incrby（指定递增多少）/decrby（指定递减多少）—数字才行 getrange（区间范围内取值）/setrange（区间范围内覆盖设值） setex（set with expire）设值以及过期时间/setnx（set if not exist 不存在则写入） mset（多值设置）/mget（多值获取）/msetnx（全部不存在才进行插入） getset 先获取再设值Hash hset/hget/hmset/hmget/hgetall/hdel hlen获取键值个数 hexist key keyname 判断keyname是否在key中 hkeys（获取所有key）/hvals（获取所有values） hincrby/hincrbyfloat（指定递增） hsetnx（键值不存在则进行设值）List lpush（添加左边元素）/rpush（添加右边元素）/lrange（LRANGE key start stop 获取列表片段，0 -1 返回整个列表） lindex （返回索引的元素值，-1表示从最右边的第一位） llen（获取list长度） lrem（LREM key count value，返回被删除的个数）count&gt;0，从左边开始删除前count个值为value的元素count&lt;0，从右边开始删除前|count|个值为value的元素count=0，删除所有值为value的元素 ltrim （根据传入索引截取保留对应列表片段） rpoplpush（一个列表右移除转移另一个列表左插入） lset（设值元素值） linsert key before/after val01 val02 （在val01之前或者之后插入val02）Set sadd（新增set元素，去重）/smembers（获取set集合）/sismember（判断是否set里的值） scard（返回集合元素个数） srem（ 删除集合中一个或多个元素，返回成功删除的个数） srandmember（SRANDMEMBER key [count]）根据count不同有不同结果，count大于元素总数时返回全部元素count&gt;0 ，返回集合中count不重复的元素count&lt;0，返回集合中count的绝对值个元素，但元素可能会重复 spop（随机出栈） smove（smove k1 k2 val -&gt;将k1的val剪切到k2上） sdiff【差集】（sdiff A B —-&gt;集合A和集合B，差集表示A-B，在A里有的元素B里没有，返回差集合；多个集合(A-B)-C） sinter【交集】 sunion【并集】ZSet zadd（不存在添加，存在更新） zscore（获取元素分数） zrange（元素从小到大:加上withscores 返回带元素，即元素，分数，当分数一样时，按元素排序） zrevrange（元素从大到小） zrangebyscore（指定分数范围元素）返回从小到大的在min和max之间的元素，( 左括号表示不包含，例如：80-100—&gt;(80 100withscore返回带分数limit offest count 向左偏移offest个元素，并获取前count个元素 zrevrangebyscore（从大到小排序） zrem（删除元素） zcard（计算集合内个数） zcount（计算对应范围内个数）eg：ZCOUNT salary 2000 5000 —-&gt;计算薪水在 2000-5000 之间的人数 zrank（获取下标值） zrevrank（逆序获取下标值） zscore（获取对应的分数）]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程之synchronized、Lock、volatile]]></title>
    <url>%2F2018%2F05%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8Bsynchronized%E3%80%81Lock%E3%80%81volatile%2F</url>
    <content type="text"><![CDATA[synchronized Java的关键字，是Java的内置特性，在JVM层面实现了对临界资源的同步互斥访问，通过对对象的头文件来操作，从而达到加锁和释放锁的目的 synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生 不能响应中断 同一时刻不管是读还是写都只能有一个线程对共享资源操作，其他线程只能等待，性能不高 synchronized是Java中的关键字，是一种同步锁： 无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁对应的是类，该类所有的对象同一把锁。 每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码。 实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制 lock Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现 Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁 Lock可以让等待锁的线程响应中断，synchronized不可以 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到 Lock可以提高多个线程进行读操作的效率1234567891011121314151617181920212223242526272829303132333435363738394041public interface Lock &#123; /** * 获取锁，如果锁被其他线程获取，则进行等待 */ void lock(); /** * 当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断， * 即中断线程的等待状态。也就是说， * 当两个线程同时通过lock.lockInterruptibly()想获取某个锁时， * 假若此时线程A获取到了锁，而线程B只有在等待， * 那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 * * @throws InterruptedException */ void lockInterruptibly() throws InterruptedException; /** * tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成 * 功，则返回true，如果获取失败（即锁已被其他线程获取），则返回 * false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 */ boolean tryLock(); /** * tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的， * 只不过区别在于这个方法在拿不到锁时会等待一定的时间， * 在时间期限之内如果还拿不到锁，就返回false。 * 如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 * * @param time * @param unit * @return * @throws InterruptedException */ boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); //释放锁 Condition newCondition();&#125; volatile 可见性：保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的 有序性：禁止进行指令重排序 加入volatile关键字时，会多出一个lock前缀指令，lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成 它会强制将对缓存的修改操作立即写入主存 如果是写操作，它会导致其他CPU中对应的缓存行无效 lock和synchronized的区别 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 Lock可以提高多个线程进行读操作的效率。在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized volatile和synchronized区别 volatile本质是在告诉jvm当前变量在寄存器中的值是不确定的,需要从主存中读取,synchronized则是锁定当前变量,只有当前线程可以访问该变量,其他线程被阻塞住. volatile仅能使用在变量级别,synchronized则可以使用在变量,方法. volatile仅能实现变量的修改可见性,而synchronized则可以保证变量的修改可见性和原子性. 《Java编程思想》上说，定义long或double变量时，如果使用volatile关键字，就会获得（简单的赋值与返回操作）原子性。 volatile不会造成线程的阻塞,而synchronized可能会造成线程的阻塞. 当一个域的值依赖于它之前的值时，volatile就无法工作了，如n=n+1,n++等。如果某个域的值受到其他域的值的限制，那么volatile也无法工作，如Range类的lower和upper边界，必须遵循lower&lt;=upper的限制。 使用volatile而不是synchronized的唯一安全的情况是类中只有一个可变的域 锁可重入锁如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock（唯一实现了Lock接口的类）都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2 可中断锁在Java中，synchronized就不是可中断锁，而Lock是可中断锁如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁 公平锁公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁 参考：java中volatile、synchronized和lock解析、Java并发编程：Lock]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot学习之禁用数据库自动配置]]></title>
    <url>%2F2018%2F05%2FSpringboot%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A6%81%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[SpringBoot默认会自动配置数据库，如果业务不需要，就要手动禁用数据库自动配置,在Application的SpringBootApplication注解里加上12345@SpringBootApplication(exclude = &#123; DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class, HibernateJpaAutoConfiguration.class&#125;)]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA集合总结]]></title>
    <url>%2F2018%2F05%2FJAVA%E9%9B%86%E5%90%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Collection接口是集合类的根接口，Java中没有提供这个接口的直接的实现类。但是却让其被继承产生了两个接口，就是Set和List。Set中不能包含重复的元素。List是一个有序的集合，可以包含重复的元素，提供了按索引访问的方式 Map是Java.util包中的另一个接口，它和Collection接口没有关系，是相互独立的，但是都属于集合类的一部分。Map包含了key-value对。Map不能包含重复的key，但是可以包含相同的value Iterator，所有的集合类，都实现了Iterator接口，这是一个用于遍历集合中元素的接口，主要包含以下三种方法： hasNext()是否还有下一个元素。 next()返回下一个元素。 remove()删除当前元素 List List里存放的对象是有序的，同时也是可以重复的，List关注的是索引，拥有一系列和索引相关的方法，查询速度快。因为往list集合里插入或删除数据时，会伴随着后面数据的移动，所有插入删除数据速度慢。 说明 ArrayList在内存不够时默认是扩展50% + 1个，Vector是默认扩展1倍。 Vector属于线程安全级别的，但是大多数情况下不使用Vector，因为线程安全需要更大的系统开销。 一般使用ArrayList和LinkedList比较多，LinkedList不存在get()的操作，不能单个定位，ArrayList是顺序存储结构，LinkedList是链表存储结构 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据 ArrayList（常用、数组实现，对元素快速随机访问）ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要讲已经有数组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除 Vector（数组实现、线程同步、需高花费）Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢 LinkedList（链表结构、Queue）LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用 ArrayList和LinkedList在用法上没有区别，但是在功能上还是有区别的。LinkedList经常用在增删操作较多而查询操作很少的情况下，ArrayList则相反 Set Set集合不允许出现重复数据允许包含值为null的元素，但最多只能有一个null元素。 HashSet HashSet中不能有重复的元素 HashSet是无序的 HashSet也是基于HashMap实现 TreeSet TreeSet中不能有重复的元素； TreeSet具有排序功能，缺省是按照自然排序进行排列 TreeSet中的元素必须实现Comparable接口并重写compareTo()方法，TreeSet判断元素是否重复 、以及确定元素的顺序靠的都是这个方法 基于TreeMap实现 Map Map集合中存储的是键值对，键不能重复，值可以重复。根据键得到值，对map集合遍历时先得到键的set集合，对set集合进行遍历，得到相应的值 Map遍历：KeySet()、entrySet()keySet其实是遍历了2次，一次是转为iterator，一次就是从HashMap中取出key所对于的value。而entryset只是遍历了第一次，它把key和value都放到了entry中，所以entrySet效率较高 HashMapHashMap是最常用的Map，它根据键的HashCode值存储数据，根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。因为键对象不可以重复，所以HashMap最多只允许一条记录的键为Null，允许多条记录的值为Null，是非同步的 HashMap是无序的散列映射表； HashMap通过Hash 算法来决定存储位置 底层实现是哈希表 HashtableHashtable与HashMap类似，是HashMap的线程安全版，它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了Hashtale在写入时会比较慢，它继承自Dictionary类，不同的是它不允许记录的键或者值为null，同时效率较低 TreeMapTreeMap实现SortMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序（自然顺序），也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。不允许key值为空，非同步的 适用于按自然顺序或自定义顺序遍历键(key)。 底层是二叉树 提供compareTo，可以定义排序方法 LinkedHashMapLinkedHashMap保存了记录的插入顺序，在用Iteraor遍历LinkedHashMap时，先得到的记录肯定是先插入的，在遍历的时候会比HashMap慢，有HashMap的全部特性。 ConcurrentHashMap 线程安全 JDK1.7分析：ConcurrentHashMap采用 分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构 JDK1.8分析：1.8的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构 CAS的思想：三个参数，一个当前内存值V、旧的预期值A、即将更新的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。 主要实现类区别Vector VS ArrayList vector是线程同步的，所以它也是线程安全的，而arraylist是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用arraylist效率比较高。 如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%，而arraylist增长率为目前数组长度的50%。如果在集合中使用数据量比较大的数据，用vector有一定的优势。 如果查找一个指定位置的数据，vector和arraylist使用的时间是相同的，如果频繁的访问数据，这个时候使用vector和arraylist都可以。而如果移动一个指定位置会导致后面的元素都发生移动，这个时候就应该考虑到使用linklist,因为它移动一个指定位置的数据时其它元素不移动。 ArrayList 和Vector是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，都允许直接序号索引元素，但是插入数据要涉及到数组元素移动等内存操作，所以索引数据快，插入数据慢，Vector由于使用了synchronized方法（线程安全）所以性能上比ArrayList要差，LinkedList使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快 ArrayList VS LinkedList ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 这一点要看实际情况的。若只对单条数据插入或删除，ArrayList的速度反而优于LinkedList。但若是批量随机的插入删除数据，LinkedList的速度大大优于ArrayList. 因为ArrayList每插入一条数据，要移动插入点及之后的所有数据 HashMap VS TreeMap HashMap通过hashcode对其内容进行快速查找，而TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。 在Map 中插入、删除和定位元素，HashMap是最好的选择。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现。两个map中的元素一样，但顺序不一样，导致hashCode()不一样。同样做测试：123在HashMap中，同样的值的map,顺序不同，equals时，false;而在treeMap中，同样的值的map,顺序不同,equals时，true，说明treeMap在equals()时是整理了顺序了的 HashTable VS HashMap 同步性:Hashtable是线程安全的，也就是说是同步的，而HashMap是线程序不安全的，不是同步的。 HashMap允许存在一个为null的key，多个为null的value 。 hashtable的key和value都不允许为null 参考：JAVA集合类汇总、深入理解Java集合]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL两种引擎的区别]]></title>
    <url>%2F2018%2F05%2FMySQL%E4%B8%A4%E7%A7%8D%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Innodb引擎Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。 MyISAM引擎MyISAM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。不过和Innodb不同，MyISAM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyISAM也是很好的选择。 区别 MyISAM是非事务安全的，而InnoDB是事务安全的 MyISAM锁的粒度是表级的，而InnoDB支持行级锁 MyISAM支持全文类型索引，而InnoDB不支持全文索引 MyISAM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyISAM MyISAM表保存成文件形式，跨平台使用更加方便 应用场景 MyIASM管理非事务表，提供高速存储和检索以及全文搜索能力，如果再应用中执行大量select操作，应该选择MyIASM InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB 摘抄：MySQL两种引擎的区别]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis主从复制]]></title>
    <url>%2F2018%2F05%2FRedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[配置从库，不配主库从库配置：slaveof 主库ip 主库端口每次与master断开后，都需要重新连接，除非配置redis.conf文件 修改配置文件常用3招 一主二仆 薪火相传 反客为主（slaveof no one） 复制原理salve 启动成功连接到master后会发送一个sync命令，master接到命令后启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，进程执行完毕后，master将传送整个数据文件到slave，以完成一次完全同步，也就是全量复制，而slave服务在接收到数据后，存盘到内存中；master将新的修改命令依次传给slave，完成同步，此时为增量复制 只要重新连接master，一次完全同步（全量复制）将被自动执行 哨兵模式 反客为主的自动版本，监控主机是否故障，当主库挂了，根据投票数重新选定master 新建sentinel.conf 配置文件内容 1sentinel monitor 自定义名称 监控库ip 监控库端口 1 启动哨兵 1redis-sentinel /usr/local/redis/sentinel.conf 自动监控，选好新master后，原master恢复后会变成slave 一组sentinel可以同时监控多个master 复制的缺点由于所有的写操作都在master上，然后同步更新到slave上，所以从master同步到slave 机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave机器数量的增加也会使得这个问题更加严重]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化存储]]></title>
    <url>%2F2018%2F05%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[Redis中数据存储模式 cache-onlypersistence 1234cache-only：只做为“缓存”服务，不持久数据，数据在服务终止后将消失，此模式下也将不存在“数据恢复”的手段，是一种安全性低/效率高/容易扩展的方式；persistence：为内存中的数据持久备份到磁盘文件，在服务重启后可以恢复，此模式下数据相对安全。 对于persistence持久化存储，Redis提供了两种持久化方法12Redis DataBase(简称RDB)Append-only file (简称AOF) 如果同时开启两种持久化，会优先加载AOF进行恢复 RDB持久化：默认开启 指定时间间隔进行快照存储 优点：使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能缺点：RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候 save：服务器进程进行快照存储（阻塞） bgsave：进行异步快照存储（派生子进程处理，非阻塞） 异常恢复：redis-check-rdb1234567891011121314151617181920#dbfilename：持久化数据存储在本地的文件dbfilename dump.rdb#dir：持久化数据存储在本地的路径，如果是在/redis/redis-3.0.6/src下启动的redis-cli，则数据会存储在当前src目录下dir ./##snapshot触发的时机，save &lt;seconds&gt; &lt;changes&gt; ##如下为900秒后，至少有一个变更操作，才会snapshot ##对于此值的设置，需要谨慎，评估系统的变更操作密集程度 ##可以通过save “”来关闭snapshot功能 #持久化(以快照的方式) 策略（默认）save 900 1 （15分钟变更一次）save 300 10 （5分钟变更10次）save 60 10000 （1分钟变更1万次）##当snapshot时出现错误无法继续时，是否阻塞客户端“变更操作”，“错误”可能因为磁盘已满/磁盘故障/OS级别异常等 stop-writes-on-bgsave-error yes ##是否启用rdb文件压缩，默认为“yes”，压缩往往意味着“额外的cpu消耗”，同时也意味这较小的文件尺寸以及较短的网络传输时间 rdbcompression yes AOF持久化：默认不开启 以日志的形式来记录每个写操作，将redis执行过的所有写指令记录下来（读操作不记录），只许追加但不可以改写文件，redis启动之初会读取改文件进行重新构建数据 AOF通过保存所有修改数据库的写命令请求来记录服务器的数据库状态 AOF文件中的所有命令都会以Redis命令请求协议的格式保存优点：可以保持更高的数据完整性，如果设置追加file的时间是1s，如果redis发生故障，最多会丢失1s的数据（appendfsync—&gt;everysec）；且如果日志写入不完整支持redis-check-aof来进行日志修复；AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）。缺点：AOF文件比RDB文件大，且恢复速度慢，运行效率也比rdb慢。 重写机制 当超过阈值，则启动内容压缩，只保留最小指令集，可使用命令：bgrewriteaof 定义：AOF采用文件追加的方式持久化数据，所以文件会越来越大，为了避免这种情况发生，增加了重写机制当AOF文件的大小超过了配置所设置的阙值时，Redis就会启动AOF文件压缩，只保留可以恢复数据的最小指令集，可以使用命令bgrewriteaof 原理：当AOF增长过大时，会fork出一条新的进程将文件重写(也是先写临时文件最后rename)，遍历新进程的内存数据，每条记录有一条set语句。重写AOF文件并没有操作旧的AOF文件，而是将整个内存中的数据内容用命令的方式重写了一个新的aof文件（有点类似快照） 触发机制：Redis会记录上次重写时的AOF文件大小，默认配置时当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发12auto-aof-rewrite-percentage 100 （一倍）auto-aof-rewrite-min-size 64mb 持久化策略 appendfsync always (同步持久化，每次发生数据变更会被立即记录到磁盘，性能差但数据完整性比较好) appendfsync everysec (异步操作，每秒记录，如果一秒钟内宕机，有数据丢失) appendfsync no （将缓存回写的策略交给系统，linux 默认是30秒将缓冲区的数据回写硬盘的）12345678910111213141516171819##此选项为aof功能的开关，默认为“no”，可以通过“yes”来开启aof功能 ##只有在“yes”下，aof重写/文件同步等特性才会生效 appendonly yes ##指定aof文件名称 appendfilename appendonly.aof ##指定aof操作中文件同步策略，有三个合法值：always(记录立即同步，性能较差) everysec(每秒同步，官方推荐) no(将缓存回写的策略交给系统，linux 默认是30秒将缓冲区的数据回写硬盘的)，默认为everysec appendfsync everysec ##在aof-rewrite期间，appendfsync是否暂缓文件同步，&quot;no&quot;表示“不暂缓”，“yes”表示“暂缓”，默认为“no” no-appendfsync-on-rewrite no ##aof文件rewrite触发的最小文件尺寸(mb,gb),只有大于此aof文件大于此尺寸是才会触发rewrite，默认“64mb” auto-aof-rewrite-min-size 64mb ##相对于“上一次”rewrite，本次rewrite触发时aof文件应该增长的百分比。 ##每一次rewrite之后，redis都会记录下此时“新aof”文件的大小(例如A)，那么当aof文件增长到A*(1 + p)之后 ##触发下一次rewrite，每一次aof记录的添加，都会检测当前aof文件的尺寸。 auto-aof-rewrite-percentage 100 比较 RDB与AOF同时开启 默认先加载AOF的配置文件 相同数据集，AOF文件要远大于RDB文件，恢复速度慢于RDB AOF运行效率慢于RDB,但是同步策略效率好，不同步效率和RDB相同]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java常见设计模式]]></title>
    <url>%2F2018%2F04%2FJava%E5%B8%B8%E8%A7%81%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式 保证一个类仅有一个实例，并提供一个访问它的全局访问点 懒汉式123456789101112131415public class Singleton &#123; /* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */ private static Singleton instance = null; /* 私有构造方法，防止被实例化 */ private Singleton() &#123;&#125; /* 1:懒汉式，静态工程方法，创建实例 */ public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 调用：Singleton.getInstance().method();优点：延迟加载（需要的时候才去加载）,适合单线程操作缺点： 线程不安全，在多线程中很容易出现不同步的情况，如在数据库对象进行的频繁读写操作时。 饿汉模式 在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快 1234567891011121314public class EagerSingleton &#123; //饿汉单例模式 //在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快 private static EagerSingleton instance = new EagerSingleton();//静态私有成员，已初始化 private EagerSingleton() &#123; //私有构造函数 &#125; public static EagerSingleton getInstance() //静态，不用同步（类加载时已初始化，不会有多线程的问题） &#123; return instance; &#125;&#125; 双重线程检查模式12345678910111213141516171819202122232425public class SingletonInner &#123; private static volatile SingletonInner sInst = null; // &lt;&lt;&lt; 这里添加了 volatile /** * 私有的构造函数 */ private SingletonInner() &#123;&#125; public static SingletonInner getInstance() &#123; SingletonInner inst = sInst; // &lt;&lt;&lt; 在这里创建临时变量 if (inst == null) &#123; synchronized (SingletonInner.class) &#123; inst = sInst; if (inst == null) &#123; inst = new SingletonInner(); sInst = inst; &#125; &#125; &#125; return inst; // &lt;&lt;&lt; 注意这里返回的是临时变量 &#125; protected void method() &#123; System.out.println(&quot;SingletonInner&quot;); &#125; &#125; volatile：可见性（volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新）防止指令重排序（赋值后多执行了一个“load addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障）调用：Singleton.getInstance().method();优点：延迟加载，线程安全缺点：写法复杂，不简洁 内部类模式12345678910111213141516171819202122public class SingletonInner &#123; /** * 内部类实现单例模式 * 延迟加载，减少内存开销 */ private static class SingletonHolder &#123; private static SingletonInner instance = new SingletonInner(); &#125; /** * 私有的构造函数 */ private SingletonInner() &#123;&#125; public static SingletonInner getInstance() &#123; return SingletonHolder.instance; &#125; protected void method() &#123; System.out.println(&quot;SingletonInner&quot;); &#125; &#125; 调用：Singleton.getInstance().method();优点：延迟加载，线程安全（java中class加载时互斥的），也减少了内存消耗，推荐使用内部类方式。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中的代码优化]]></title>
    <url>%2F2018%2F04%2F%E5%B7%A5%E4%BD%9C%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[函数式接口改造123456789101112131415161718192021222324252627private TopModel generateTopDetailModel(TopModel topModel, List&lt;PlayerWithData&gt; playerWithDataList) &#123; List&lt;TopDetailModel&gt; shotsTopDetail = playerWithDataList.stream() .filter(p -&gt; p.getShots() != null &amp;&amp; p.getShots() != 0)//要过滤掉空值再比较,且要过滤掉0值 .sorted(Comparator.comparing(PlayerWithData::getShots).reversed() .thenComparing(PlayerWithData::getName)). limit(3).map(StatsPlayer -&gt; &#123; TopDetailModel model = new TopDetailModel(); BeanUtils.copyProperties(StatsPlayer, model); model.setDataCount(StatsPlayer.getShots()); return model; &#125;).collect(Collectors.toList()); topModel.setShots(shotsTopDetail); List&lt;TopDetailModel&gt; maxDribbSpTopDetail = playerWithDataList.stream(). filter(p -&gt; p.getMaxDribbSp() != null &amp;&amp; p.getMaxDribbSp() != 0.0) .sorted(Comparator.comparing(PlayerWithData::getMaxDribbSp).reversed() .thenComparing(PlayerWithData::getName)). limit(3).map(StatsPlayer -&gt; &#123; TopDetailModel model = new TopDetailModel(); BeanUtils.copyProperties(StatsPlayer, model); model.setDataCount(StatsPlayer.getMaxDribbSp()); return model; &#125;).collect(Collectors.toList()); topModel.setMaxDribbSp(maxDribbSpTopDetail); //省略N个字段的获取设值... return topModel; &#125; 123456789101112131415private List&lt;TopDetailModel&gt; setIntegerTopModel(List&lt;PlayerWithData&gt; playerWithDataList, Function&lt;PlayerWithData, Integer&gt; function, Integer count) &#123; return playerWithDataList.stream() .filter(p -&gt; function.apply(p) != null &amp;&amp; function.apply(p) != 0) .sorted(Comparator.comparing(function).reversed() .thenComparing(PlayerWithData::getName)). limit(count).map(stasPlayer -&gt; &#123; TopDetailModel model = new TopDetailModel(); BeanUtils.copyProperties(stasPlayer, model); model.setDataCount(function); return model; &#125;).collect(Collectors.toList()); &#125; 之后每个参数传入函数方法调用设值即可： topModel.setShots(setIntegerTopModel(playerWithDataList, PlayerWithData::getShots, count)); 字符串操作12345678910for (PenaltyModel penaltyModel : penaltyModels) &#123; String eventType = &quot;PENALTY.&quot;; if (penaltyModel.getIsGoal()) &#123; eventType = eventType + &quot;TRUE&quot;; &#125; else &#123; eventType = eventType + &quot;FALSE&quot;; &#125; ...... 每次循环都会创建新对象，造成内存资源浪费 &#125; 12345String为字符串常量，而StringBuilder和StringBuffer均为字符串变量，即String对象一旦创建之后该对象是不可更改的，但后两者的对象是变量，是可以更改的String：适用于少量的字符串操作的情况StringBuilder：适用于单线程下在字符缓冲区进行大量操作的情况StringBuffer：适用多线程下在字符缓冲区进行大量操作的情况 枚举命名建议带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开正例：BallEnum 反例：BallType 避免在循环中进行数据库操作12345678910private void uploadTeamConfig(List&lt;TeamConfig&gt; teamConfigList, String matchId) &#123; if (!CollectionUtils.isEmpty(teamConfigList)) &#123; for (TeamConfig teamConfig : teamConfigList) &#123; PerMatchTeamConfig perMatchTeamConfig = new PerMatchTeamConfig(); BeanUtils.copyProperties(teamConfig, perMatchTeamConfig); perMatchTeamConfig.setMatchId(matchId); perMatchTeamConfigService.saveOrUpdateByMatchIdAndTeamId(perMatchTeamConfig); &#125; &#125; &#125;]]></content>
      <categories>
        <category>优化</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习之actuator]]></title>
    <url>%2F2018%2F04%2FSpringBoot%E5%AD%A6%E4%B9%A0%E4%B9%8Bactuator%2F</url>
    <content type="text"><![CDATA[应用配置类/autoconfig用来获取应用的自动化配置报告，其中包括所有自动化配置的候选项。该端点可以帮助我们方便找到一些自动化配置为什么没有生效的具体原因。 positiveMatches：返回条件匹配成功的自动化配置 negativeMatches：返回条件匹配不成功的自动化配置 /beans获取应用上下文创建的所有Bean /configprops获取应用中配置的属性信息报告。prefix属性代表了属性的配置前缀，properties代表了各个属性的名称和值。如果要关闭该端点，通过使用endpoints.configprops.enabled=false来完成设置 /env该端点主要是用来获取应用中所有可用的环境属性报告。包括环境变量、JVM属性、应用的配置属性、命令行的参数。该端点会进行隐私保护，对于password、serect、key等关键词会使用*来替代实际的属性值 /mappings返回所有SpringMVC的控制器映射关系报告 /info返回自定义的配置信息，该自定义配置信息需要以info为前缀进行配置，例如：12info.app.name=spring-helloinfo.app.version=v0.0.1 度量指标类/metrics返回当前应用的各类重要度量指标，比如内存信息、线程信息、垃圾回收信息等。 系统信息：包括处理器数量processors、运行时间uptime和instance.uptime、系统平均负载systemload.average mem.* ：内存概要情况 heap.* ：堆内存使用情况 noheap.* ： 非堆内存使用情况 threads.*：线程使用情况，包括线程数、守护线程数（daemon）、线程峰值（peak）等 classes.*：应用加载和卸载的类统计 gc.*：垃圾收集器的详细信息，包括垃圾回收次数gc.ps_scavenge.count、垃圾回收消耗时间gc.ps_scavenge.time、标记-清楚算法的次数gc.ps_marksweep.count、标记-清楚算法的消耗时间gc.ps_marksweep.time httpsessions.*：Tomcat容器的会话使用情况，包括最大会话数httpsessions.max和活跃会话数httpsessions.active，该度量指标仅在引入嵌入式Tomcat作为应用容器才会提供 gauge.* ：HTTP请求的性能指标之一，主要用来反映一个绝对数值，比如gauge.response.hello:5，表示上一次hello请求的延迟时间为5毫秒 counter.*：HTTP请求的性能指标之一，主要作为计数器使用，记录了增加量和减少量，counter.status.200.hello:11，表示hello请求返回200状态的次数为11 可以通过/metrics/{name}接口来获取更细粒度的度量信息，比如通过/metrics/mem.free来获取当前可用内存数量 /health获取应用的各类健康指标信息 /dump用来暴露程序运行中的线程信息 /trace返回基本的HTTP跟踪信息，始终保留最近的100条请求记录 操作控制类在原生端点中，只提供了一个用来关闭应用的端点：/shutdown，通过如下配置开启1endpoints.shutdown.enabled=true 配置好了之后，只要访问该端点，就能实现关闭该应用的远程操作，后续Eureka中还会有许多控制端点…]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《书单》]]></title>
    <url>%2F2018%2F04%2F%E3%80%8A%E4%B9%A6%E5%8D%95%E3%80%8B%2F</url>
    <content type="text"><![CDATA[一 锋利的Jquery JavaScript高级程序设计 Maven Spring实战 第四版 二 Java8实战 Redis设计与实现 SpringBoot实战 深入理解Java虚拟机 Spring Cloud与Docker微服务架构实战 SpringCloud微服务实战 鸟哥的linux私房菜-服务器架设（待定）]]></content>
      <categories>
        <category>书单</category>
      </categories>
      <tags>
        <tag>书单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Stream结合RabbitMQ简单实例]]></title>
    <url>%2F2018%2F03%2FSpring-Cloud-Stream%E7%BB%93%E5%90%88RabbitMQ%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[了解Spring Cloud Stream了解RabbitMQ各项目中引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 生产者AA项目中新建一个接口作为通道 NotifyChannelConstant为自定义常量@Output注解代表这是一个输出通道 123456@Componentpublic interface PdfNotifyChannel &#123; @Output(NotifyChannelConstant.PDF_NOTIFY_CHANNEL) MessageChannel output();&#125; 绑定接口@EnableBinding 进行消息通知的类，需要添加@EnableBinding(PdfNotifyChannel.class)，指定绑定的接口通道 在类中进行初始化 12@Autowiredprivate PdfNotifyChannel pdfNotifyChannel; 业务方法中进行调用 1pdfNotifyChannel.output().send(MessageBuilder.withPayload(msg).build()); 消费者BB项目中新建一个接口作为通道 NotifyChannelConstant为自定义常量，此处引用的是A项目中的常量@Input注解代表这是一个输入通道，通道名需要与生产者对应才能接收消息12345@Componentpublic interface PdfNotifyChannel &#123; @Input(NotifyChannelConstant.PDF_NOTIFY_CHANNEL) MessageChannel input();&#125; 绑定接口@EnableBinding 进行消息接收的类，需要添加@EnableBinding(PdfNotifyChannel.class)，指定绑定的接口通道 监听使用@StreamListener进行监听该通道中的信息123456789/** * 监听推送信息 * @param message */ @StreamListener(NotifyChannelConstant.PDF_NOTIFY_CHANNEL) public void receiverPdfNotify(Message&lt;String&gt; message) &#123; LOGGER.info(&quot;频道[&#123;&#125;]监听信息为:[&#123;&#125;]&quot;, NotifyChannelConstant.PDF_NOTIFY_CHANNEL, message.getPayload()); &#125; 配置RabbitMQ 需要AB配置一致1234567spring.rabbitmq.host=localhostspring.rabbitmq.username=guestspring.rabbitmq.password=guest#默认5672spring.rabbitmq.port=5673#默认/spring.rabbitmq.virtual-host=/ RabbitMQ相关命令1234567891011121314151617181920# 查看当前所有用户$ sudo rabbitmqctl list_users# 查看默认guest用户的权限$ sudo rabbitmqctl list_user_permissions guest# 由于RabbitMQ默认的账号用户名和密码都是guest。为了安全起见, 先删掉默认用户$ sudo rabbitmqctl delete_user guest# 添加新用户$ sudo rabbitmqctl add_user username password# 设置用户tag$ sudo rabbitmqctl set_user_tags username administrator# 赋予用户默认vhost的全部操作权限$ sudo rabbitmqctl set_permissions -p / username &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;# 查看用户的权限$ sudo rabbitmqctl list_user_permissions username]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九浅一深之RabbitMQ]]></title>
    <url>%2F2018%2F03%2F%E4%B9%9D%E6%B5%85%E4%B8%80%E6%B7%B1%E4%B9%8BRabbitMQ%2F</url>
    <content type="text"><![CDATA[RabbitMQ是一个开源的AMQP实现：AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。 AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 ConnectionFactory、Connection、Channel都是RabbitMQ对外提供的API中最基本的对象。Connection是RabbitMQ的socket链接，它封装了socket协议相关部分逻辑。ConnectionFactory为Connection的制造工厂。 Channel是我们与RabbitMQ打交道的最重要的一个接口，我们大部分的业务操作是在Channel这个接口中完成的，包括定义Queue、定义Exchange、绑定Queue与Exchange、发布消息等。 RabbitMQMessage消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher消息的生产者，也是一个向交换器发布消息的客户端应用程序。 Exchange交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。 Binding绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 Connection网络连接，比如一个TCP连接。 Channel信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。 Virtual Host虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。 Broker表示消息队列服务器实体。 AMQP 中的消息路由 AMQP 中消息的路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发送到那个队列。 Exchange 类型Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了 direct 消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。 fanout 每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。 topic routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit” binding key与routing key一样也是句点号“. ”分隔的字符串 binding key中可以存在两种特殊字符’*’与“#”，用于做模糊匹配，其中“**”用于匹配一个单词，“#”用于匹配多个单词（可以是零个） headerheaders类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。 RPCMQ本身是基于异步的消息处理，前面的示例中所有的生产者（P）将消息发送到RabbitMQ后不会知道消费者（C）处理成功或者失败（甚至连有没有消费者来处理这条消息都不知道）。 但实际的应用场景中，我们很可能需要一些同步处理，需要同步等待服务端将我的消息处理完成后再进行下一步处理。这相当于RPC（Remote Procedure Call，远程过程调用）。在RabbitMQ中也支持RPC。 RabbitMQ 中实现RPC 的机制是： 客户端发送请求（消息）时，在消息的属性（MessageProperties ，在AMQP 协议中定义了14中properties ，这些属性会随着消息一起发送）中设置两个值replyTo （一个Queue 名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue 中）和correlationId （此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败） 服务器端收到消息并处理 服务器端处理完消息后，将生成一条应答消息到replyTo 指定的Queue ，同时带上correlationId 属性 客户端之前已订阅replyTo 指定的Queue ，从中收到服务器的应答消息后，根据其中的correlationId 属性分析哪条请求被执行了，根据执行结果进行后续业务处理 RabbitMQ 选型和对比 从社区活跃度按照目前网络上的资料，RabbitMQ 、activeM 、ZeroMQ 三者中，综合来看，RabbitMQ 是首选。 持久化消息比较ZeroMq 不支持，ActiveMq 和RabbitMq 都支持。持久化消息主要是指我们机器在不可抗力因素等情况下挂掉了，消息不会丢失的机制。 综合技术实现可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等等。RabbitMq / Kafka 最好，ActiveMq 次之，ZeroMq 最差。当然ZeroMq 也可以做到，不过自己必须手动写代码实现，代码量不小。尤其是可靠性中的：持久性、投递确认、发布者证实和高可用性。 高并发毋庸置疑，RabbitMQ 最高，原因是它的实现语言是天生具备高并发高可用的erlang 语言。 比较关注的比较， RabbitMQ 和 KafkaRabbitMq 比Kafka 成熟，在可用性上，稳定性上，可靠性上， RabbitMq 胜于 Kafka （理论上）。 另外，Kafka 的定位主要在日志等方面， 因为Kafka 设计的初衷就是处理日志的，可以看做是一个日志（消息）系统一个重要组件，针对性很强，所以 如果业务方面还是建议选择 RabbitMq 。还有就是，Kafka 的性能（吞吐量、TPS ）比RabbitMq 要高出来很多。 原文：消息队列之 RabbitMQ 、 我为什么要选择RabbitMQ]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务管理@Transactional]]></title>
    <url>%2F2018%2F03%2F%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86-Transactional%2F</url>
    <content type="text"><![CDATA[传播行为（生命周期）-Propagation 所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为（org.springframework.transaction.annotation.Propagation） REQUIRED（默认）方法A调用时没有事务新建一个事务，当在方法A调用另一个方法B的时候，方法B将使用同一个事务；如果方法B发生异常需要数据回滚的时候，整个事务回滚 REQUIRED_NEW对于方法A与B，在方法调用的时候无论是否有事务，都要开启一个新的事；如果这样方法B有异常不会导致方法A的数据回滚 NESTED和REQUIRED_NEW类似，但支持JDBC，不支持JPA或者Hibernate SUPPORTS方法调用时有事务就用事务，没有就不用 NOT_SUPPORTS强制方法不在事务中执行，若有事务，在方法调用到结束阶段事务都将会被挂起 NEVER强制方法不在事务中执行，若有事务则抛出异常 MANDATORY强制方法在事务中执行，若无事务则抛出异常指定方法：通过使用propagation属性设置1@Transactional(propagation = Propagation.REQUIRED) 隔离级别-Isolation 隔离级别是指若干个并发的事务之间的隔离程度，与我们开发时候主要相关的场景包括：脏读取、重复读、幻读；Isolation（隔离）决定了事务的完整性，处理在多事务对相同数据下的处理机制 READ_UNCOMMITED对于在A事务里修改了一条记录但没有提交事务，在B事务可以读取到修改后的记录。可导致脏读，不可重复读以及幻读 READ_COMMITED只有当在A事务里修改了一条记录且提交记录之后，B事务才可以读取到提交后的记录；阻止脏读，但可能导致不可重复读和幻读 REPEATABLE_READ不仅能实现READ_COMMITED的功能，而且还能阻止当A事务读取了一条记录，B事务将不允许修改这条记录；阻止脏读和不可重复读，但可出现幻读 SERIALIZABLE此级别下事务是顺序执行的，可以避免上述级别的缺陷，但开销较大 DEFAULT（默认）使用当前数据库的默认隔离界级别，如Oracle、SqlServer是READ_COMMITED；Mysql是REPEATABLE_READ指定方法：通过使用isolation属性设置1@Transactional(isolation = Isolation.DEFAULT) timeout（默认TIMEOUT_DEFAULT）timeout指定事务过期时间，默认为当前数据库的事务过期时间 readonly（默认false）指定当前事务是否是只读事务 rollbackFor（默认Throwable的子类）指定哪个或者哪些异常可以引起事务回滚 noRollBackFor（默认Throwable的子类）指定哪个或者哪些异常不可以引起事务回滚 12345678@Transactional(propagation=Propagation.REQUIRED) //控制事务传播。默认是Propagation.REQUIRED@Transactional(isolation=Isolation.DEFAULT) //控制事务隔离级别。默认跟数据库的默认隔离级别相同@Transactional(readOnly=false) //控制事务可读写还是只可读。默认可读写@Transactional(timeout=30) //控制事务的超时时间，单位秒。默认跟数据库的事务控制系统相同，又说是30秒@Transactional(rollbackFor=RuntimeException.class) //控制事务遇到哪些异常才会回滚。默认是RuntimeException@Transactional(rollbackForClassName=RuntimeException) //同上@Transactional(noRollbackFor=NullPointerException.class) //控制事务遇到哪些异常不会回滚。默认遇到非RuntimeException不会回滚@Transactional(noRollbackForClassName=NullPointerException)//同上]]></content>
      <categories>
        <category>事务</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java元注解]]></title>
    <url>%2F2018%2F03%2FJava%E5%85%83%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[@Retention: 定义注解的保留策略@Retention(RetentionPolicy.SOURCE) // 注解仅存在于源码中，在 class 字节码文件中不包含@Retention(RetentionPolicy.CLASS) // 默认的保留策略，注解会在 class 字节码文件中存在，但运行时无法获得，@Retention(RetentionPolicy.RUNTIME) // 注解会在 class 字节码文件中存在，在运行时可以通过反射获取到首 先要明确生命周期长度 SOURCE &lt; CLASS &lt; RUNTIME ，所以前者能作用的地方后者一定也能作用。一般如果需要在运行时去动态获取注解信息，那只能用 RUNTIME 注解；如果要在编译时进行一些预处理操作，比如生成一些辅助代码（如 ButterKnife），就用 CLASS 注解；如果只是做一些检查性的操作，比如 @Override 和 @SuppressWarnings，则可选用 SOURCE 注解。 @Target：定义注解的作用目标源码为：@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Target {ElementType[] value();}@Target(ElementType.TYPE) // 接口、类、枚举、注解@Target(ElementType.FIELD) // 字段、枚举的常量@Target(ElementType.METHOD) // 方法@Target(ElementType.PARAMETER) // 方法参数@Target(ElementType.CONSTRUCTOR) // 构造函数@Target(ElementType.LOCAL_VARIABLE)// 局部变量@Target(ElementType.ANNOTATION_TYPE)// 注解@Target(ElementType.PACKAGE) /// 包 @Document：说明该注解将被包含在 javadoc 中@Inherited：说明子类可以继承父类中的该注解作者：JavaIsRubbish链接：http://pipe.b3log.org/blogs/JavaIsRubbish/articles/2018/03/16/1521171085983]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系列：垃圾收集器与内存分配策略]]></title>
    <url>%2F2018%2F03%2FJVM%E7%B3%BB%E5%88%97%EF%BC%9A%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[判断对象是否存活引用计数算法 实现简单，判定效率高 Java虚拟机没有使用，主要原因是此算法很难解决对象之间相互循环引用的问题 可达性分析算法 通过一系列的称为”GC Roots”的对象作为起始点，从这些节点向下搜索，搜索走过的路径称为引用链；当一个对象跟”GC Roots”没有任何引用链的关系，则证明此对象不可达。 在进行可达性分析后发现此对象没有与”GC Roots”相连的引用链，则会被第一次标记并且进行一次筛选，条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者说finalize()方法已被虚拟机调用过，则没有必要执行如果该对象判定有必要执行，则会放到F-Quene队列，并在稍后由一个虚拟机自动建立、低优先级的Finalize线程去执行（会触发，但并不一定会等这个方法执行结束，以避免该方法执行缓慢或者死循环）finalize方法是对象逃脱死亡的最后一次机会，GC会对F-Quene中的对象进行第二次小规模标记，只有重新与引用链上的任何一个对象建立关联， 那么第二次标记，将会被移出”即将回收”集合，否则，就进行回收。一个对象的finalize方法只会被虚拟机调用一次 在Java中，可作为”GC Roots”的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（一般说的是Native方法）引用的对象 引用又分为：强、软、弱、虚 回收方法区 永久代的垃圾收集主要是：废弃常量和无用的类 无用的类： 该类所有的实例都已经被回收 加载该类的ClassLoader已经被回收 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法满足以上3个条件，可以进行回收，而不是必然回收。 垃圾收集算法标记-清除—-&gt;老年代 效率不高，产生大量不连续内存碎片 复制—-&gt;新生代 实现简单，运行高效，但是将内存缩小了一半 将可用内存划分为（A，B）2块，每次只用A块，将A块存活对象复制到B块，然后将A块一次清理，每次都对半区进行回收 标记-整理—-&gt;老年代垃圾收集器Serial收集器单线程：进行垃圾收集时，必须暂停其他所有的工作线程，直到收集结束。在Client模式下，简单高效，没有线程交互的开销 ParNew收集器Serial收集器的多线程版本 Parallel Scavenge收集器使用复制算法，达到可控制的吞吐量 Serial Old收集器使用标记-整理算法 Parallel Old收集器使用标记整理算法 CMS收集器 以获取最短回收停顿时间为目标的收集器 步骤： 初始标记（stop the world） 并发标记（stop the world） 重新标记 并发清除缺点： 对CPU资源非常敏感 无法处理浮动垃圾，可能导致Full GC产生 标记-清除算法，会导致大量内存碎片，从而引起Full GC G1收集器 面向服务器应用的垃圾收集器 特点： 并行与并发 分代收集 空间整合（标记-整理算法） 可预测的停顿：明确指定在一个长度为M毫秒的时间片段里，消耗在垃圾收集上的时间不得超过N毫秒 将Java堆划分为多个大小相等的独立区域Region，G1跟踪各个Region里面的价值大小（回收获得的空间大小以及需要花费的时间的经验值），在后台维护一个优先列表，每一次根据允许的收集时间（可预测的停顿）优先回收价值最大的Region（每个Region都有Remembered Set 避免全堆扫描） 步骤： 初始标记 并发标记 最终标记 筛选回收 内存分配与回收策略 对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配少数情况下分配到老年代 对象优先在Eden区分配当Eden区没有足够的空间分配时，虚拟机将会发起一次Minor GC（新生代GC，速度较快） 大对象直接进入老年代长期存活对象将进入老年代年龄计数器：在Survivor没熬过一次Minor GC，年龄加1，当达到阈值，则进入老年代；阈值设置（-XX:MaxTenuringThreshold） 动态对象年龄判定如果Survivor 中相同年龄所有对象的大小总和大于Survivor空间的一半，年龄大于或者等于该年龄的对象都直接进入老年代 空间分配担保在Minor GC，虚拟机会检查老年代中最大可用的连续空间是否大于新生代所有对象总空间。如果成立，则Minor GC安全；不成立，查看HandlePromotionFailure是否允许担保失败；如果允许，则检查老年代可用连续空间是否大于之前每次晋升老年代的平均值大小，如果大于，则冒险进行Minor GC，如果小于或者设置不允许担保失败的话，则进行Full GC。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系列：Java内存区域与内存溢出异常]]></title>
    <url>%2F2018%2F03%2FJVM%E7%B3%BB%E5%88%97%EF%BC%9AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[运行时数据区域 程序计数器 作用记录当前线程所执行到的字节码的行号。字节码解释器工作的时候就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。 意义JVM的多线程是通过线程轮流切换并分配处理器来实现的，对于我们来说的并行事实上一个处理器也只会执行一条线程中的指令。所以，为了保证各线程指令的安全顺利执行，每条线程都有独立的私有的程序计数器。 存储内容当线程中执行的是一个Java方法时，程序计数器中记录的是正在执行的线程的虚拟机字节码指令的地址。当线程中执行的是一个本地方法时，程序计数器中的值为空。 可能出现的异常此内存区域是唯一一个在JVM上不会发生内存溢出异常（OutOfMemoryError）的区域。 Java虚拟机栈 Java内存区常被分为堆内存（Heap）和栈内存（Stack），其中栈内存其实指的就是虚拟机栈，或者说是虚拟机栈中的局部变量表部分 作用描述Java方法执行的内存模型。每个方法在执行的同时都会开辟一段内存区域用于存放方法运行时所需的数据，成为栈帧，一个栈帧包含如：局部变量表、操作数栈、动态链接、方法出口等信息。 意义JVM是基于栈的，所以每个方法从调用到执行结束，就对应着一个栈帧在虚拟机栈中入栈和出栈的整个过程。 存储内容局部变量表（编译期可知的各种基本数据类型、引用类型和指向一条字节码指令的returnAddress类型）、操作数栈、动态链接、方法出口等信息。值得注意的是：局部变量表所需的内存空间在编译期间完成分配。在方法运行的阶段是不会改变局部变量表的大小的 可能出现的异常如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。如果在动态扩展内存的时候无法申请到足够的内存，就会抛出OutOfMemoryError异常。本地方法栈与虚拟机栈类似，区别在于虚拟机栈为虚拟机执行java方法（字节码）服务，而本地方法则为虚拟机所使用的Native方法服务Java堆 Java堆是垃圾收集器管理的主要区域（GC堆），可细分为：新生代，老年代，按空间可细分为：Eden空间，From Survivor空间，To Survivor空间 作用所有线程共享一块内存区域，在虚拟机开启的时候创建 意义存储对象实例，更好地分配内存。垃圾回收（GC）。堆是垃圾收集器管理的主要区域。更好地回收内存 存储内容存放对象实例，几乎所有的对象实例都在这里进行分配。堆可以处于物理上不连续的内存空间，只要逻辑上是连续的就可以。值得注意的是：在JIT编译器等技术的发展下，所有对象都在堆上进行分配已变得不那么绝对。有些对象实例也可以分配在栈中 可能出现的异常实现堆可以是固定大小的，也可以通过设置配置文件设置该为可扩展的。如果堆上没有内存进行分配，并无法进行扩展时，将会抛出OutOfMemoryError异常方法区 作用用于存储运行时常量池、已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 意义对运行时常量池、常量、静态变量等数据做出了规定。 存储内容运行时常量池（具有动态性）、已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 可能出现的异常当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。运行时常量池 运行时常量池对于Class文件常量池的另一个特征是具备动态性，在运行期间也可能将新的常量放入池中，例如String类的intern() 直接内存 JDK1.4中新加入NIO类，引入一种基于通道与缓冲的IO方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffeer对象作为这块内存的引用进行操作。（在一些场景中显著提高性能，因为避免了Java堆和Native堆中来回复制数据） 如果服务器管理员在配置虚拟机参数时，忽略了直接内存，就有可能导致动态扩展时，出现OutOfMemoryError异常 HotSpot虚拟机对象对象创建 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程，类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。 内存分配的2种方式： 选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定 指针碰撞Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离 空闲列表Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值 对象的内存布局 在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding） HotSpot虚拟机的对象头包括两部分信息： Mark Word第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit。 类型指针对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身对象的访问定位 建立对象是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的具体对象 目前主流的访问方式有使用句柄和直接指针两种： 句柄访问 直接指针访问对比优势： 使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。 使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。Sun HotSpot虚拟机是使用第二种方式进行对象虚拟机访问的。OutOfMemoryError 异常 除了程序计数器，其他运行时区域都有可能抛出OutOfMemoryError异常 Java堆溢出 内存泄露查看泄露对象到GC Roots的引用链，定位泄露代码位置。 内存溢出如果不存在泄露，即内存中的对象确实都还必须活着，检查JVM堆参数（-Xmx与-Xms），调大参数，检查代码是否存在某些对象生命周期过长，持有状态过长的情况，减少程序运行期的内存消耗。虚拟机栈、本地方法栈溢出HotSpot不区分虚拟机栈和本地方法栈，栈容量只能由-Xss参数设定。 StackOverFlow：线程申请的栈深度超过允许的最大深度 OutOfMemoryError： 虚拟机扩展时无法申请到足够的内存空间StackOverFlow的情况：递归调用方法，定义大量的本地变量，增大此方法帧中本地变量表的长度。OutOfMemoryError：多线程下的内存溢出，与栈空间是否足够大并不存在任何联系。为每个线程的栈分配的内存越大（参数-Xss），那么可以建立的线程数量就越少，建立线程时就越容易把剩下的内存耗尽，越容易内存溢出。在这种情况下，如果不能减少线程数目或者更换64位虚拟机时，减少最大堆和减少栈容量能够换区更多的线程。方法区和运行时常量池溢出 运行时常量池String.intern()是一个Native方法，它的作用是：如果运行时常量池中已经包含一个等于此String对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此String内容相同的字符串，并返回常量池中创建的字符串的引用。JDK7的intern()方法的实现有所不同，当常量池中没有该字符串时，不再是在常量池中创建与此String内容相同的字符串，而改为在常量池中记录堆中首次出现的该字符串的引用，并返回该引用 方法区方法区用于存放Class的相关信息，如果运行时产生大量的类去填满方法区，就可能发生方法区的内存溢出。 例如主流框架Spring、Hibernate对大量的类进行增强时，利用CGLib字节码生成动态类；大量JSP或动态JSP(JSP第一次运行时需要编译为Java类）。本机直接内存溢出Java虚拟机可以通过参数-XX:MaxDirectMemorySize设定本机直接内存可用大小，如果不指定，则默认与java堆内存大小相同。JDK中可以通过反射获取Unsafe类(Unsafe的getUnsafe()方法只有启动类加载器Bootstrap才能返回实例)直接操作本机直接内存。通过使用-XX:MaxDirectMemorySize=10M，限制最大可使用的本机直接内存大小为10MB。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cache声名式缓存注解]]></title>
    <url>%2F2018%2F03%2FCache%E5%A3%B0%E5%90%8D%E5%BC%8F%E7%BC%93%E5%AD%98%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[@Cacheable在方法执行前Spring先查看缓存中是否有数据，如果有，则直接返回缓存数据；若没有，调用方法并将方法返回值放入缓存 value：缓存的名称，在 spring 配置文件中定义，必须指定至少一个 例如：@Cacheable(value=”mycache”) 或者@Cacheable(value={”cache1”,”cache2”} key：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 例如：@Cacheable(value=”testcache”,key=”#userName”) condition：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 例如：@Cacheable(value=”testcache”,condition=”#userName.length()&gt;2”) @CachePut无论怎么样，都会把方法的返回值放进缓存中，属性与@Cacheable一致 @CacheEvict将一条或者多条数据从缓存中删除 value：缓存的名称，在 spring 配置文件中定义，必须指定至少一个 例如：@CachEvict(value=”mycache”) 或者@CachEvict(value={”cache1”,”cache2”} key：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 例如：@CachEvict(value=”testcache”,key=”#userName”) condition：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才清空缓存 例如：@CachEvict(value=”testcache”, condition=”#userName.length()&gt;2”) allEntrie：是否清空所有缓存内容，缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存 例如：@CachEvict(value=”testcache”,allEntries=true) beforeInvocation：是否在方法执行前就清空，缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存 例如：@CachEvict(value=”testcache”，beforeInvocation=true) @Caching可以通过@Caching注解将多个注解策略组合到一个方法上@Caching注解可以让我们在一个方法或者类上同时指定多个Spring Cache相关的注解。其拥有三个属性：cacheable、put和evict，分别用于指定@Cacheable、@CachePut和@CacheEvict。12345@Caching(cacheable = @Cacheable(&quot;users&quot;), evict = &#123; @CacheEvict(&quot;cache2&quot;), @CacheEvict(value = &quot;cache3&quot;, allEntries = true) &#125;) public User find(Integer id) &#123; return null; &#125;]]></content>
      <categories>
        <category>cache</category>
      </categories>
      <tags>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC内存回收]]></title>
    <url>%2F2018%2F02%2FGC%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[Java在内存中的状态 可达状态：在一个对象创建后，有一个以上的引用变量引用它 可恢复状态：如果程序中某个对象不再有任何的引用变量引用它，它将先进入可恢复状态。在这个状态下，系统的垃圾回收机制准备回收该对象的所占用的内存，在回收之前，系统会调用finalize()方法进行资源清理，如果资源整理后重新让一个以上引用变量引用该对象，则这个对象会再次变为可达状态；否则就会进入不可达状态 不可达状态：当对象的所有关联都被切断，且系统调用finalize()方法进行资源清理后依旧没有使该对象变为可达状态，则这个对象将永久性失去引用并且变成不可达状态，系统才会真正的去回收该对象所占用的资源 Java对对象的4种引用 强引用 ：创建一个对象并把这个对象直接赋给一个变量，eg ：Person person = new Person(“sunny”); 不管系统资源有么的紧张，强引用的对象都绝对不会被回收，即使以后不会再用到 软引用 ：通过SoftReference类实现，eg : SoftReference p = new SoftReference(new Person(“Rain”));,内存非常紧张的时候会被回收，其他时候不会被回收，所以在使用之前要判断是否为null从而判断他是否已经被回收了 弱引用 ：通过WeakReference类实现，eg : WeakReference p = new WeakReference(new Person(“Rain”));不管内存是否足够，系统垃圾回收时必定会回收 虚引用 ：不能单独使用，主要是用于追踪对象被垃圾回收的状态。通过PhantomReference类和引用队列ReferenceQueue类联合使用实现 JAVA辣鸡回收机制 内存回收 / 碎片整理 辣鸡回收算法 串行回收（单个CPU）/ 并行回收（多个CPU才有用） 1并行回收的执行效率很高，但复杂度增加，另外也有一些副作用，如内存碎片增加 并发执行和应用程序停止 1234***应用程序停止，这种方式会导致应用程序的暂停***并发执行虽然不会导致应用程序暂停，但是需要解决和应用程序的执行冲突（应用程序可能在回收阶段修改对象等等），所以并发执行这种方式的系统开销比应用程序停止更高，而且执行起来需要更多的堆内栈 压缩/不压缩/复制 支持压缩的垃圾回收器（标记-压缩 = 标记清除+压缩）会把所有的可达对象搬迁到一端，然后直接清理掉端边界以外的内存，减少了内存碎片。 不压缩的垃圾回收器（标记-清除）要遍历两次，第一次先从跟开始访问所有可达对象，并将他们标记为可达状态，第二次便利整个内存区域，对未标记可达状态的对象进行回收处理。这种回收方式不压缩，不需要额外内存，但要两次遍历，会产生碎片 复制式的垃圾回收器：将堆内存分成两个相同空间，从根（类似于前面的有向图起始顶点）开始访问每一个关联的可达对象，将空间A的全部可达对象复制到空间B，然后一次性回收空间A。对于该算法而言，因为只需访问所有的可达对象，将所有的可达对象复制走之后就直接回收整个空间，完全不用理会不可达对象，所以遍历空间的成本较小，但需要巨大的复制成本和较多的内存。 堆内存的分代回收分代回收的依据 对象生存时间的长短：大部分对象在Young期间就被回收 不同代采取不同的垃圾回收策略：新（生存时间短）老（生存时间长）对象之间很少存在引用 堆内存的分代 Young代 回收机制 ：因为对象数量少，所以采用复制回收 回收频率：Young代对象大部分很快进入不可达状态，回收频率高且回收速度快 对象来源：绝大多数对象先分配到Eden区，一些大的对象会直接被分配到Old代中 Old代 回收机制：采用标记压缩算法回收 对象来源：对象大直接进入老年代 / Young代中生存时间长的可达对象 回收频率 ：因为很少对象会死掉，所以执行频率不高，而且需要较长时间来完成 Permanent代 用途 ：用来装载Class，方法等信息，默认为64M，不会被回收 对象来源 ：eg：对于像Hibernate，Spring这类喜欢AOP动态生成类的框架，往往会生成大量的动态代理类，因此需要更多的Permanent代内存。所以我们经常在调试Hibernate，Spring的时候经常遇到java.lang.OutOfMemoryError:PermGen space的错误，这就是Permanent代内存耗尽所导致的错误。 回收频率 ：不会被回收 常见的垃圾回收器串行回收器（只使用一个CPU） Young代采用串行复制算法；Old代使用串行标记压缩算法（三个阶段：标记mark—清除sweep—压缩compact），回收期间程序会产生暂停 并行回收器 对Young代采用的算法和串行回收器一样，只是增加了多CPU并行处理； 对Old代的处理和串行回收器完全一样，依旧是单线程 并行压缩回收器 对Young代处理采用与并行回收器完全一样的算法；只是对Old代采用了不同的算法，其实就是划分不同的区域，然后进行标记压缩算法：① 将Old代划分成几个固定区域；② mark阶段（多线程并行），标记可达对象；③ summary阶段（串行执行），从最左边开始检验知道找到某个达到数值（可达对象密度小）的区域时，此区域及其右边区域进行压缩回收，其左端为密集区域④ compact阶段（多线程并行），识别出需要装填的区域，多线程并行的把数据复制到这些区域中。经此过程后，Old代一端密集存在大量活动对象，另一端则存在大块空间 并发标识—清理回收（CMS） 对Young代处理采用与并行回收器完全一样的算法；只是对Old代采用了不同的算法，但归根待地还是标记清理算法：① 初始标识（程序暂停）：标记被直接引用的对象(一级对象)；② 并发标识（程序运行）：通过一级对象寻找其他可达对象；③ 再标记（程序暂停）：多线程并行的重新标记之前可能因为并发而漏掉的对象（简单的说就是防遗漏）④ 并发清理（程序运行） 内存管理小技巧 尽量使用直接量，eg：String javaStr = “内存回收” 使用StringBuilder和StringBuffer进行字符串连接等操作 尽早释放无用对象 尽量少使用静态变量 缓存常用的对象:可以使用开源的开源缓存实现，eg：OSCache，Ehcache 尽量不使用finalize()方法 在必要的时候可以考虑使用软引用SoftReference]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>GC</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis安装以及配置]]></title>
    <url>%2F2018%2F01%2FRedis%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[下载http://redis.io/download 解压tar zxvf redis-2.8.17.tar.gz 编译并安装1234cd redis-2.8.17make cd srcmake install PREFIX=/usr/local/redis make编译如果失败，因为没有安装gcc服务12yum install gcc---安装gccrpm -qa |grep gcc---查看安装是否成功 将配置文件移动到redis安装目录下进入redis目录，创建etc文件夹mv redis.conf /usr/local/redis/etc 启动服务、配置123/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf第一个是启动redis服务器第二个是启动服务器所需的配置 设置后台运行vim /usr/local/redis/etc/redis.conf将daemonize的值改为yes 设置开机自启vim /etc/rc.local加入/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis-conf 客户端链接/usr/local/redis/bin/redis-cli 停止服务/usr/local/redis/bin/redis-cli shutdown或者pkill redis-server]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx小知识]]></title>
    <url>%2F2017%2F12%2FNginx%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Nginx 禁止IP访问 为了避免别人把未备案的域名解析到自己的服务器IP而导致服务器被断网 在配置文件nginx.conf中新建一个server 12345server &#123; listen 80 default; server_name _; return 500; &#125; 原先的server中，server_name可以设置多个域名 Nginx 代理，http识别不到js，但是https可以识别到？ 由于在https的server中没有对js/css进行操作，但是在http的server中，发现了下面这一段： 1234location ~ .*\.(js|css)?$ &#123; expires 15d; &#125; 将需要识别的文件所在的端口的地址放进去 12345location ~ .*\.(js|css)?$ &#123; # expires 15d; proxy_pass http://127.0.0.1:8088; &#125; 或者直接将这一段删除即可 nginx 出现413 Request Entity Too Large问题的解决方法 nginx默认上传文件的大小是1M，可nginx的设置中修改 打开nginx配置文件 nginx.conf 在http{}段中加入 client_max_body_size 20m; 20m为允许最大上传的大小 保存后重启nginx]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛文件操作]]></title>
    <url>%2F2017%2F12%2F%E4%B8%83%E7%89%9B%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[七牛资源管理]]></content>
      <categories>
        <category>七牛</category>
      </categories>
      <tags>
        <tag>七牛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis小知识]]></title>
    <url>%2F2017%2F12%2FRedis%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[更改Redis报序列化错误，ClassNotFind 问题描述： 更改环境上线，由于依赖的A项目更改为旧的redis，因此B项目也改为旧的redis，发送短信时，系统报错，报错信息是：序列化错误，找不到对应的模型 检查发现，涉及到对应的逻辑代码已经几个月没有更新过 重启Tomcat，清除Tomcat缓存，无效 还原redis配置，短信发送成功 原因： 由于更改为旧的redis配置，登录redis客户端，发现对应的消息队列中还有一些没有被消费掉的消息，这些消息是之前旧的模型序列化进来，现在第一条序列化出去就找不到对应的模型，因此报错 更改旧版redis配置 &rArr; 旧消息队列没有被消费 &rArr; 重新连接总是读取第一条进行序列化 &rArr; 如果代码更改或者模型变更 &rArr; 导致序列化错误，找不到对应的模型 &rArr; redis需要设置过期时间进行自动清除 解决：设置缓存过期时间一天，且redis错误提示信息应当更加友好！redisTemplate.expire(“testKey”,1l,TimeUnit.DAYS);]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx安装以及配置]]></title>
    <url>%2F2017%2F11%2FNginx%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装编译工具及库文件1yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装 PCRE下载 PCRE 安装包1[root@bogon src]# wget http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz 解压安装包1[root@bogon src]# tar zxvf pcre-8.35.tar.gz 进入安装包目录1[root@bogon src]# cd pcre-8.35 编译安装12[root@bogon pcre-8.35]# ./configure[root@bogon pcre-8.35]# make &amp;&amp; make install 查看pcre版本1[root@bogon pcre-8.35]# pcre-config --version 安装 Nginx下载Nginx1[root@bogon src]# wget http://nginx.org/download/nginx-1.6.2.tar.gz 解压安装包1[root@bogon src]# tar zxvf nginx-1.6.2.tar.gz 进入安装目录1[root@bogon src]# cd nginx-1.6.2 编译安装123[root@bogon nginx-1.6.2]# ./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.35[root@bogon nginx-1.6.2]# make[root@bogon nginx-1.6.2]# make install 查看Nginx版本1[root@bogon nginx-1.6.2]# /usr/local/webserver/nginx/sbin/nginx -v Nginx 配置创建 Nginx 运行使用的用户 www12[root@bogon conf]# /usr/sbin/groupadd www [root@bogon conf]# /usr/sbin/useradd -g www www 配置nginx.conf 将/usr/local/webserver/nginx/conf/nginx.conf替换为以下内容配置nginx.conf ，将/usr/local/webserver/nginx/conf/nginx.conf替换为以下内容: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105user www www;worker_processes 2; #设置值和CPU核心数一致error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别pid /usr/local/webserver/nginx/nginx.pid;#Specifies the value for maximum file descriptors that can be opened by this process.worker_rlimit_nofile 65535;events&#123; use epoll; worker_connections 65535;&#125;http&#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;; #charset gb2312; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 8m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #下面是server虚拟主机的配置 server &#123; listen 80;#监听端口 server_name localhost;#域名 index index.html index.htm index.php; root /usr/local/webserver/nginx/html;#站点目录 location /aaa &#123; proxy_pass http://127.0.0.1:8080/aaa; &#125; location /abcd &#123; proxy_pass http://127.0.0.1:8081/abcd; &#125; location /yiwu &#123; proxy_pass http://127.0.0.1:8081/yiwu; &#125; location ~ .*\.(php|php5)?$ &#123; #fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|ico)$ &#123; expires 30d; # access_log off; &#125; location ~ .*\.(js|css)?$ &#123; expires 15d; # access_log off; &#125; access_log off; &#125; server &#123; listen 443 ssl; server_name localhost; ssl on; root html; index index.html index.htm; ssl_certificate cert/214335641040602.pem; ssl_certificate_key cert/214335641040602.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125; location /aaa &#123; proxy_pass http://127.0.0.1:8080/aaa; &#125; location /abcd &#123; proxy_pass http://127.0.0.1:8081/abcd; &#125; &#125;&#125; 在conf目录新建cert文件夹，将证书文件（阿里云免费证书：pem，key）放置cert，并且加入一个配置server：（这个server是https的配置，原先的server是对于http的配置） 1234567891011121314151617181920212223server &#123; listen 443 ssl; server_name localhost; ssl on; root html; index index.html index.htm; ssl_certificate cert/214335641040602.pem; ssl_certificate_key cert/214335641040602.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125; location /bjjc &#123; proxy_pass http://127.0.0.1:8080/bjjc; &#125; location /yiwu &#123; proxy_pass http://127.0.0.1:8081/yiwu; &#125; &#125; 检查配置文件ngnix.conf的正确性命令1[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx -t 启动 Nginx1[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx 启动后可以根据ip访问成功！ Nginx其他命令123/usr/local/webserver/nginx/sbin/nginx -s reload # 重新载入配置文件/usr/local/webserver/nginx/sbin/nginx -s reopen # 重启 Nginx/usr/local/webserver/nginx/sbin/nginx -s stop # 停止 Nginx 安装后启动报错，原因是tomcat80端口冲突]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux ActiveMQ安装启动]]></title>
    <url>%2F2017%2F11%2FLinux-ActiveMQ%E5%AE%89%E8%A3%85%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[下载 ActiveMQ官网：http://activemq.apache.org ， 下载apache-activemq-5.14.4-bin.tar.gz 安装jdk，配置环境变量 安装 上传apache-activemq-5.12.1-bin.tar.gz到linux服务器，并解压 部分目录说明：1234567bin目录：(windows下面的bat和unix/linux下面的sh) 启动ActiveMQ的启动服务就在这里conf目录： activeMQ配置目录，包含最基本的activeMQ配置文件data目录：activeMQ的日志文件目录webapps目录：系统管理员web控制界面文件 启动 进入bin目录，执行命令：1./activemq start 访问 启动成功就可以以 http://ip地址:8161 方式访问WEB管理界面，默认用户名和密码admin/admin ActiveMQ启动后，默认会启用8161和61616两个端口 8161端口为ActiveMQ的web管理控制端口， 61616为ActiveMQ的通讯端口 配置 web管理界面默认的用户名为admin/admin，其配置文件位于./conf/jetty-realm.properties 通信端口的定义在ActiveMQ的主配置文件，./conf/activemq.xml 12345678 &lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;!-- &lt;transportConnector name=&quot;amqp&quot; uri=&quot;amqp://0.0.0.0:5672?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;--&gt;&lt;!-- &lt;transportConnector name=&quot;stomp&quot; uri=&quot;stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;--&gt; &lt;transportConnector name=&quot;mqtt&quot; uri=&quot;mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;!-- &lt;transportConnector name=&quot;ws&quot; uri=&quot;ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;--&gt; &lt;/transportConnectors&gt; web管理端口的修改，activemq使用了jetty服务器来进行管理， 我们可以在conf/jetty.xml文件中对其配置，web管理端口默认为8161，定义在jetty.xml文件 12345&lt;bean id=&quot;jettyPort&quot; class=&quot;org.apache.activemq.web.WebConsolePort&quot; init-method=&quot;start&quot;&gt; &lt;!-- the default port number for the web console --&gt; &lt;property name=&quot;host&quot; value=&quot;0.0.0.0&quot;/&gt; &lt;property name=&quot;port&quot; value=&quot;8161&quot;/&gt;&lt;/bean&gt; 自動清空沒在使用的 topic 12345------broker 元素加上 schedulePeriodForDestinationPurge 的屬性 (10秒):------&lt;broker xmlns=&quot;http://activemq.apache.org/schema/core&quot; brokerName=&quot;localhost&quot; dataDirectory=&quot;$&#123;activemq.data&#125;&quot; schedulePeriodForDestinationPurge=&quot;10000&quot;&gt;------policyEntry 元素加上 gcInactiveDestinations 跟 inactiveTimoutBeforeGC 的屬性 (分別是開啟, 跟 20秒):------&lt;policyEntry topic=&quot;&gt;&quot; gcInactiveDestinations=&quot;true&quot; inactiveTimoutBeforeGC=&quot;20000&quot; &gt; 关闭服务 进入bin目录，执行命令：1./activemq stop]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7(firewall)开放端口和关闭防火墙]]></title>
    <url>%2F2017%2F11%2FCentOS7-firewall-%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3%E5%92%8C%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[开放端口永久的开放需要的端口12sudo firewall-cmd --zone=public --add-port=8080/tcp --permanentsudo firewall-cmd --reload 之后检查新的防火墙规则1firewall-cmd --list-all 关闭防火墙12345678910111213//临时关闭防火墙,重启后会重新自动打开systemctl restart firewalld//检查防火墙状态firewall-cmd --statefirewall-cmd --list-all//Disable firewallsystemctl disable firewalldsystemctl stop firewalldsystemctl status firewalld//Enable firewallsystemctl enable firewalldsystemctl start firewalldsystemctl status firewallad]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux小知识]]></title>
    <url>%2F2017%2F10%2FLinux%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[linux 执行jar nohup java -jar dlz-0.0.1-SNAPSHOT.jar –server.port=8899 &gt;&gt; background.log 2&gt;&amp;1 &amp; linux命令 查看是否存在相关进程(Back)： ps ax | grep Back 添加用户1234567首先用adduser命令添加一个普通用户，命令如下：#adduser tommy //添加一个名为tommy的用户#passwd tommy //修改密码Changing password for user tommy.New UNIX password: //在这里输入新密码Retype new UNIX password: //再次输入新密码passwd: all authentication tokens updated successfully. 赋予root权限 方法一 123456修改 /etc/sudoers 文件，找到下面一行，把前面的注释（#）去掉## Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL然后修改用户，使其属于root组（wheel），命令如下：#usermod -g root tommy修改完毕，现在可以用tommy帐号登录，然后用命令 su - ，即可获得root权限进行操作。 方法二 12345修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示：## Allow root to run any commands anywhereroot ALL=(ALL) ALLtommy ALL=(ALL) ALL修改完毕，现在可以用tommy帐号登录，然后用命令 su - ，即可获得root权限进行操作。 通常查找出错误日志 cat error.log | grep ‘错误error’ , 这时候我们还有个需求就是输出当前这个日志的前后几行：123cat error.log | grep -C 5 &apos;错误error&apos; 显示error.log文件里匹配&quot;错误error&quot;字符串那行以及上下5行cat error.log | grep -B 5 &apos;错误error&apos; 显示&quot;错误error&quot;及前5行cat error.log | grep -A 5 &apos;错误error&apos; 显示&quot;错误error&quot;及后5行 批量删除某字符串开头的文件12删除“tomcat-开头的文件”find . -name &quot;tomcat-*&quot; | xargs rm -rf 查看文件最后N行的命令12tail -n 20 filename说明：显示filename最后20行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>小知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven小知识]]></title>
    <url>%2F2017%2F10%2FMaven%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Maven 的classifier的作用 maven中要引入json包 12345&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; 当执行mvn install 命令时，却抛出一个错误，说找不到net.sf.json-lib:json-lib:2.2.2这个包，到仓库中看一下http://repo2.maven.org/maven2/net/sf/json-lib/json-lib/2.2.2/ jar的名称中多了一个跟JDK相关的名称，例如jdk15，按照上面的配置，明显是找不到这个jar的，于是classifier就有它的用武之地了，它表示在相同版本下针对不同的环境或者jdk使用的jar,如果配置了这个元素，则会将这个元素名在加在最后来查找相应的jar，例如： 123456&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; 这样配置即可找到json-lib-2.2.2-jdk15.jar maven 快照 更新策略 为什么会有快照？ 没有快照之前： A项目依赖于项目B，B每次改动就赋予一个新版本号，然后告诉A我改版本好了啊，每次改动都得告诉，有时忘了就麻烦了。 可以看出没有快照会带来“浪费版本号”、沟通成大加大的问题。 有了快照之后： A项目依赖于项目B，B每次改动都会打上时间戳，A编译时会检查B的时间戳，如果晚于本地仓库B的时间戳，那么就会进行更新，否则不予更新。 可以看出快照省去了沟通成本、版本号成本。 快照更新策略 注意，快照并不是每次install就会更新，这取决于更新策略；快照更新策略，有每日更新、永远检查更新、从不检查更新和自定义时间间隔更新，默认是每日更新也就是说一日更新一次，如果想总是更新，那么可以在settings.xml中配置。比如:12345678910111213141516&lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; updatePolicy更新snapshot包的频率，属性有四个值always(实时更新) daily（每天更新） interval:xxx（隔xxx分钟更新一次） never（从不更新） 默认为daily 也可以通过命令强制更新，mvn clean install-U参考博文 maven打包本地jar包，在plugin中设置includeSystemScope为true1234567&lt;dependency&gt; &lt;groupId&gt;llw-base-rpc&lt;/groupId&gt; &lt;artifactId&gt;llw-base-rpc&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/lib/llw-base-rpc.jar&lt;/systemPath&gt;&lt;/dependency&gt; 1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习之配置文件的加载顺序]]></title>
    <url>%2F2017%2F10%2FSpringBoot%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[spring boot通过jar包启动时，配置文件的加载顺序 @TestPropertySource 注解 命令行参数 Java系统属性（System.getProperties()） 操作系统环境变量 只有在random.*里包含的属性会产生一个RandomValuePropertySource 在打包的jar外的应用程序配置文件（通过 java -jar demo.jar –spring.config.location=/path/test_evn.properties ） 在打包的jar内的应用程序配置文件（application.properties，包含YAML和profile变量） 在@Configuration类上的@PropertySource注解 默认属性（使用SpringApplication.setDefaultProperties指定）所以，针对6和7的情况，我们一般在应用程序外部放置配置yml文件，防止每次发布时被篡改！参考]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git命令]]></title>
    <url>%2F2017%2F10%2FGit%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586git init # 初始化本地git仓库（创建新仓库）git config --global user.name &quot;xxx&quot; # 配置用户名git config --global user.email &quot;xxx@xxx.com&quot; # 配置邮件git config --global color.ui true # git status等命令自动着色git config --global color.status autogit config --global color.diff autogit config --global color.branch autogit config --global color.interactive autogit config --global --unset http.proxy # remove proxy configuration on gitgit clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库git status # 查看当前版本状态（是否修改）git add xyz # 添加xyz文件至indexgit add . # 增加当前子目录下所有更改过的文件至indexgit commit -m &apos;xxx&apos; # 提交git commit --amend -m &apos;xxx&apos; # 合并上一次提交（用于反复修改）git commit -am &apos;xxx&apos; # 将add和commit合为一步git rm xxx # 删除index中的文件git rm -r * # 递归删除git log # 显示提交日志git log -1 # 显示1行日志 -n为n行git log -5git log --stat # 显示提交日志及相关变动文件git log -p -mgit show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交的详细内容git show dfb02 # 可只用commitid的前几位git show HEAD # 显示HEAD提交日志git show HEAD^ # 显示HEAD的父（上一个版本）的提交日志 ^^为上两个版本 ^5为上5个版本git tag # 显示已存在的taggit tag -a v2.0 -m &apos;xxx&apos; # 增加v2.0的taggit show v2.0 # 显示v2.0的日志及详细内容git log v2.0 # 显示v2.0的日志git diff # 显示所有未添加至index的变更git diff --cached # 显示所有已添加index但还未commit的变更git diff HEAD^ # 比较与上一个版本的差异git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异git diff origin/master..master # 比较远程分支master上有本地分支master上没有的git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程定义（用于push/pull/fetch）git branch # 显示本地分支git branch --contains 50089 # 显示包含提交50089的分支git branch -a # 显示所有分支git branch -r # 显示所有原创分支git branch --merged # 显示所有已合并到当前分支的分支git branch --no-merged # 显示所有未合并到当前分支的分支git branch -m master master_copy # 本地分支改名git checkout -b master_copy # 从当前分支创建新分支master_copy并检出git checkout -b master master_copy # 上面的完整版git checkout features/performance # 检出已存在的features/performance分支git checkout --track hotfixes/BJVEP933 # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支git checkout v2.0 # 检出版本v2.0git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出git checkout -- README # 检出head版本的README文件（可用于修改错误回退）git merge origin/master # 合并远程master分支至当前分支git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改git push origin master # 将当前分支push到远程master分支git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支git push --tags # 把所有tag推送到远程仓库git fetch # 获取所有远程分支（不更新本地分支，另需merge）git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支git pull origin master # 获取远程分支master并merge到当前分支git mv README README2 # 重命名文件README为README2git reset --hard HEAD # 将当前版本重置为HEAD（通常用于merge失败回退）git rebasegit branch -d hotfixes/BJVEP933 # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支）git branch -D hotfixes/BJVEP933 # 强制删除分支hotfixes/BJVEP933git ls-files # 列出git index包含的文件git show-branch # 图示当前分支历史git show-branch --all # 图示所有分支历史git whatchanged # 显示提交历史对应的文件修改git revert dfb02e6e4f2f7b573337763e5c0013802e392818 # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818git ls-tree HEAD # 内部命令：显示某个git对象git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASHgit reflog # 显示所有提交，包括孤立节点git show HEAD@&#123;5&#125;git show master@&#123;yesterday&#125; # 显示master分支昨天的状态git log --pretty=format:&apos;%h %s&apos; --graph # 图示提交日志git show HEAD~3git show -s --pretty=raw 2be7fcb476git stash # 暂存当前修改，将所有至为HEAD状态git stash list # 查看所有暂存git stash show -p stash@&#123;0&#125; # 参考第一次暂存git stash apply stash@&#123;0&#125; # 应用第一次暂存git grep &quot;delete from&quot; # 文件中搜索文本“delete from”git grep -e &apos;#define&apos; --and -e SORT_DIRENTgit gcgit fsck]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ与Spring整合]]></title>
    <url>%2F2017%2F09%2FActiveMQ%E4%B8%8ESpring%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[配置文件中引入ActiveMQ.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:amq=&quot;http://activemq.apache.org/schema/core&quot; xmlns:jms=&quot;http://www.springframework.org/schema/jms&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms-4.0.xsd http://activemq.apache.org/schema/core http://activemq.apache.org/schema/core/activemq-core-5.8.0.xsd&quot;&gt; &lt;context:property-placeholder location=&quot;classpath:app*.properties&quot; local-override=&quot;true&quot; file-encoding=&quot;UTF-8&quot;/&gt; &lt;!-- ActiveMQ 连接工厂 --&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;!-- 如果连接网络：tcp://ip:61616；未连接网络：tcp://localhost:61616 以及用户名，密码--&gt; &lt;amq:connectionFactory id=&quot;amqConnectionFactory&quot; brokerURL=&quot;$&#123;jms.broker-url&#125;&quot; userName=&quot;admin&quot; password=&quot;admin&quot;/&gt; &lt;!-- Spring Caching连接工厂 --&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.CachingConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;amqConnectionFactory&quot;/&gt; &lt;!-- 同上，同理 --&gt; &lt;!-- &lt;constructor-arg ref=&quot;amqConnectionFactory&quot; /&gt; --&gt; &lt;!-- Session缓存数量 --&gt; &lt;property name=&quot;sessionCacheSize&quot; value=&quot;100&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring JmsTemplate 的消息生产者 start--&gt; &lt;!-- 定义JmsTemplate的Topic类型 --&gt; &lt;bean id=&quot;jmsTopicTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;constructor-arg ref=&quot;connectionFactory&quot;/&gt; &lt;!-- pub/sub模型（发布/订阅） --&gt; &lt;property name=&quot;pubSubDomain&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; &lt;!-- 定义JmsTemplate的Queue类型 --&gt; &lt;bean id=&quot;jmsQueueTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;constructor-arg ref=&quot;connectionFactory&quot;/&gt; &lt;!-- 非pub/sub模型（发布/订阅），即队列模式 --&gt; &lt;property name=&quot;pubSubDomain&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;!--Spring JmsTemplate 的消息生产者 end--&gt; &lt;!-- 消息消费者 start--&gt; &lt;!-- 定义Queue监听器 --&gt; &lt;jms:listener-container destination-type=&quot;queue&quot; container-type=&quot;default&quot; connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;auto&quot;&gt; &lt;jms:listener destination=&quot;test.queue&quot; ref=&quot;queueReceiver1&quot;/&gt; &lt;jms:listener destination=&quot;test.queue&quot; ref=&quot;queueReceiver2&quot;/&gt; &lt;/jms:listener-container&gt; &lt;!-- 定义Topic监听器 --&gt; &lt;jms:listener-container destination-type=&quot;topic&quot; container-type=&quot;default&quot; connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;auto&quot;&gt; &lt;jms:listener destination=&quot;test.topic&quot; ref=&quot;topicReceiver1&quot;/&gt; &lt;jms:listener destination=&quot;test.topic&quot; ref=&quot;topicReceiver2&quot;/&gt; &lt;/jms:listener-container&gt; &lt;!-- 消息消费者 end --&gt;&lt;/beans&gt; Queue生产者123456789101112131415161718192021/** * @description 队列消息生产者，发送消息到队列 */@Component(&quot;queueSender&quot;)public class QueueSender &#123; @Autowired @Qualifier(&quot;jmsQueueTemplate&quot;) private JmsTemplate jmsQueueTemplate;//通过@Qualifier修饰符来注入对应的bean /** * 发送一条消息到指定的队列（目标） * * @param queueName 队列名称 * @param message 消息内容 */ public void send(String queueName, final String message) &#123; jmsQueueTemplate.convertAndSend(queueName, message); &#125;&#125; Topic生产者123456789101112131415161718@Component(&quot;topicSender&quot;)public class TopicSender &#123; @Autowired @Qualifier(&quot;jmsTopicTemplate&quot;) private JmsTemplate jmsTemplate; /** * 发送一条消息到指定的队列（目标） * * @param topicName 队列名称 * @param message 消息内容 */ public void send(String topicName, final String message) &#123; jmsTemplate.convertAndSend(topicName, message); &#125;&#125; 接口测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Controller@RequestMapping(&quot;/activemq&quot;)public class ActivemqController &#123; @Resource private QueueSender queueSender; @Resource private TopicSender topicSender; /** * todo 开启activeMQ服务 * 发送消息到队列 * Queue队列：仅有一个订阅者会收到消息，消息一旦被处理就不会存在队列中 * @param message * @return String */ @ResponseBody @PostMapping(&quot;/queueSender&quot;) public String queueSender(@RequestParam(&quot;message&quot;) String message) &#123; String opt = &quot;&quot;; try &#123; queueSender.send(&quot;test.queue&quot;, message); opt = &quot;success&quot;; &#125; catch (Exception e) &#123; opt = e.getCause().toString(); &#125; return opt; &#125; /** * 发送消息到主题 * Topic主题 ：放入一个消息，所有订阅者都会收到 * 这个是主题目的地是一对多的 * * @param message * @return String */ @ResponseBody @PostMapping(&quot;/topicSender&quot;) public String topicSender(@RequestParam(&quot;message&quot;) String message) &#123; String opt = &quot;&quot;; try &#123; topicSender.send(&quot;test.topic&quot;, message); opt = &quot;success&quot;; &#125; catch (Exception e) &#123; opt = e.getCause().toString(); &#125; return opt; &#125;&#125;]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九浅一深之ActiveMQ]]></title>
    <url>%2F2017%2F09%2F%E4%B9%9D%E6%B5%85%E4%B8%80%E6%B7%B1%E4%B9%8BActiveMQ%2F</url>
    <content type="text"><![CDATA[下载ActiceMQ : http://activemq.apache.org/运行ActiveMQ服务 双击bin目录下的activemq.bat脚本文件 ActiveMQ默认使用的TCP连接端口是61616, 通过查看该端口的信息可以测试ActiveMQ是否成功启动 netstat -an|find “61616” ActiveMQ默认启动时，启动了内置的jetty服务器，提供一个用于监控ActiveMQ的admin应用。admin：http://127.0.0.1:8161/admin/，账号密码默认admin Ctrl+Shift+C 停止服务HelloWorld 生产者 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class JMSProducer &#123; //默认连接用户名 private static final String USERNAME = ActiveMQConnection.DEFAULT_USER; //默认连接密码 private static final String PASSWORD = ActiveMQConnection.DEFAULT_PASSWORD; //默认连接地址 private static final String BROKEURL = ActiveMQConnection.DEFAULT_BROKER_URL; //发送的消息数量 private static final int SENDNUM = 10; public static void main(String[] args) &#123; //连接工厂 ConnectionFactory connectionFactory; //连接 Connection connection = null; //会话 接受或者发送消息的线程 Session session; //消息的目的地 Destination destination; //消息生产者 MessageProducer messageProducer; //实例化连接工厂 connectionFactory = new ActiveMQConnectionFactory(JMSProducer.USERNAME, JMSProducer.PASSWORD, JMSProducer.BROKEURL); try &#123; //通过连接工厂获取连接 connection = connectionFactory.createConnection(); //启动连接 connection.start(); //创建session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); //创建一个名称为HelloWorld的消息队列 destination = session.createQueue(&quot;HelloWorld&quot;); //创建消息生产者 messageProducer = session.createProducer(destination); //发送消息 sendMessage(session, messageProducer); session.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; if(connection != null)&#123; try &#123; connection.close(); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 发送消息 * @param session * @param messageProducer 消息生产者 * @throws Exception */ public static void sendMessage(Session session,MessageProducer messageProducer) throws Exception&#123; for (int i = 0; i &lt; JMSProducer.SENDNUM; i++) &#123; //创建一条文本消息 TextMessage message = session.createTextMessage(&quot;ActiveMQ 发送消息&quot; +i); System.out.println(&quot;发送消息：Activemq 发送消息&quot; + i); //通过消息生产者发出消息 messageProducer.send(message); &#125; &#125;&#125; 消费者 1234567891011121314151617181920212223242526272829303132333435363738394041public class JMSConsumer &#123; private static final String USERNAME = ActiveMQConnection.DEFAULT_USER;//默认连接用户名 private static final String PASSWORD = ActiveMQConnection.DEFAULT_PASSWORD;//默认连接密码 private static final String BROKEURL = ActiveMQConnection.DEFAULT_BROKER_URL;//默认连接地址 public static void main(String[] args) &#123; ConnectionFactory connectionFactory;//连接工厂 Connection connection = null;//连接 Session session;//会话 接受或者发送消息的线程 Destination destination;//消息的目的地 MessageConsumer messageConsumer;//消息的消费者 //实例化连接工厂 connectionFactory = new ActiveMQConnectionFactory(JMSConsumer.USERNAME, JMSConsumer.PASSWORD, JMSConsumer.BROKEURL); try &#123; //通过连接工厂获取连接 connection = connectionFactory.createConnection(); //启动连接 connection.start(); //创建session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建一个连接HelloWorld的消息队列 destination = session.createQueue(&quot;HelloWorld&quot;); //创建消息消费者 messageConsumer = session.createConsumer(destination); while (true) &#123; TextMessage textMessage = (TextMessage) messageConsumer.receive(100000); if(textMessage != null)&#123; System.out.println(&quot;收到的消息:&quot; + textMessage.getText()); &#125;else &#123; break; &#125; &#125; &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 开启ActiveMQ服务，启动生产者，发送消息，此时在http://localhost:8161/admin/ 可查看相应的Queues内容 启动消费者，消费队列中的消息，此时在http://localhost:8161/admin/ 相应的Queues内容已被消费]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九浅一深之JMS]]></title>
    <url>%2F2017%2F09%2F%E4%B9%9D%E6%B5%85%E4%B8%80%E6%B7%B1%E4%B9%8BJMS%2F</url>
    <content type="text"><![CDATA[消息模型点对点模型概念 消息队列（Queue） 发送者(Sender) 接收者(Receiver) 每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。 特点 每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中) 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列 接收者在成功接收消息之后需向队列应答成功 如果你希望发送的每个消息都应该被成功处理的话，那么你需要P2P模式。 发布订阅模型概念 主题（Topic） 发布者（Publisher） 订阅者（Subscriber） 客户端将消息发送到主题。多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。 特点 每个消息可以有多个消费者 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。 为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。 如果你希望发送的消息可以不被做任何处理、或者被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型 消息的消费 在JMS中，消息的产生和消息是异步的。对于消费来说，JMS的消息者可以通过两种方式来消费消息。 同步订阅者或接收者调用receive方法来接收消息，receive方法在能够接收到消息之前（或超时之前）将一直阻塞 异步订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的onMessage方法。JMS编程模型 ConnectionFactory创建Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。 DestinationDestination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的Destination是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的Destination也是某个队列或主题（即消息来源）。 所以，Destination实际上就是两种类型的对象：Queue、Topic可以通过JNDI来查找Destination。 ConnectionConnection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。 SessionSession是我们操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当我们需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。 消息的生产者消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。 消息消费者消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。 MessageListener消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。 优点 提供消息灵活性 松散耦合 异步性]]></content>
      <categories>
        <category>JMS</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bug小知识]]></title>
    <url>%2F2017%2F09%2FBug%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[数据库字段类型与模型类型要一一对应 空指针验证anytime 会变动的配置数据，不应当存到数据库当中。例如，一个比赛发布地址（http://127.0.0.1/schedule/address/{scheduleId}），地址前缀是配置项，在数据库只需在比赛表设定一个状态，验证是否发布，调用时候再进行拼接即可。]]></content>
      <categories>
        <category>Bug</category>
      </categories>
      <tags>
        <tag>Bug</tag>
        <tag>小知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的5个常见使用场景]]></title>
    <url>%2F2017%2F09%2FRedis%E7%9A%845%E4%B8%AA%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。 全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。 发布/订阅]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis发布订阅]]></title>
    <url>%2F2017%2F09%2FRedis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%2F</url>
    <content type="text"><![CDATA[发布订阅(pub/sub)是一种消息通信模式，主要的目的是解耦消息发布者和消息订阅者之间的耦合，这点和设计模式中的观察者模式比较相似。pub /sub不仅仅解决发布者和订阅者直接代码级别耦合也解决两者在物理部署上的耦合。redis作为一个pub/sub server，在订阅者和发布者之间起到了消息路由的功能。订阅者可以通过subscribe和psubscribe命令向redis server订阅自己感兴趣的消息类型，redis将消息类型称为通道(channel)。当发布者通过publish命令向redis server发送特定类型的消息时。订阅该消息类型的全部client都会收到此消息。这里消息的传递是多对多的。一个client可以订阅多个 channel,也可以向多个channel发送消息。 配置文件12345678910111213141516171819202122232425262728&lt;bean id=&quot;jedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt; &lt;constructor-arg name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot;/&gt; &lt;property name=&quot;hostName&quot; value=&quot;$&#123;redis.host&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;redis.password&#125;&quot;/&gt; &lt;property name=&quot;port&quot; value=&quot;$&#123;redis.port&#125;&quot;/&gt; &lt;property name=&quot;database&quot; value=&quot;$&#123;redis.database&#125;&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;$&#123;redis.maxIdle&#125;&quot;/&gt; &lt;property name=&quot;maxTotal&quot; value=&quot;$&#123;redis.maxActive&#125;&quot;/&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;redis.testOnBorrow&#125;&quot;/&gt; &lt;property name=&quot;maxWaitMillis&quot; value=&quot;$&#123;redis.timeout&#125;&quot;/&gt; &lt;/bean&gt; &lt;bean scope=&quot;prototype&quot; id=&quot;redisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;/&gt; &lt;property name=&quot;keySerializer&quot; ref=&quot;stringRedisSerializer&quot;/&gt; &lt;property name=&quot;hashKeySerializer&quot; ref=&quot;stringRedisSerializer&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;stringRedisSerializer&quot; class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot;/&gt; &lt;bean id=&quot;redisMessageListener&quot; class=&quot;com.gengee.gsm.util.RedisMessageListener&quot;/&gt; &lt;redis:listener-container connection-factory=&quot;jedisConnectionFactory&quot;&gt; &lt;redis:listener ref=&quot;redisMessageListener&quot; topic=&quot;redisChannel&quot; /&gt; &lt;/redis:listener-container&gt; RedisMessageListener 消息监听 12345678910111213public class RedisMessageListener implements MessageListener &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RedisMessageListener.class); @Autowired private ScheduleLogMapper scheduleLogMapper; @Override public void onMessage(Message message, byte[] bytes) &#123; if (message != null &amp;&amp; !message.toString().equals(&quot;&quot;)) &#123; LOGGER.info(message.toString()); //do you job &#125; &#125;&#125; redis发布 123Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);jedis.auth(&quot;redisPassword&quot;);jedis.publish(&quot;redisChannel&quot;, &quot;publishMessage&quot;); 参考文档：http://www.cnblogs.com/yitudake/p/6747995.htmlhttp://blog.csdn.net/valenon/article/details/46414455]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA小知识]]></title>
    <url>%2F2017%2F09%2FJAVA%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[&amp;和&amp;&amp;的区别 &amp;和^,&lt;&lt;,&lt;&lt;&lt;,|同属于位运算符,其中&amp;是按位与,例如,1&amp;1=1，1&amp;0=0 &amp;&amp;是逻辑运算符,处理真假值，例如,true&amp;&amp;true=true。 mybatis中的CDATA标签的用法 在mapper文件中写sql语句时，遇到特殊字符时，如：&lt; 等，建议使用&lt;![CDATA[ sql 语句 ]]&gt;标记，将sql语句包裹住，不被解析器解析 Http跨域OPTIONS请求跨域资源共享标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站有权限访问哪些资源。另外，规范要求，对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。 OPTIONS请求报错由于预检请求（OPTIONS请求）不会包含Cookie信息（浏览器本身的实现决定其是否发送Cookie，前端无法控制，并且Chrome是不发送的），因此被权限拦截器提前结束，没有输出包含指定头部信息的响应。而一个被浏览器认为合格的预检请求响应必须包含如下的Http头部。(预检请求Options的执行顺序在拦截器之后，因此预检请求被拦截，导致出错,) 方法一：在拦截器中加响应头 1234567891011public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (request.getHeader(HttpHeaders.ORIGIN) != null) &#123; response.addHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); response.addHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;); response.addHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;POST, GET, OPTIONS, DELETE, PUT, HEAD&quot;); response.addHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type,token&quot;); response.addHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;); return true; &#125; &#125; 方法二：在mvcConfig中添加跨域设置：—–无效！待验证！12345678910111213//请求跨域@Overridepublic void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/**&quot;) .allowedOrigins(CorsConfiguration.ALL) .allowCredentials(true)//表示是否允许发送Cookie。 默认情况下，Cookie不包括在CORS请求之中。 设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。 这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可 .allowedHeaders(&quot;Content-Type&quot;, &quot;token&quot;) .allowedMethods(&quot;GET&quot;, &quot;HEAD&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;); super.addCorsMappings(registry);&#125; Tomcat报错： Note: further occurrences of HTTP header parsing errors will be logged at DEBUG level.网上是说在tomcat的server.xml文件里面的&lt;Connector&gt; 里面设定maxHttpHeaderSize属性，但是并没有效果，最后的原因是：用了https请求了本地接口，GG。。。 java作用域public ,private ,protected 及不写时的区别 对于继承自己的class，base class可以认为他们都是自己的子女，而对于和自己一个目录下的classes，认为都是自己的朋友 public：public表明该数据成员、成员函数是对所有用户开放的，所有用户都可以直接进行调用 private：private表示私有，私有的意思就是除了class自己之外，任何人都不可以直接使用，私有财产神圣不可侵犯嘛，即便是子女，朋友，都不可以使用 protected：protected对于子女、朋友来说，就是public的，可以自由使用，没有任何限制，而对于其他的外部class，protected就变成private 1234567891011作用域 当前类 同一package 子孙类 其他package public √ √ √ √ protected √ √ √ × friendly √ √ × × private √ × × × 不写时默认为friendly 图片上传耗时太久 问题描述：页面上传图片，提交后耗时8s才上传 成功，debug页面发现TTFB是主要原因，等待服务器返回的时间过长。 首先将服务器对应的ip端口开放，直接用postman调用接口，发现耗时一样很长，排除服务器nginx代理以及路由导致的原因 发现服务器带宽只有2M，下载理论峰值256k左右，上传只有128左右，1024/128=8s ，原因就是因为服务器带宽不足，导致上传时间消耗比较多 Switch能否用string做参数 在jdk 7 之前，switch 只能支持 byte、short、char、int 这几个基本数据类型和其对应的封装类型 jdk1.7后，整形，枚举类型，boolean，字符串都可以 其实jdk1.7并没有新的指令来处理switch string，而是通过调用switch中string.hashCode,将string转换为int从而进行判断 全局异常处理 使用 @ControllerAdvice + @ExceptionHandler 进行全局的 Controller 层异常处理，只要设计得当，就再也不用在 Controller 层进行 try-catch 了！而且，@Validated 校验器注解的异常，也可以一起处理，无需手动判断绑定校验结果 BindingResult/Errors 优点：将 Controller 层的异常和数据校验的异常进行统一处理，减少模板代码，减少编码量，提升扩展性和可维护性。 缺点：只能处理 Controller 层未捕获（往外抛）的异常，对于 Interceptor（拦截器）层的异常，Spring 框架层的异常，就无能为力了。 Integer 装箱 拆箱 比较 Integer与int类型的赋值 把Integer类型的赋值给int类型，调用intValue()方法进行拆箱赋值。 把int类型赋值给Integer，会调用valueOf()方法对int进行装箱赋值。 Integer与int类型的比较 先对Integer调用intValue()进行拆箱，然后进行值比较]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql小知识]]></title>
    <url>%2F2017%2F09%2FMysql%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Count(null) = 0 Sum(null) = null null + 1 = null 根据得分进行排名，分数为0 不进行排名1234567891011121314SELECT t.competition_id, t.player_id, ( SELECT CASE WHEN t.score &lt;= 0 THEN NULL ELSE COUNT(DISTINCT score) END # 当score小于等于0时，设定排名为null，否则根据where条件（t1.score &gt; t.score）count不同的score值来获取排名 FROM v_player_total_data t1 WHERE t1.competition_id = t.competition_id AND t1.score &gt; t.score ) + 1 scoreFROM v_player_total_data t ORDER BY competition_id]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql随机函数]]></title>
    <url>%2F2017%2F09%2FMySql%E9%9A%8F%E6%9C%BA%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[rand（）函数只能生成0到1之间的随机小数，如果想要生成0到10,0到100就rand（）相应的值。如果想得到整数就要用到round（x），floor（x）和ceiling（x）。round（x）是四舍五入 ； floor（x）是去小于等于x的整数； ceiling（x）是取大于等于x的整数；得到指定范围的随机数 round（rand（）（max-min）+min）即可 ROUND ROUND(X) – 表示将值 X 四舍五入为整数，无小数位 ROUND(X,D) – 表示将值 X 四舍五入为小数点后 D 位的数值，D为小数点后小数位数。若要保留 X 值小数点左边的 D 位，可将 D 设为负值。123456789101112SELECT ROUND(&apos;123.456&apos;)-----------------------------123SELECT ROUND(&apos;123.654&apos;)-----------------------------124SELECT ROUND(&apos;123.456&apos;,2)-----------------------------123.46SELECT ROUND(&apos;123.654&apos;,2)-----------------------------123.65 FLOOR FLOOR(X)表示向下取整，只返回值X的整数部分，小数部分舍弃。123456SELECT FLOOR(&apos;123.456&apos;)-----------------------------123SELECT FLOOR(&apos;123.654&apos;)-----------------------------123 CEILING CEILING(X) 表示向上取整，只返回值X的整数部分，小数部分舍弃。1234567SELECT CEILING(&apos;123.456&apos;)-----------------------------124SELECT CEILING(&apos;123.654&apos;)-----------------------------124]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[外面好吵]]></title>
    <url>%2F2017%2F09%2F%E5%A4%96%E9%9D%A2%E5%A5%BD%E5%90%B5%2F</url>
    <content type="text"><![CDATA[今天很阴。早晨模糊醒来，是阴冷的空调风。书桌上的瓶罐，一晃一晃没了重心。整个房间，没了生气。 外面好吵。轰隆隆的飞机声，掠过梦境。冷气一直吹，冰冷冷。棱角分明，生硬的拽我。摆了摆手，给我安静。]]></content>
      <categories>
        <category>大白话</category>
      </categories>
      <tags>
        <tag>大白话</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux安装多个tomcat]]></title>
    <url>%2F2017%2F09%2Flinux%E5%AE%89%E8%A3%85%E5%A4%9A%E4%B8%AAtomcat%2F</url>
    <content type="text"><![CDATA[编辑环境变量：vi /etc/profile 加入以下代码(tomcat路径要配置自己实际的tomcat安装目录) 123456789101112##########first tomcat###########CATALINA_BASE=/usr/local/tomcatCATALINA_HOME=/usr/local/tomcatTOMCAT_HOME=/usr/local/tomcatexport CATALINA_BASE CATALINA_HOME TOMCAT_HOME##########first tomcat######################second tomcat##########CATALINA_2_BASE=/usr/local/tomcat_2CATALINA_2_HOME=/usr/local/tomcat_2TOMCAT_2_HOME=/usr/local/tomcat_2export CATALINA_2_BASE CATALINA_2_HOME TOMCAT_2_HOME##########second tomcat########## 保存退出（:wq） source /etc/profile 生效 修改tomcat配置文件 第一个tomcat，保持解压后的原状不用修改, 来到第二个tomcat的bin目录下，打开catalina.sh ，找到下面红字： 1# OS specific support. $var _must_ be set to either true or false. 在下面增加如下代码 12export CATALINA_BASE=$CATALINA_2_BASEexport CATALINA_HOME=$CATALINA_2_HOME 来到第二个tomcat的conf目录下打开server.xml更改端口： 修改server.xml配置和第一个不同的启动、关闭监听端口。 修改后示例如下：123456789 &lt;Server port=&quot;9005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; 端口：8005-&gt;9005&lt;!-- Define a non-SSL HTTP/1.1 Connector on port 8080 --&gt; &lt;Connector port=&quot;8081&quot; maxHttpHeaderSize=&quot;8192&quot; 端口：8080-&gt;8081maxThreads=&quot;150&quot; minSpareThreads=&quot;25&quot; maxSpareThreads=&quot;75&quot; enableLookups=&quot;false&quot; redirectPort=&quot;8443&quot; acceptCount=&quot;100&quot; connectionTimeout=&quot;20000&quot; disableUploadTimeout=&quot;true&quot; /&gt;&lt;!-- Define an AJP 1.3 Connector on port 8009 --&gt; &lt;Connector port=&quot;9009&quot; 端口：8009-&gt;9009 enableLookups=&quot;false&quot; redirectPort=&quot;8443&quot; protocol=&quot;AJP/1.3&quot; /&gt; 分别进入两个tomcat的bin目录，启动tomcat–./startup.sh 然后访问http://localhost:8080 和 http://localhost:8081 都可以看到熟悉的tomcat欢迎界面。 如果想启动多个可以依此法类推……]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 80端口映射到8080]]></title>
    <url>%2F2017%2F08%2Flinux-80%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E5%88%B08080%2F</url>
    <content type="text"><![CDATA[有时我们在服务Linux服务器上安装了tomcat（端口号为8080），而要求是输入网址后不添加端口号就能访问，这就意味着浏览器得通过80端口访问到你的tomcat（端口为8080），为此有两种解决方式： 基于linux系统禁止1024一下的端口让非root用户使用，那么就必须是用root用户登录才能去启动修改为80端口的tomcat（注意： 直接在tomcat server.xml中更改为80，用sudo命令是启动不了的，必须要root用户登录启动！！） 基于root密码不是随随便便能得到的，所以一般采用第二种方法（即端口映射）来达到你的目的：具体命令为： 1iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080 1234-t nat : 指出我要操作什么表.(不写就表示filter.默认是filter) -A PREROUTING : A 添加的意思.表示我要在PREROUTING 中添加一个规则 --dport 80 : 如果请求80端口. --to-port 8080 : 那么就转到8080端口.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swagger文档linux部署]]></title>
    <url>%2F2017%2F08%2FSwagger%E6%96%87%E6%A1%A3linux%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[安装httpd配置httpd.conf文件 vim /etc/httpd/conf/httpd.conf 添加监听端口：Listen 6080 12345&lt;VirtualHost *:6080&gt; DocumentRoot /swagger Header set Access-Control-Allow-Origin * ServerName *.*.*.*:6080&lt;/VirtualHost&gt; 修改后需要重启httpd服务：/etc/init.d/httpd restart 放置文档文件夹 /swagger由于SELinux开启造成的Apache 2 Test Page powered by CentOS 把SELinux的状态改一下就可以：执行setenforce 0]]></content>
      <categories>
        <category>Swagger</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小知识系列：第二集]]></title>
    <url>%2F2017%2F08%2F%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97%EF%BC%9A%E7%AC%AC%E4%BA%8C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Shiro Redis JMS ActiveMQ/RabbitMQ 高并发 Maven WebSocket SpringBoot SpringCloud Docker JFinal]]></content>
      <categories>
        <category>杂烩</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>杂烩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小知识系列：第一集]]></title>
    <url>%2F2017%2F08%2F%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97%EF%BC%9A%E7%AC%AC%E4%B8%80%E9%9B%86%2F</url>
    <content type="text"><![CDATA[贫血模型—领域模型（区分）泛型JSR 303验证Lombok 去掉Setter和Getter bean的链式风格 构造静态方法 builder 代理模式理解OAuth 2.0学习列表 JAVA8 Git Maven MongoDB Shiro Redis Spring Mybatis Linux Liquibase Restful RMI Spring BootRemember Coding要考虑语义的操作，提高代码可读性 保证任何数据的入参到方法体内都合法，对于脏数据的产生一定是致命的 多回头看自己的代码 勤于重构 多看成熟的框架源码 排列组合 排列AA(n,m) = n! / (n-m)! 组合CC(n,m) = A(n,m) / m! 三角函数 远程调用(魔法隧道) 注册魔法隧道 新建一个隧道，设置本地ip以及发布端口 获取token以及隧道域名 本地下载魔法隧道exe，在命令行根据token开启隧道 网络调用本地接口]]></content>
      <categories>
        <category>杂烩</category>
      </categories>
      <tags>
        <tag>小知识</tag>
        <tag>杂烩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 协作]]></title>
    <url>%2F2017%2F08%2FGit-%E5%8D%8F%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Fork项目到个人的仓库Clone项目到本地SSH （命令行操作） 复制ssh url在git命令行执行 git clone git@github.com:XXXXXX/你要fork的项目名12git branch -a ------查看所有分支git checkout -b dev-local origin/dev ----------创建一个dev-local分支（-b），并把远程dev分支（origin/dev）的内容放在该分支内。接着切换到该分支（checkout） HTTPS（idea等工具操作） https: //github.com/XXXXXX/你要fork的项目名.git VCS-&gt;checkout from Version controller-&gt;git-&gt;clone 后期直接idea操作， 不需要进行以下操作 push修改到自己的项目上 git add –all git fetch git commit -m ‘提交的注释’ git push 请求合并到团队项目上 点击Pull request 添加标题跟描述信息，确认提交内容 点击Create pull request进行发送合并请求]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小问题]]></title>
    <url>%2F2017%2F08%2F%E5%B0%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[bindException 1234567891011&lt;bean id=&quot;sessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:/mybatis.xml&quot;/&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.gengee.insait.c1.bean&quot;/&gt; # 引入mapper.xml文件 &lt;property name=&quot;mapperLocations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:/mapper/*.xml&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 抛出AuthenticationException，状态仍为200 1234567891011121314151617181920212223Filter应当重新实现onLoginFailure方法@Override protected boolean onLoginFailure(AuthenticationToken token, AuthenticationException e, ServletRequest request, ServletResponse response) &#123; HashMap&lt;String, String&gt; errMap = new HashMap&lt;&gt;(); errMap.put(&quot;description&quot;, e.getMessage()); errMap.put(&quot;error&quot;, &quot;invalid_equipId&quot;); try &#123; ObjectMapper objectMapper = new ObjectMapper(); String errorJson = objectMapper.writeValueAsString(errMap); HttpServletResponse httpResponse = WebUtils.toHttp(response); httpResponse.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); httpResponse.setHeader(&quot;Access-Control-Request-Method&quot;, &quot;*&quot;); httpResponse.setHeader(&quot;Access-Control-Request-Headers&quot;, &quot;*&quot;); httpResponse.setStatus(401); httpResponse.setContentType(&quot;application/json;charset=UTF-8&quot;); httpResponse.getWriter().write(errorJson); return false; &#125; catch (IOException var9) &#123; LOGGER.error(&quot;Build JSON message error&quot;, var9); throw new IllegalStateException(var9); &#125; &#125; one or more listener failed to startapp-shiro.xml应当在Spring Application配置文件中引入，而不是在Spring Mvc配置文件中引入]]></content>
      <categories>
        <category>小问题</category>
      </categories>
      <tags>
        <tag>Exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我想要说]]></title>
    <url>%2F2017%2F08%2F%E6%88%91%E6%83%B3%E8%A6%81%E8%AF%B4%2F</url>
    <content type="text"><![CDATA[小时候，你带着我虽然吃的不好，过的不好但总是没有饿着尽管你有缺点，也有不好可是我理解，我也有啊现在长大了，每次陪你聊天其实是听你叨叨我很满足，也开心的虽然每次讲的大体都一样可我知道你能记住的不多对老人还要苛求什么？老人只想要陪伴只想要心里舒坦点时间真的变了很多人但我记得你的好，也会对你好。]]></content>
      <categories>
        <category>大白话</category>
      </categories>
      <tags>
        <tag>大白话</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天晴的透透]]></title>
    <url>%2F2017%2F08%2F%E5%A4%A9%E6%99%B4%E7%9A%84%E9%80%8F%E9%80%8F%2F</url>
    <content type="text"><![CDATA[太阳不辣，天晴的透透漂了天蓝色，抹淡淡的妆幼稚的小松鼠探出头瞧了瞧，咽了口水跐溜一下，爬上龙眼树定是嘴馋了，像我一样盈满的木瓜树，缀着青翠一旁的枇杷，大半年也不结个果子妒忌着，眼羡极了别怕，再等等努努力，总会有结果的像我们一样]]></content>
      <categories>
        <category>大白话</category>
      </categories>
      <tags>
        <tag>大白话</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ajax 跨域请求]]></title>
    <url>%2F2017%2F08%2FAjax-%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[错误信息12345jquery-3.1.1.min.js:4 XMLHttpRequest cannot load http://127.0.0.1:8080/user/login.action. No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://localhost:8080&apos; is therefore not allowed access. 解决办法服务端设置支持跨域@CrossOrigin注解 即在Controller控制器中，在Controller注解上方添加@CrossOrigin注解。 12@CrossOrigin(origins = &#123;&quot;*&quot;&#125;, maxAge = 3600)public classUserController&#123;&#125; 官网：www.fhadmin.org也可以在Controller控制器中的每个方法中分别添加@CrossOrigin注解。 12@CrossOrigin(origins = &#123;&quot;*&quot;&#125;, maxAge = 3600)public String login(String username, String password)throws Exception &#123;&#125; 假如添加之后还是出现了跨域问题，需要给映射路径中配置请求方法（method） 123@RequestMapping(value = &quot;user&quot;, method = &#123;RequestMethod.POST&#125;)@CrossOrigin(origins = &#123;&quot;*&quot;&#125;, maxAge = 3600)public class UserController &#123;&#125; CORS全局配置 基于xml的配置，在springmvc.xml中配置 1234&lt;!-- 跨域请求 --&gt;&lt;mvc:cors&gt; &lt;mvc:mappingpath=&quot;/user/*&quot;/&gt;&lt;/mvc:cors&gt; 官网：www.fhadmin.org 可以进行详细的配置 12345678&lt;mvc:cors&gt; &lt;mvc:mappingpath=&quot;/api/**&quot;allowed-origins=&quot;http://domain1.com, http://domain2.com&quot;allowed-methods=&quot;GET, PUT &quot;allowed-headers=&quot;header1, header2, header3&quot; exposed-headers=&quot;header1, header2&quot; allow-credentials=&quot;false&quot;max-age=&quot;123&quot; /&gt; &lt;mvc:mappingpath=&quot;/resources/**&quot;allowed-origins=&quot;http://domain1.com&quot; /&gt;&lt;/mvc:cors&gt; 假如出现”通配符的匹配很全面, 但无法找到元素 ‘mvc:cors’ 的声明。”这样的错误解决办法： 查看文件上边beans中xsd文件引入的版本是不是不对。如下所示： http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd引入的xsd版本为3.0，而mvc:cors是4.2版本的功能。因此，只需要将xsd版本更新就行。或者设置成4.2以上的。 http://www.springframework.org/schema/mvc/spring-mvc.xsd PHP 1header(&quot;Access-Control-Allow-Origin:*&quot;); //*号表示所有域名都可以访问 JSONP实现跨域 常用的jquery实现跨域调用12345678$.ajax(&#123; url: &quot;&quot;, dataType: &quot;jsonp&quot;, jsonp: &quot;callback&quot;, success: function(data) &#123; console.log(data); &#125;&#125;); 这个调用实际上的实现原理是：在网页中构造一个script标签，将src设置为对应的url，并增加上相应的callback参数，形如如下格式：1&lt;script src=&quot;http://127.0.0.1/index?callback=jQuery211018970995225637144_1465350372062&amp;_=1465350372063&quot;&gt;&lt;/script&gt; 请求的服务端代码：12String jsoncallback=request.getParameter(&quot;callback&quot;);//指定接受参数为callbackreturn jsoncallback+&quot;([&#123;name:&apos;jsonp&apos;,age:&apos;30&apos;&#125;,&#123;name:&apos;jack&apos;,age:&apos;90&apos;&#125;])&quot;; jsonp实现的缺点jsonp实现的跨域方式不支持post请求，只能支持get请求]]></content>
      <categories>
        <category>Ajax</category>
      </categories>
      <tags>
        <tag>ajax</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro 简介]]></title>
    <url>%2F2017%2F08%2FShiro-%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[基本功能点 Authentication：身份认证/登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web支持，可以非常容易的集成到Web环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率； Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 记住一点，Shiro不会去维护用户、维护权限；这些需要我们自己去设计/提供；然后通过相应的接口注入给Shiro即可。接下来我们分别从外部和内部来看看Shiro的架构，对于一个好的框架，从外部来看应该具有非常简单易于使用的API，且API契约明确；从内部来看的话，其应该有一个可扩展的架构，即非常容易插入用户自定义实现，因为任何框架都不能满足所有需求。 外部视角 首先，我们从外部来看Shiro吧，即从应用程序角度的来观察如何使用Shiro完成工作。如下图： 可以看到：应用代码直接交互的对象是Subject，也就是说Shiro的对外API核心就是Subject；其每个API的含义： Subject：主体，代表了当前“用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是Subject，如网络爬虫，机器人等；即一个抽象概念；所有Subject都绑定到SecurityManager，与Subject的所有交互都会委托给SecurityManager；可以把Subject认为是一个门面；SecurityManager才是实际的执行者； SecurityManager：安全管理器；即所有与安全有关的操作都会与SecurityManager交互；且它管理着所有Subject；可以看出它是Shiro的核心，它负责与后边介绍的其他组件进行交互，如果学习过SpringMVC，你可以把它看成DispatcherServlet前端控制器； Realm：域，Shiro从从Realm获取安全数据（如用户、角色、权限），就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法；也需要从Realm得到用户相应的角色/权限进行验证用户是否能进行操作；可以把Realm看成DataSource，即安全数据源。 也就是说对于我们而言，最简单的一个Shiro应用： 应用代码通过Subject来进行认证和授权，而Subject又委托给SecurityManager； 我们需要给Shiro的SecurityManager注入Realm，从而让SecurityManager能得到合法的用户及其权限进行判断。 从以上也可以看出，Shiro不提供维护用户/权限，而是通过Realm让开发人员自己注入。 内部视角接下来我们来从Shiro内部来看下Shiro的架构，如下图所示： s Subject：主体，可以看到主体可以是任何可以与应用交互的“用户”； SecurityManager：相当于SpringMVC中的DispatcherServlet或者Struts2中的FilterDispatcher；是Shiro的心脏；所有具体的交互都通过SecurityManager进行控制；它管理着所有Subject、且负责进行认证和授权、及会话、缓存的管理。 Authenticator：认证器，负责主体认证的，这是一个扩展点，如果用户觉得Shiro默认的不好，可以自定义实现；其需要认证策略（Authentication Strategy），即什么情况下算用户认证通过了； Authrizer：授权器，或者访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能； Realm：可以有1个或多个Realm，可以认为是安全实体数据源，即用于获取安全实体的；可以是JDBC实现，也可以是LDAP实现，或者内存实现等等；由用户提供；注意：Shiro不知道你的用户/权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的Realm； SessionManager：如果写过Servlet就应该知道Session的概念，Session呢需要有人去管理它的生命周期，这个组件就是SessionManager；而Shiro并不仅仅可以用在Web环境，也可以用在如普通的JavaSE环境、EJB等环境；所有呢，Shiro就抽象了一个自己的Session来管理主体与应用之间交互的数据；这样的话，比如我们在Web环境用，刚开始是一台Web服务器；接着又上了台EJB服务器；这时想把两台服务器的会话数据放到一个地方，这个时候就可以实现自己的分布式会话（如把数据放到Memcached服务器）； SessionDAO：DAO大家都用过，数据访问对象，用于会话的CRUD，比如我们想把Session保存到数据库，那么可以实现自己的SessionDAO，通过如JDBC写到数据库；比如想把Session放到Memcached中，可以实现自己的Memcached SessionDAO；另外SessionDAO中可以使用Cache进行缓存，以提高性能； CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据基本上很少去改变，放到缓存中后可以提高访问的性能 Cryptography：密码模块，Shiro提高了一些常见的加密组件用于如密码加密/解密的。]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RMI框架搭建]]></title>
    <url>%2F2017%2F08%2FRMI%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[创建子模块一个作为公有接口模块（Common），一个作为接口实现模块（Component），一个作为引用接口模块（ApiCenter）Component 引入Common 去实现接口方法ApiCenter 引入Common 去调用接口方法 公有模块123&lt;artifactId&gt;Common&lt;/artifactId&gt;&lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 只需要创建接口文件即可，配置文件resource以及webapp都可以删除 接口实现模块12&lt;artifactId&gt;Component&lt;/artifactId&gt;&lt;packaging&gt;war&lt;/packaging&gt; 在接口实现模块的pom.xml，需要引入对接口模块的依赖12345&lt;dependency&gt; &lt;groupId&gt;**********&lt;/groupId&gt; &lt;artifactId&gt;Common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 新建接口实现类BaseService（自动扫描）1234567@Servicepublic class BaseService implements CommonInterface &#123; public String getName() &#123; return &quot;success&quot;; &#125;&#125; Spring Mvc配置文件中引入rmi配置文件（新建rmi配置文件）1234567891011 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; # 此时这个/baseService即为之后调用接口的方法 &lt;bean name=&quot;/baseService&quot; class=&quot;org.springframework.remoting.httpinvoker.HttpInvokerServiceExporter&quot;&gt; &lt;property name=&quot;service&quot; ref=&quot;baseService&quot;/&gt; &lt;property name=&quot;serviceInterface&quot; value=&quot;***.***.***.CommonInterface&quot;/&gt;#指的是Common模块的接口 &lt;/bean&gt;&lt;/beans&gt; 引用接口模块12&lt;artifactId&gt;ApiCenter&lt;/artifactId&gt;&lt;packaging&gt;war&lt;/packaging&gt; 在接口实现模块的pom.xml，需要引入对接口模块的依赖12345&lt;dependency&gt; &lt;groupId&gt;**********&lt;/groupId&gt; &lt;artifactId&gt;Common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Spring Mvc配置文件中引入rmi配置文件（新建rmi配置文件）12345678910 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;baseService&quot; class=&quot;org.springframework.remoting.httpinvoker.HttpInvokerProxyFactoryBean&quot;&gt; &lt;property name=&quot;serviceInterface&quot; value=&quot;***.***.***.CommonInterface&quot;/&gt; &lt;property name=&quot;serviceUrl&quot; value=&quot;$&#123;rmi.server.host&#125;/baseService&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; rmi.server.host应当配置在配置文件里头123# RMI 远程调用服务接口rmi.server.host=http://127.0.0.1:8083/Component# Component模块war包部署在tomcat8083端口 调用接口方法：1234567891011121314@Autowiredprivate CommonInterface commonService;/** * 获取商品列表 * * @param idleResModel * @return */@GetMapping(&quot;/list&quot;)public Map&lt;String, Object&gt; getIdleList(@Valid IdleResModel idleResModel) &#123; Map&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put(&quot;test&quot;, commonService.getName()); return resultMap;&#125;]]></content>
      <categories>
        <category>RMI</category>
      </categories>
      <tags>
        <tag>搭建</tag>
        <tag>RMI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Tag]]></title>
    <url>%2F2017%2F08%2FGit-Tag%2F</url>
    <content type="text"><![CDATA[tag我们可以创建一个tag来指向软件开发中的一个关键时期，比如版本号更新的时候可以建一个“v2.0”、“v3.1”之类的标签，这样在以后回顾的时候会比较方便。tag的使用很简单，主要操作有：查看tag、创建tag、验证tag以及共享tag。 查看tag列出所有tag： git tag 这样列出的tag是按字母排序的，和创建时间没关系。如果只是想查看某些tag的话，可以加限定： git tag -l v1.* 这样就只会列出1.几的版本。 创建tag创建轻量级tag： git tag v1.0 这样创建的tag没有附带其他信息，与之相应的是带信息的tag： git tag -a v1.0-m “first version” -m后面带的就是注释信息，这样在日后查看的时候会很有用，这种是普通tag，还有一种有签名的tag： git tag -s v1.0-m “first version” 前提是你有GPG私钥，把上面的a换成s就行了。除了可以为当前的进度添加tag，我们还可以为以前的commit添加tag： 首先查看以前的commitgit log –oneline假如有这样一个commit：8a5cbc2 updated readme这样为他添加taggit tag -a v1.18a5cbc2 删除tag很简单，知道tag名称后： git tag -d v1.0 验证tag如果你有GPG私钥的话就可以验证tag： git tag -v v1.0 共享tag我们在执行git push的时候，tag是不会上传到服务器的，比如现在的github，创建tag后git push，在github网页上是看不到tag的，为了共享这些tag，你必须这样：（在idea直接执行提交设置的tag）git push origin –tags]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛云图片上传]]></title>
    <url>%2F2017%2F08%2F%E4%B8%83%E7%89%9B%E4%BA%91%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[注册注册一个七牛账号，注册链接：点击注册 ，注册成功之后最好实名认证一下，每个月的流量以及空间的容量会增加很多。 新建空间新建一个空间，记下空间名称（bucketName）。在账号里找到密钥：AK，SK。后面开发中会用到这些。 引入依赖使用maven管理，自动下载对应jar包12345678910&lt;dependency&gt; &lt;groupId&gt;com.qiniu&lt;/groupId&gt; &lt;artifactId&gt;pili-sdk-java&lt;/artifactId&gt; &lt;version&gt;1.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.qiniu&lt;/groupId&gt; &lt;artifactId&gt;qiniu-java-sdk&lt;/artifactId&gt; &lt;version&gt;7.1.3&lt;/version&gt;&lt;/dependency&gt; 编编编编编编码初始化七牛配置文件在配置文件中加入七牛配置123456#--------七牛配置qiniu.access.key=你的AKqiniu.secret.key=你的SKqiniu.bucket.name=你的bucketNameqiniu.bucket.host.name=你的外链默认域名#--------七牛配置 文件上传接口12345678910111213141516171819202122232425public interface UploadUtil &#123;String uploadFile(MultipartFile multipartFile) throws UploadException; String uploadFile(String filePath, MultipartFile multipartFile) throws UploadException; String uploadFile(MultipartFile multipartFile, String fileName) throws UploadException; String uploadFile(MultipartFile multipartFile, String fileName, String filePath) throws UploadException; String uploadFile(File file) throws UploadException; String uploadFile(String filePath, File file) throws UploadException; String uploadFile(File file, String fileName) throws UploadException; String uploadFile(File file, String fileName, String filePath) throws UploadException; String uploadFile(byte[] data) throws UploadException; String uploadFile(String filePath, byte[] data) throws UploadException; String uploadFile(byte[] data, String fileName) throws UploadException; String uploadFile(byte[] data, String fileName, String filePath) throws UploadException;&#125; 文件上传接口实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256public class QiniuUtil implements UploadUtil &#123; private final Logger LOGGER = LoggerFactory.getLogger(this.getClass()); private String bucketHostName; private String bucketName; private Auth auth; private UploadManager uploadManager = new UploadManager(); /** * 构造函数 * * @param bucketHostName 七牛域名 * @param bucketName 七牛空间名 * @param auth 七牛授权 */ public QiniuUtil(String bucketHostName, String bucketName, Auth auth) &#123; this.bucketHostName = bucketHostName; this.bucketName = bucketName; this.auth = auth; &#125; public String generate()&#123; return this.generateToken(); &#125; /** * 根据spring mvc 文件接口上传 * * @param multipartFile spring mvc 文件接口 * @return 文件路径 * @throws IOException */ @Override public String uploadFile(MultipartFile multipartFile) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(bytes); &#125; /** * 根据spring mvc 文件接口上传 * * @param filePath 文件前缀,例如:/test或者/test/ * @param multipartFile spring mvc 文件接口 * @return 文件路径 * @throws IOException */ @Override public String uploadFile(String filePath, MultipartFile multipartFile) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(filePath, bytes); &#125; /** * 根据spring mvc 文件接口上传 * * @param multipartFile spring mvc 文件接口 * @param fileName 文件名 * @return 文件路径 * @throws IOException */ @Override public String uploadFile(MultipartFile multipartFile, String fileName) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(bytes, fileName); &#125; /** * 根据spring mvc 文件接口上传 * * @param multipartFile spring mvc 文件接口 * @param fileName 文件名 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws IOException */ @Override public String uploadFile(MultipartFile multipartFile, String fileName, String filePath) throws UploadException &#123; byte[] bytes = getBytesWithMultipartFile(multipartFile); return this.uploadFile(bytes, fileName, filePath); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(File file) throws UploadException &#123; return this.uploadFile(file, null, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(String filePath, File file) throws UploadException &#123; return this.uploadFile(file, null, filePath); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @param fileName 文件名 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(File file, String fileName) throws UploadException &#123; return this.uploadFile(file, fileName, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param file 文件 * @param fileName 文件名 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(File file, String fileName, String filePath) throws UploadException &#123; String key = preHandle(fileName, filePath); Response response = null; try &#123; response = this.uploadManager.put(file, key, this.generateToken()); &#125; catch (QiniuException e) &#123; LOGGER.warn(&quot;QiniuException:&quot;, e); throw new UploadException(e.getMessage()); &#125; return this.getUrlPath(response); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(byte[] data) throws UploadException &#123; return this.uploadFile(data, null, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(String filePath, byte[] data) throws UploadException &#123; return this.uploadFile(data, null, filePath); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @param fileName 文件名 * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(byte[] data, String fileName) throws UploadException &#123; return this.uploadFile(data, fileName, null); &#125; /** * 根据spring mvc 文件接口上传 * * @param data 文件 * @param fileName 文件名 * @param filePath 文件前缀,例如:/test或者/test/ * @return 文件路径 * @throws UploadException */ @Override public String uploadFile(byte[] data, String fileName, String filePath) throws UploadException &#123; String key = preHandle(fileName, filePath); Response response; try &#123; response = this.uploadManager.put(data, key, generateToken()); &#125; catch (QiniuException e) &#123; LOGGER.error(&quot;QiniuException:&quot;, e); throw new UploadException(e.getMessage()); &#125; return this.getUrlPath(response); &#125; private byte[] getBytesWithMultipartFile(MultipartFile multipartFile) &#123; try &#123; return multipartFile.getBytes(); &#125; catch (IOException e) &#123; e.printStackTrace(); return null; &#125; &#125; private String preHandle(String fileName, String filePath) throws UploadException &#123; if (StringUtils.isNotBlank(fileName) &amp;&amp; !fileName.contains(&quot;.&quot;)) &#123; throw new UploadException(&quot;文件名必须包含尾缀&quot;); &#125; if (StringUtils.isNotBlank(filePath) &amp;&amp; !filePath.startsWith(&quot;/&quot;)) &#123; throw new UploadException(&quot;前缀必须以&apos;/&apos;开头&quot;); &#125; String name = StringUtils.isBlank(fileName) ? RandomStringUtils.randomAlphanumeric(32) : fileName; if (StringUtils.isBlank(filePath)) &#123; return name; &#125; String prefix = filePath.replaceFirst(&quot;/&quot;, &quot;&quot;); return (prefix.endsWith(&quot;/&quot;) ? prefix : prefix.concat(&quot;/&quot;)).concat(name); &#125; private String generateToken() &#123; return this.auth.uploadToken(bucketName); &#125; private String getUrlPath(Response response) throws UploadException &#123; if (!response.isOK()) &#123; throw new UploadException(&quot;文件上传失败&quot;); &#125; DefaultPutRet defaultPutRet; try &#123; defaultPutRet = response.jsonToObject(DefaultPutRet.class); &#125; catch (QiniuException e) &#123; LOGGER.warn(&quot;QiniuException&quot;, e); throw new UploadException(e.getMessage()); &#125; String key = defaultPutRet.key; if (key.startsWith(bucketHostName)) &#123; return key; &#125; return bucketHostName + (key.startsWith(&quot;/&quot;) ? key : &quot;/&quot; + key); &#125;&#125; 接口实例化12345678public class UploadFactory &#123; public static UploadUtil createUpload(String accessKey, String secretKeySpec, String bucketHostName, String bucketName) &#123; Auth auth = Auth.create(accessKey, secretKeySpec); return new QiniuUtil(bucketHostName, bucketName, auth); &#125;&#125; 传上你的小黄图12345678910111213141516171819202122@Servicepublic class UploadService extends BaseService &#123; //引入第一步的七牛配置 @Value(&quot;$&#123;qiniu.access.key&#125;&quot;) private String accesskey; @Value(&quot;$&#123;qiniu.secret.key&#125;&quot;) private String secretKey; @Value(&quot;$&#123;qiniu.bucket.name&#125;&quot;) private String bucketName; @Value(&quot;$&#123;qiniu.bucket.host.name&#125;&quot;) private String bucketHostName; public String uploadImage(MultipartFile image) throws UploadException &#123; UploadUtil uploadUtil = UploadFactory.createUpload(this.accesskey, this.secretKey, this.bucketHostName, this.bucketName); return uploadUtil.uploadFile(&quot;/filePath/&quot;, image); &#125;&#125; 简不简单？惊不惊喜？意不意外？开不开心？]]></content>
      <categories>
        <category>七牛</category>
      </categories>
      <tags>
        <tag>七牛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC 视图解析出错]]></title>
    <url>%2F2017%2F07%2FSpringMVC-%E8%A7%86%E5%9B%BE%E8%A7%A3%E6%9E%90%E5%87%BA%E9%94%99%2F</url>
    <content type="text"><![CDATA[当没有在配置文件中配置&lt;mvc:annotation-driven/&gt;,程序执行没有出现问题，但是postman会报如下图的问题： 总结如果没有&lt;mvc:annotation-driven/&gt;，那么所有的Controller可能就没有解析，所有当有请求时候都没有匹配的处理请求类，就都去&lt;mvc:default-servlet-handler/&gt;即default servlet处理了。添加上&lt;mvc:annotation-driven/&gt;后，相应的do请求被Controller处理。总之没有相应的Controller就会被default servlet处理。所以要使用spring mvc中的@Controller注解就必须要配置&lt;mvc:annotation-driven /&gt;否则org.springframework.web.servlet.DispatcherServlet无法找到控制器并把请求分发到控制器]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[孤独的一个人想着热闹]]></title>
    <url>%2F2017%2F07%2F%E5%AD%A4%E7%8B%AC%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BA%BA%E6%83%B3%E7%9D%80%E7%83%AD%E9%97%B9%2F</url>
    <content type="text"><![CDATA[昨夜，吹冷风有人叹息在灯下，在车里，在路上排成曲折一列谁会在意往心里，来这里路灯，一闪一闪闪了困惑，避开刻意拐进眼角，那左转路口一滴泪，送行热闹的夜，降下来了]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用MyBatis Generator自动创建代码]]></title>
    <url>%2F2017%2F07%2F%E4%BD%BF%E7%94%A8MyBatis-Generator%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[由于MyBatis属于一种半自动的ORM框架，所以主要的工作就是配置Mapping映射文件，但是由于手写映射文件很容易出错，所以可利用MyBatis生成器自动生成实体类、DAO接口和Mapping映射文件。这样可以省去很多的功夫，将生成的代码copy到项目工程中即可 上图文件下载地址：http://download.csdn.net/detail/u012909091/7206091 其中有mybatis框架的jar包，数据库驱动程序jar包以及MyBatis生成器jar包。其中的generatorConfig.xml是需要我们来配置的文件，配置如下： 当以上这些完成之后，只需要打开控制台，进入lib目录下，执行脚本：Java -jar mybatis-generator-core-1.3.2.jar -configfile generatorConfig.xml -overwrite即可。 这样在生成之后，就可以在src目录下找到相应的文件夹，每个表格都会对应三个文件：实体类、接口、配置文件 转载要注明出处：谢谢shu_lin]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swagger 炫酷上手]]></title>
    <url>%2F2017%2F07%2FSwagger-%E7%82%AB%E9%85%B7%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[描述API接口文档（OpenAPI规范） 一个例子 #之后为我的备注 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115swagger: &quot;2.0&quot; # OpenAPI规范的版本号info: # 文档描述信息 version: v1.0.0 title: 标题 description: 这个文档的描述schemes: # API的URL - httphost: 127.0.0.1:8080basePath: /MyTestpaths: # API的操作###########API开始################## /player/compare/&#123;playerId&#125;: # http://127.0.0.1:8080/MyTest//player/compare/&#123;playerId&#125;----进行调用api get: tags: # 这个api的标签分类 - player description: 获取球员场均数据 parameters: - in: path # 路径参数（api的url要带上，名称要一致） name: playerId description: 球员id required: true type: string - in: query name: gender description: 性别 required: false type: string enum:# 枚举 - F - M - in: query # 请求参数 name: competitionId description: 赛事id required: false type: string # 此外还有一个消息体参数(in: body) # 引入分页参数，下方的parameters定义 - $ref: &quot;#/parameters/pageSize&quot; - $ref: &quot;#/parameters/page&quot; responses:# 响应 200: # 响应类型（HTTP状态码） description: 请求成功 schema: # 响应内容 type: object # 对象类型 properties: totalCount: type: integer description: 统计数据数量 playerData: type: array# 数组类型 description: 统计数据总和 items: type: object description: 球员统计数据模型 $ref: &apos;#/definitions/PlayerDataModel&apos; 500: # 下文responses定义 $ref: &quot;#/responses/Standard500ErrorResponse&quot; 404: # 下文responses定义 $ref: &quot;#/responses/Standard404ErrorResponse&quot; security: # 安全验证 - access_token: []##############API结束#################securityDefinitions: access_token: type: apiKey name: Authorization in: header definitions: # 自定义模型 Error: required: - code - message properties: code: type: string message: type: string PlayerDataModel: properties: teamId: type: string description: 球队id playerId: type: string description: 球员id playerName: type: string description: 球员名称responses: # 自定义响应模型 Standard500ErrorResponse: description: 请求失败 schema: $ref: &quot;#/definitions/Error&quot; Standard404ErrorResponse: description: 页面不存在parameters: # 自定义参数模型 pageSize: name: pageSize in: query description: 每页大小 type: integer format: int32 required: false page: in: query name: page description: 页码 type: integer format: int32 required: false 详细解释传送门]]></content>
      <categories>
        <category>Swagger</category>
      </categories>
      <tags>
        <tag>Swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个痴]]></title>
    <url>%2F2017%2F07%2F%E4%B8%80%E4%B8%AA%E7%97%B4%2F</url>
    <content type="text"><![CDATA[谁的一抹笑，泛滥在西边的彩霞里，荡开了归鸟的群喧！半扬的嘴角，醉人的笑，依洄在彩虹似的梦？任凭晚风吹尽黄昏的徘徊；任凭孤雁掠走夕阳的彷徨。户外的昏黄已然凝聚成夜的乌黑。她的温存，我的迷醉。假若、不能用沉默，来回复长夜的慰安，我宁愿…独自呐喊，看星斗纵横。枉然？我不是盲目，我只是痴。]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我愿意]]></title>
    <url>%2F2017%2F07%2F%E6%88%91%E6%84%BF%E6%84%8F%2F</url>
    <content type="text"><![CDATA[我愿意是只小鸟 栖息在你木屋房的树林里 纵然飞不到那片天空 我也会尽力向你飞去 我愿意是条小溪 流淌在你树林间的水流里 纵然淌不过那片海洋 我也会全力向你奔去 我愿意是朵小花 开放在水流边的泥土地里 纵然走不进那片土地 我也会尽力向你绽放出所有的美丽 我愿意 我愿意 飞翔在你的记忆里 流淌在你的记忆里 芬芳在你呼吸的每一寸空气里 ——只是为你 我愿意]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蛤蟆]]></title>
    <url>%2F2017%2F07%2F%E8%9B%A4%E8%9F%86%2F</url>
    <content type="text"><![CDATA[一缕又一缕轻烟似的雨隆重的奏歌又有天空的绚彩莫以为这烂漫的旋律能绕出万般的喝彩妄想这烦躁的枯闷抵过夏日骄阳的絢烂一如既往的细细绵绵在雨中奔跑溅开的泥泞荡走了微尘微微的一阵涟漪波折又起伏那咧嘴的蛤蟆看着，笑开了花]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你]]></title>
    <url>%2F2017%2F07%2F%E4%BD%A0%2F</url>
    <content type="text"><![CDATA[拂人的凉意透过秋风的层层阻挠扎破了我裹实的心防贴近胸膛，就要刺穿我的心扉渗进肌肤，就要颤抖我的躯干你像希望奔赴而来像阳光，照在胸口，散开醉人的暖像月光，绕在指尖，缠了岁月温柔像星光，缀在心头，闪着斑斓的梦不畏严寒，你在左右你在心里，我身不由己遇上你，定是上天厚重的恩赐]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我在这里，你找去哪里？]]></title>
    <url>%2F2017%2F07%2F%E6%88%91%E5%9C%A8%E8%BF%99%E9%87%8C%EF%BC%8C%E4%BD%A0%E6%89%BE%E5%8E%BB%E5%93%AA%E9%87%8C%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[飘渺的云端，漫步的流云，翻滚的思念汇成闪电，仿佛被指使，轰隆隆粘上了我的发梢，带着你梦里幽香你在淡淡青草地，轻盈、雀跃的笑从白昼，到黑夜，半刻也不歇寻找，灯火阑珊几束微火缘由是星火斑斓的春日的沐浴给不了远足的马力我在身旁，紧紧跟随连我火辣辣的心，全给你可你现在，又要找去哪里？我在这里，就在这里你找去哪里？我凝望，你能凝望我凝望的影子？]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从前慢]]></title>
    <url>%2F2017%2F07%2F%E4%BB%8E%E5%89%8D%E6%85%A2%2F</url>
    <content type="text"><![CDATA[记得早先少年时 大家诚诚恳恳 说一句是一句 清早上火车站 长街黑暗无行人 卖豆浆的小店冒着热气 从前的日色变得慢 车、马、邮件都慢 一生只够爱一个人 从前的锁也好看 钥匙精美有样子 你锁了，人家就懂了]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hexo搭建博客流程]]></title>
    <url>%2F2017%2F07%2F%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[首先声明，本教程所针对的是windows用户。 安装Git下载并安装git，如果你想了解点Git的基础命令，我推荐以下博文：Git常用的基础命令，史上最全github使用方法：github入门到精通,当然即使你不懂Git的命令，跟着本博文走，也完全没问题。 安装Node.js下载并安装Node.js，此处建议不要下载最新的v6开头的版本，否则每次执行hexo命令都会有提示，建议使用v5开头的版本，Node.js主要用于安装hexo，npm开头的命令都依赖于Node.js，此处我建议安装完毕后重启电脑，因为我当初安装完没重启，结果后面使用命令安装hexo的时候，提示无效的命令，因此推荐重启。当然，你也可以选择等到后面遇到问题，再选择重启。如果出现以下提示则代表你的Node.js没有安装或者还未生效，如果已经安装了则重启电脑，如果没安装则安装再重启电脑。 安装hexo安装前先介绍几个hexo常用的命令,#后面为注释。 $ hexo g #完整命令为hexo generate，用于生成静态文件 $ hexo s #完整命令为hexo server，用于启动服务器，主要用来本地预览 $ hexo d #完整命令为hexo deploy，用于将本地文件发布到github上 $ hexo n #完整命令为hexo new，用于新建一篇文章 鼠标右键任意地方，选择Git Bash，使用以下命令安装hexo（ps：以下命令中的$符号只为了让教程和实际看起来一致，实际输入命令只需输入$ 后面的命令即可） $ npm install hexo-cli -g 如果之后在使用的过程中，遇到以下的错误 ERROR Deployer not found : github 则运行以下命令,或者你直接先运行这个命令更好。 $ npm install hexo-deployer-git –save 接下来创建放置博客文件的文件夹：hexo文件夹。在自己想要的位置创建文件夹，如我hexo文件夹的位置为E:\hexo，名字和地方可以自由选择，当然最好不要放在中文路径下，至于原因，我想很多人懂得。之后进入文件夹，即E:\hexo内，点击鼠标右键，选择Git Bash，执行以下命令，Hexo会自动在该文件夹下下载搭建网站所需的所有文件。 $ hexo init 安装依赖包 $ npm install 让我们看看刚刚下载的hexo文件带来了什么，在E:\hexo内执行以下命令， $ hexo g $ hexo s 然后用浏览器访问http://localhost:4000/，此时，你应该看到了一个漂亮的博客了，当然这个博客只是在本地的，别人是看不到的，hexo3.0使用的默认主题是landscape。轻轻松松就看到了一点成果，是不是很激动，这就是hexo的强大之处，这个本地预览的功能，我真是爱不释手。 hexo的配置文件详细参照 hexo里面有两个常用到的配置文件，分别是整个博客的配置文件E:\hexo_config.yml和主题的配置文件E:\hexo\themes\light_config.yml，此地址是对于我来说，hexo3.0使用的默认主题是landscape，因此你们的地址应该是E:\hexo\themes\landscape_config.yml，下文所有讲到light的地方，你们将之换为自己的主题名即可。本博客使用的主题是基于light改善的主题，目前还在完善中，如果完成的比较好，以后可能发布在github上。如果你想自己挑选喜欢的主题，hexo官方提供了12个主题供你自己选择，使用方法很简单，点击自己想要的主题，进入该主题的Repository，使用Git将主题clone到本地，然后将整个文件夹复制到E:\hexo\themes文件夹下，将E”\hexo_config.yml里的theme名字改为自己下载的主题的文件夹名即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# Hexo Configuration## Docs: http://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Site 这下面的几项配置都很简单，你看我的博客就知道分别是什么意思title: Chillax blog #博客名subtitle: Goals determine what you are going to be #副标题description: Goals determine what you are going to be #用于搜索，没有直观表现author: huangjunhui #作者language: zh-CN #语言timezone: #时区，此处不填写，hexo会以你目前电脑的时区为默认值# URL 暂不配置，使用默认值## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://opiece.me #域名root: /permalink: :year/:month/:day/:title/permalink_defaults:# Directory 暂不配置，使用默认值source_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writing 文章布局等，使用默认值new_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true tab_replace:# Category &amp; Tag 暂不配置，使用默认值default_category: uncategorizedcategory_map:tag_map:# Date / Time format 时间格式，使用默认值## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination ## Set per_page to 0 to disable paginationper_page: 10 #每页显示的文章数，0表示不分页pagination_dir: page# Extensions 插件配置，暂时不配置## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/plugins:- hexo-generator-feedtheme: light #使用的主题，即：E:\myblog\themes文件夹下的主题文件夹名feed: #之后配置rss会用，使用如下配置即可 type: atom path: atom.xml limit: 20 # Deployment 用于部署到github，之前已经配置过## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repository: http://github.com/huangjunhui/huangjunhui.github.io.git branch: master 按照自己的意愿修改完后，执行hexo g，hexo s，打开localhost:4000看看效果。E:\hexo\themes\light_config.yml，此处针对Concise主题，如果使用其他主题，请查看自己主题的帮助文档，NexT主题帮助文档 12345678910111213141516171819202122232425262728293031323334353637menu: #博客右上角的菜单栏，暂时使用默认值 首页: / 归档: /archives 关于: /about #该类对应于E:\hexo\themes\light\layout\_widget下的文件widgets: #站点右边栏，可以参照我的博客看，暂时使用默认值- intro #简介- search #搜索- category #分类- tagcloud #标签云- weibo #微博- blogroll #友情链接excerpt_link: Read more #文章下的Read more，可以改为&apos;阅读全文&apos;plugins: #插件，暂时使用默认值twitter: #twitter username: show_replies: false tweet_count: 5addthis: #SNS分享，暂时使用默认 enable: true pubid: facebook: true twitter: true google: true pinterest: truefancybox: true #图片效果，使用默认值google_analytics: rss: #生成RSS，暂时使用默认值 注册Github帐号已经有Github帐号跳过此步，首先进入Github进行注册，用户名、邮箱和密码之后都需要用到，自己记好。 创建repository百度 部署本地文件到github既然Repository已经创建了，当然是先把博客放到Github上去看看效果。编辑E：\hexo下的_config.yml文件，建议使用Notepad++(Sublime 也可以哈哈哈)。 在_config.yml最下方，添加如下配置(命令中的第一个huangjunhui为Github的用户名,第二个huangjunhui为之前New的Repository的名字,记得改成自己的。另外记得一点，hexo的配置文件中任何’:’后面都是带一个空格的),如果配置以下命令出现ERROR Deployer not found : github，则参考上文的解决方法。 1234deploy: type: git repository: http://github.com/huangjunhui/huangjunhui.github.io.git branch: master 配置好_config.yml并保存后，执行以下命令部署到Github上。如果你是第一次使用Github或者是已经使用过，但没有配置过SSH，则可能需要配置一下，另一种发布到github的配置走原文（我弄的时候没有使用到这一步骤）。 12$ hexo g$ hexo d 执行上面的第二个命令，可能会要你输入用户名和密码，皆为注册Github时的数据，输入密码是不显示任何东西的，输入完毕回车即可。此时，我们的博客已经搭建起来，并发布到Github上了，这时可以登陆自己的Github查看代码是否已经推送到对应Repository，在浏览器访问huangjunhui.github.io就能看到自己的博客了。第一次访问地址，可能访问不了，您可以在几分钟后进行访问，一般不超过10分钟。 发表一篇文章 在Git Bash执行命令：$ hexo new “my new post” 在E:\hexo\source_post中打开my-new-post.md，打开方式使用记事本或notepad++。hexo中写文章使用的是Markdown，没接触过的可以看下Markdown语法说明,一分钟学会Markdown 1234567title: my new post #可以改成中文的，如“新文章”date: 2015-04-08 22:56:29 #发表日期，一般不改动categories: blog #文章文类tags: [博客，文章] #文章标签，多于一项时用这种格式，只有一项时使用tags: blog---#这里是正文，用markdown写，你可以选择写一段显示在首页的简介后，加上&lt;!--more--&gt;#在&lt;!--more--&gt;之前的内容会显示在首页，之后的内容会被隐藏，当游客点击Read more才能看到。 写完文章后，你可以使用1.$ hexo g生成静态文件。2.$ hexo s在本地预览效果。3.hexo d同步到github，然后使用http://你的项目名.github.io进行访问。 12------hexo new page tags 新建标签------hexo new page categories 新建分类 清除缓存清除缓存文件db.json和已生成的静态文件public。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 1$ hexo clean 转载要注明出处：谢谢JoonWhee]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>搭建</tag>
        <tag>博客</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无关风月]]></title>
    <url>%2F2017%2F07%2F%E6%97%A0%E5%85%B3%E9%A3%8E%E6%9C%88%2F</url>
    <content type="text"><![CDATA[风的哭诉在野的其中偶尔会有稀疏的来客走了一遭超脱自然的宁静这静谧的夜要宣誓什么？你给不了万众瞩目的喧嚣，那你就别打扰这我这独处思虑的安静我的爱不是风景你何必在这里流连忘返我的爱不是风景不需要你在这到处留情我的爱不是风景爱是无关风月]]></content>
      <categories>
        <category>小调调</category>
      </categories>
      <tags>
        <tag>吟诗作赋</tag>
      </tags>
  </entry>
</search>
